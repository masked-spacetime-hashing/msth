diff --git a/MSTH/SpaceTimeHashing/ray_samplers.py b/MSTH/SpaceTimeHashing/ray_samplers.py
index f258aab..f6f24c1 100644
--- a/MSTH/SpaceTimeHashing/ray_samplers.py
+++ b/MSTH/SpaceTimeHashing/ray_samplers.py
@@ -7,6 +7,7 @@ import torch
 # from nerfacc import OccupancyGrid
 from torch import nn
 from torchtyping import TensorType
+from MSTH.utils import Timer
 
 from nerfstudio.cameras.rays import Frustums, RayBundle, RaySamples
 from nerfstudio.model_components.ray_samplers import (
@@ -108,52 +109,67 @@ class ProposalNetworkSamplerSpatial(ProposalNetworkSampler):
         ray_bundle: Optional[RayBundle] = None,
         density_fns: Optional[List[Callable]] = None,
     ) -> Tuple[RaySamples, List, List, List]:
-        assert ray_bundle is not None
-        assert density_fns is not None
-
-        weights_list = []
-        # weights_list_static = []
-        ray_samples_list = []
-
-        n = self.num_proposal_network_iterations
-        weights = None
-        weights_static = None
-        ray_samples = None
-        updated = self._steps_since_update > self.update_sched(self._step) or self._step < 10
-        # print(n)
-        for i_level in range(n + 1):
-            is_prop = i_level < n
-            num_samples = self.num_proposal_samples_per_ray[i_level] if is_prop else self.num_nerf_samples_per_ray
-            # print("num_samples", num_samples)
-            if i_level == 0:
-                # Uniform sampling because we need to start with some samples
-                ray_samples = self.initial_sampler(ray_bundle, num_samples=num_samples)
-            else:
-                # PDF sampling based on the last samples and their weights
-                # Perform annealing to the weights. This will be a no-op if self._anneal is 1.0.
-                assert weights is not None
-                annealed_weights = torch.pow(weights, self._anneal)
-                ray_samples = self.pdf_sampler(ray_bundle, ray_samples, annealed_weights, num_samples=num_samples)
-                # print("ray_samples.shape", ray_samples.shape)
-            if is_prop:
-                if updated:
-                    # always update on the first step or the inf check in grad scaling crashes
-                    # density = density_fns[i_level](ray_samples.frustums.get_positions())
-                    density, density_static = density_fns[i_level](spacetime(ray_samples))
-                    # print(density.max())
+        with Timer("total_ps"):
+            with Timer("prep"):
+                assert ray_bundle is not None
+                assert density_fns is not None
+
+                weights_list = []
+                # weights_list_static = []
+                ray_samples_list = []
+
+                n = self.num_proposal_network_iterations
+                weights = None
+                weights_static = None
+                ray_samples = None
+                updated = self._steps_since_update > self.update_sched(self._step) or self._step < 10
+            # print(n)
+            for i_level in range(n + 1):
+                with Timer("level"):
+                    is_prop = i_level < n
+                    num_samples = (
+                        self.num_proposal_samples_per_ray[i_level] if is_prop else self.num_nerf_samples_per_ray
+                    )
+                # print("num_samples", num_samples)
+                if i_level == 0:
+                    # Uniform sampling because we need to start with some samples
+                    with Timer("initial"):
+                        ray_samples = self.initial_sampler(ray_bundle, num_samples=num_samples)
                 else:
-                    with torch.no_grad():
+                    # PDF sampling based on the last samples and their weights
+                    # Perform annealing to the weights. This will be a no-op if self._anneal is 1.0.
+                    assert weights is not None
+                    with Timer("anneal"):
+                        annealed_weights = torch.pow(weights, self._anneal)
+                        self.last_weight = annealed_weights
+                    with Timer("pdf"):
+                        ray_samples = self.pdf_sampler(
+                            ray_bundle, ray_samples, annealed_weights, num_samples=num_samples
+                        )
+                    # print("ray_samples.shape", ray_samples.shape)
+                if is_prop:
+                    if updated:
+                        # always update on the first step or the inf check in grad scaling crashes
                         # density = density_fns[i_level](ray_samples.frustums.get_positions())
-                        density, density_static = density_fns[i_level](spacetime(ray_samples))
-                # print("ray_samples.shape", ray_samples.shape)
-                # print("density.shape", density.shape)
-                weights = ray_samples.get_weights(density)
-                weights_list.append(weights)  # (num_rays, num_samples)
-                # weights_static = ray_samples.get_weights(density_static)
-                # weights_list_static.append(weights_static)  # (num_rays, num_samples)
-                ray_samples_list.append(ray_samples)
-        if updated:
-            self._steps_since_update = 0
+                        with Timer("updated density_fn query"):
+                            density, density_static = density_fns[i_level](spacetime(ray_samples))
+                        # print(density.max())
+                    else:
+                        with Timer("no_updated density_fn query"):
+                            with torch.no_grad():
+                                # density = density_fns[i_level](ray_samples.frustums.get_positions())
+                                density, density_static = density_fns[i_level](spacetime(ray_samples))
+                    # print("ray_samples.shape", ray_samples.shape)
+                    # print("density.shape", density.shape)
+                    with Timer("get weights"):
+                        weights = ray_samples.get_weights(density)
+                    with Timer("append"):
+                        weights_list.append(weights)  # (num_rays, num_samples)
+                        # weights_static = ray_samples.get_weights(density_static)
+                        # weights_list_static.append(weights_static)  # (num_rays, num_samples)
+                        ray_samples_list.append(ray_samples)
+            if updated:
+                self._steps_since_update = 0
 
         assert ray_samples is not None
         return ray_samples, weights_list, ray_samples_list  # , weights_list_static
diff --git a/MSTH/SpaceTimeHashing/stmodel.py b/MSTH/SpaceTimeHashing/stmodel.py
index 7b72547..412361c 100644
--- a/MSTH/SpaceTimeHashing/stmodel.py
+++ b/MSTH/SpaceTimeHashing/stmodel.py
@@ -53,9 +53,15 @@ from nerfstudio.engine.callbacks import (
     TrainingCallbackLocation,
 )
 import tinycudann as tcnn
-from MSTH.SpaceTimeHashing.ray_samplers import ProposalNetworkSamplerSpatial, spacetime, spacetime_concat
+from MSTH.SpaceTimeHashing.ray_samplers import (
+    ProposalNetworkSamplerSpatial,
+    spacetime,
+    spacetime_concat,
+    PDFSamplerSpatial,
+    UniformLinDispPiecewiseSamplerSpatial,
+)
 from rich.console import Console
-from MSTH.SpaceTimeHashing.stmodel_components import STModule, STModuleHierarchicay, SampleNetwork
+from MSTH.SpaceTimeHashing.stmodel_components import STModule, STModuleHierarchicay, STModuleFuse, SampleNetwork
 from collections import defaultdict
 from MSTH.utils import Timer
 
@@ -90,6 +96,11 @@ class DSpaceTimeDensityFieldWithBase(Field):
         mask_log2_hash_size: int = 24,
         mask_type: str = "global",
         st_mlp_mode: str = "independent",
+        spatial_only: bool = False,
+        interp="linear",
+        nosigmoid=False,
+        ablation_add=False,
+        mask_init_mean=0.0,
     ) -> None:
         super().__init__()
         self.register_buffer("aabb", aabb)
@@ -109,29 +120,34 @@ class DSpaceTimeDensityFieldWithBase(Field):
         self.register_buffer("log2_hashmap_size_spatial", torch.tensor(log2_hashmap_size_spatial))
         self.register_buffer("log2_hashmap_size_temporal", torch.tensor(log2_hashmap_size_temporal))
 
-        if not self.use_linear:
-            if mask_type == "global":
-                STM = STModule
-            else:
-                assert mask_type == "hierarchical"
-                STM = STModuleHierarchicay
-            self.mlp_base = STM(
-                1,
-                num_levels,
-                features_per_level,
-                per_level_scale,
-                base_res,
-                log2_hashmap_size_spatial,
-                log2_hashmap_size_temporal,
-                hidden_dim,
-                num_layers,
-                mask_reso,
-                mask_log2_hash_size,
-                mode,
-                st_mlp_mode,
-            )
+        if mask_type == "global":
+            STM = STModule
+        elif mask_type == "global_fuse":
+            STM = STModuleFuse
         else:
-            raise NotImplementedError
+            assert mask_type == "hierarchical"
+            STM = STModuleHierarchicay
+        self.mlp_base = STM(
+            1,
+            num_levels,
+            features_per_level,
+            per_level_scale,
+            base_res,
+            log2_hashmap_size_spatial,
+            log2_hashmap_size_temporal,
+            hidden_dim,
+            num_layers,
+            mask_reso,
+            mask_log2_hash_size,
+            mode,
+            st_mlp_mode,
+            use_linear=self.use_linear,
+            spatial_only=spatial_only,
+            interp=interp,
+            nosigmoid=nosigmoid,
+            ablation_add=ablation_add,
+            mask_init_mean=mask_init_mean,
+        )
 
     def get_density(self, ray_samples: RaySamples, get_static_one=False) -> Tuple[TensorType, None]:
         if self.spatial_distortion is not None:
@@ -147,14 +163,11 @@ class DSpaceTimeDensityFieldWithBase(Field):
         # print(positions_flat)
         # positions_flat = positions.view(-1, 4)
 
-        if not self.use_linear:
-            mlp_out = self.mlp_base(positions_flat)
-            density_before_activation = mlp_out[0].view(*ray_samples.frustums.shape, -1).to(positions)
-            if get_static_one:
-                density_before_activation_static = mlp_out[1].view(*ray_samples.frustums.shape, -1).to(positions)
+        mlp_out = self.mlp_base(positions_flat)
+        density_before_activation = mlp_out[0].view(*ray_samples.frustums.shape, -1).to(positions)
+        if get_static_one:
+            density_before_activation_static = mlp_out[1].view(*ray_samples.frustums.shape, -1).to(positions)
 
-        else:
-            raise NotImplementedError
             # x = self.encoding(positions_flat).to(positions)
             # density_before_activation = self.linear(x).view(*ray_samples.frustums.shape, -1)
 
@@ -214,6 +227,12 @@ class DSpaceTimeHashingFieldWithBase(Field):
         mode: str = "mst",
         mask_type: str = "global",
         st_mlp_mode="independent",
+        use_linear_for_collision=False,
+        interp="linear",
+        level_one_interp="linear",
+        nosigmoid=False,
+        ablation_add=False,
+        mask_init_mean=0.0,
     ) -> None:
         super().__init__()
         self.aabb = Parameter(aabb, requires_grad=False)
@@ -241,6 +260,8 @@ class DSpaceTimeHashingFieldWithBase(Field):
         features_per_level = 2
         if mask_type == "global":
             STM = STModule
+        elif mask_type == "global_fuse":
+            STM = STModuleFuse
         else:
             assert mask_type == "hierarchical"
             STM = STModuleHierarchicay
@@ -258,6 +279,12 @@ class DSpaceTimeHashingFieldWithBase(Field):
             mask_log2_hash_size,
             mode,
             st_mlp_mode,
+            use_linear=use_linear_for_collision,
+            interp=interp,
+            level_one_interp=level_one_interp,
+            nosigmoid=nosigmoid,
+            ablation_add=ablation_add,
+            mask_init_mean=mask_init_mean,
         )
 
         in_dim = self.direction_encoding.n_output_dims + self.geo_feat_dim
@@ -443,6 +470,9 @@ class DSpaceTimeHashingModelConfig(ModelConfig):
                 "mask_log2_hash_size": 24,
                 "mask_type": "global",
                 "st_mlp_mode": "independent",
+                "interp": "linear",
+                "nosigmoid": False,
+                "mask_init_mean": 0.0,
             },
             {
                 "hidden_dim": 16,
@@ -457,6 +487,9 @@ class DSpaceTimeHashingModelConfig(ModelConfig):
                 "mask_log2_hash_size": 24,
                 "mask_type": "global",
                 "st_mlp_mode": "independent",
+                "interp": "linear",
+                "nosigmoid": False,
+                "mask_init_mean": 0.0,
             },
         ]
     )
@@ -511,6 +544,14 @@ class DSpaceTimeHashingModelConfig(ModelConfig):
     sample_network_hidden_dim: int = 64
     sample_network_num_layers: int = 2
     sample_network_loss_mult: float = 1.0
+    use_linear_for_collision: bool = False
+    debug: bool = False
+    interp: str = "linear"
+    level_one_interp: str = "linear"
+    nosigmoid: bool = False
+    ablation_add: bool = False
+    mask_init_mean: float = 0.0
+    contraction_type: str = "inf"
 
 
 class DSpaceTimeHashingModel(Model):
@@ -518,11 +559,16 @@ class DSpaceTimeHashingModel(Model):
 
     def populate_modules(self):
         super().populate_modules()
+        self.step = 0
 
         if self.config.disable_scene_contraction:
             scene_contraction = None
         else:
-            scene_contraction = SceneContraction(order=float("inf"))
+            if self.config.contraction_type == "inf":
+                scene_contraction = SceneContraction(order=float("inf"))
+            else:
+                assert self.config.contraction_type == "l2"
+                scene_contraction = SceneContraction(order=2)
 
         self.field = DSpaceTimeHashingFieldWithBase(
             self.scene_box.aabb,
@@ -540,6 +586,12 @@ class DSpaceTimeHashingModel(Model):
             mask_log2_hash_size=self.config.mask_log2_hash_size,
             mask_type=self.config.mask_type,
             st_mlp_mode=self.config.st_mlp_mode,
+            use_linear_for_collision=self.config.use_linear_for_collision,
+            interp=self.config.interp,
+            level_one_interp=self.config.level_one_interp,
+            nosigmoid=self.config.nosigmoid,
+            ablation_add=self.config.ablation_add,
+            mask_init_mean=self.config.mask_init_mean,
         )
 
         self.density_fns = []
@@ -551,6 +603,8 @@ class DSpaceTimeHashingModel(Model):
             self.sample_network = SampleNetwork(
                 hidden_dim=self.config.sample_network_hidden_dim, num_layers=self.config.sample_network_num_layers
             )
+            self.sn_initial_sampler = UniformLinDispPiecewiseSamplerSpatial(single_jitter=self.config.use_single_jitter)
+            self.sn_pdf_sampler = PDFSamplerSpatial(include_original=False, single_jitter=self.config.use_single_jitter)
             self.mle_loss = MLELoss()
 
         if self.config.use_same_proposal_network:
@@ -671,42 +725,53 @@ class DSpaceTimeHashingModel(Model):
         return callbacks
 
     def get_outputs(self, ray_bundle: RayBundle):
-        # with Timer(des="proposal_sampler"):
-        ray_samples, weights_list, ray_samples_list = self.proposal_sampler(ray_bundle, density_fns=self.density_fns)
-
         if self.config.use_sample_network:
             if self.training:
-                pass
-            sample_dist_mean, sample_dist_std = self.sample_network(
-                ray_bundle.origins, ray_bundle.directions, ray_bundle.times
-            )
-            normal_samples = torch.randn(
-                ray_bundle.origins.shape[0], self.config.num_nerf_samples_per_ray + 1, device=ray_bundle.origins.device
-            )
-            print(sample_dist_mean.shape)
-            print(sample_dist_mean.max())
-            # reparametrization trick
-            samples = normal_samples * sample_dist_std + sample_dist_mean
-            samples = samples * (self.config.far_plane - self.config.near_plane) + self.config.near_plane
-            samples = samples.sort(dim=-1)[0]
-            ray_samples_by_network = ray_bundle.get_ray_samples(
-                bin_starts=samples[..., :-1].unsqueeze(-1),
-                bin_ends=samples[..., 1:].unsqueeze(-1),
-                spacing_starts=samples[..., :-1].unsqueeze(-1),
-                spacing_ends=samples[..., 1:].unsqueeze(-1),
-                spacing_to_euclidean_fn=lambda x: x,
+                self.step += 1
+                assert self.config.num_proposal_iterations == 1
+                initial_samples = ray_samples_list[0]
+                last_weight = self.proposal_sampler.last_weight
+            else:
+                initial_samples = self.sn_initial_sampler(
+                    ray_bundle, num_samples=self.config.num_proposal_samples_per_ray[0]
+                )
+
+            sn_weights = self.sample_network(ray_bundle.origins, ray_bundle.directions, ray_bundle.times)
+
+            # sn_weights = self.sample_network.get_pdf_at(
+            # (initial_samples.frustums.starts + initial_samples.frustums.ends) / 2, sample_dist_mean, sample_dist_std
+            # )
+            # generate weights
+
+            # if self.step > 8000:
+            sn_ray_samples = self.sn_pdf_sampler(
+                ray_bundle,
+                initial_samples,
+                sn_weights.unsqueeze(dim=-1),
+                num_samples=self.config.num_nerf_samples_per_ray,
             )
-            field_outputs = self.field(ray_samples_by_network, get_static_one=self.config.render_static)
-            weights = ray_samples_by_network.get_weights(field_outputs[FieldHeadNames.DENSITY])
-            ray_samples_list.append(ray_samples_by_network)
+            field_outputs = self.field(sn_ray_samples, get_static_one=self.config.render_static)
+            weights = sn_ray_samples.get_weights(field_outputs[FieldHeadNames.DENSITY])
+            # ray_samples_list.append(sn_ray_samples)
+            ray_samples = sn_ray_samples
+            # else:
+            # field_outputs = self.field(ray_samples, get_static_one=self.config.render_static)
+            # weights = ray_samples.get_weights(field_outputs[FieldHeadNames.DENSITY])
+            # ray_samples_list.append(ray_samples)
         else:
-            field_outputs = self.field(ray_samples, get_static_one=self.config.render_static)
-            weights = ray_samples.get_weights(field_outputs[FieldHeadNames.DENSITY])
+            with Timer(des="first"):
+                ray_samples, weights_list, ray_samples_list = self.proposal_sampler(
+                    ray_bundle, density_fns=self.density_fns
+                )
+            with Timer(des="second"):
+                field_outputs = self.field(ray_samples, get_static_one=self.config.render_static)
+                weights = ray_samples.get_weights(field_outputs[FieldHeadNames.DENSITY])
             ray_samples_list.append(ray_samples)
 
-        weights_list.append(weights)
+            weights_list.append(weights)
 
-        rgb = self.renderer_rgb(rgb=field_outputs[FieldHeadNames.RGB], weights=weights)
+        with Timer(des="renderrgb"):
+            rgb = self.renderer_rgb(rgb=field_outputs[FieldHeadNames.RGB], weights=weights)
 
         # weights_list_static.append(weights_static)
         if self.config.render_static:
@@ -715,20 +780,27 @@ class DSpaceTimeHashingModel(Model):
         else:
             rgb_static = None
 
-        depth = self.renderer_depth(weights=weights, ray_samples=ray_samples)
-        accumulation = self.renderer_accumulation(weights=weights)
+        if self.config.debug:
+            depth = self.renderer_depth(weights=weights, ray_samples=ray_samples)
+            accumulation = self.renderer_accumulation(weights=weights)
 
-        outputs = {
-            "rgb": rgb,
-            "accumulation": accumulation,
-            "depth": depth,
-        }
-        outputs.update({"rgb_static": rgb_static})
+            outputs = {
+                "rgb": rgb,
+                "accumulation": accumulation,
+                "depth": depth,
+            }
+        else:
+            outputs = {
+                "rgb": rgb,
+            }
+
+        with Timer(des="dictupdate"):
+            outputs.update({"rgb_static": rgb_static})
 
         if self.config.use_sample_network:
-            outputs.update({"proposal_samples": proposal_samples})
-            outputs.update({"sample_dist_std": sample_dist_std})
-            outputs.update({"sample_dist_mean": sample_dist_mean})
+            outputs.update({"sn_weights": sn_weights})
+            if self.training:
+                outputs.update({"last_weight": last_weight.squeeze()})
 
         if self.config.predict_normals:
             normals = self.renderer_normals(normals=field_outputs[FieldHeadNames.NORMALS], weights=weights)
@@ -752,9 +824,13 @@ class DSpaceTimeHashingModel(Model):
                 field_outputs[FieldHeadNames.PRED_NORMALS],
             )
 
-        for i in range(self.config.num_proposal_iterations):
-            # CONSOLE.print(i, weights_list[i].max())
-            outputs[f"prop_depth_{i}"] = self.renderer_depth(weights=weights_list[i], ray_samples=ray_samples_list[i])
+        if self.config.debug:
+            for i in range(self.config.num_proposal_iterations):
+                # CONSOLE.print(i, weights_list[i].max())
+                outputs[f"prop_depth_{i}"] = self.renderer_depth(
+                    weights=weights_list[i], ray_samples=ray_samples_list[i]
+                )
+        # outputs[f"prop_depth_sn"] = self.renderer_depth(weights=sn_weights, ray_samples=sn_ray_samples)
 
         # CONSOLE.print("final", weights_list[-1].max())
 
@@ -774,9 +850,11 @@ class DSpaceTimeHashingModel(Model):
         loss_dict["rgb_loss"] = self.rgb_loss(image, outputs["rgb"])
         if self.training:
             if self.config.use_sample_network:
-                loss_dict["sample_network_loss"] = self.config.sample_network_loss_mult * self.mle_loss(
-                    outputs["proposal_samples"], outputs["sample_dist_mean"], outputs["sample_dist_std"]
-                )
+                if self.step > 1000:
+                    loss_dict["sample_network_loss"] = (
+                        self.config.sample_network_loss_mult  # * (outputs["last_weight"].detach() - outputs["sn_weights"]).abs().mean()
+                        * (-outputs["last_weight"].detach() * (outputs["sn_weights"] + 1e-7).log()).sum(-1).mean()
+                    )
             if self.config.render_static and self.config.use_loss_static:
                 assert "is_static" in batch, "Must provide is_static in batch for static rendering."
                 loss_dict["rgb_static_loss"] = self.rgb_loss(
@@ -789,11 +867,15 @@ class DSpaceTimeHashingModel(Model):
             #
             if self.config.mask_loss_mult > 0.0:
                 loss_dict["mask_loss"] = (
-                    self.field.mlp_base.temporal_prod_net[0].get_mask_loss() * self.config.mask_loss_mult
+                    # self.field.mlp_base.temporal_prod_net[0].get_mask_loss() * self.config.mask_loss_mult
+                    self.field.mlp_base.temporal_prod_net.get_mask_loss()
+                    * self.config.mask_loss_mult
                 )
                 for net in self.proposal_networks:
                     loss_dict["mask_loss"] += (
-                        net.mlp_base.temporal_prod_net[0].get_mask_loss() * self.config.mask_loss_mult
+                        # net.mlp_base.temporal_prod_net[0].get_mask_loss() * self.config.mask_loss_mult
+                        net.mlp_base.temporal_prod_net.get_mask_loss()
+                        * self.config.mask_loss_mult
                     )
 
             # + self.config.interlevel_loss_mult * interlevel_loss(
@@ -831,18 +913,20 @@ class DSpaceTimeHashingModel(Model):
             rgb_static = outputs["rgb_static"]
         else:
             rgb_static = None
-        acc = colormaps.apply_colormap(outputs["accumulation"])
-        depth = colormaps.apply_depth_colormap(
-            outputs["depth"],
-            accumulation=outputs["accumulation"],
-        )
+
+        if self.config.debug:
+            acc = colormaps.apply_colormap(outputs["accumulation"])
+            depth = colormaps.apply_depth_colormap(
+                outputs["depth"],
+                accumulation=outputs["accumulation"],
+            )
+            combined_acc = torch.cat([acc], dim=1)
+            combined_depth = torch.cat([depth], dim=1)
 
         if rgb_static is not None:
             combined_rgb = torch.cat([image, rgb, rgb_static], dim=1)
         else:
             combined_rgb = torch.cat([image, rgb], dim=1)
-        combined_acc = torch.cat([acc], dim=1)
-        combined_depth = torch.cat([depth], dim=1)
 
         # Switch images from [H, W, C] to [1, C, H, W] for metrics computations
         image = torch.moveaxis(image, -1, 0)[None, ...]
@@ -856,15 +940,19 @@ class DSpaceTimeHashingModel(Model):
         metrics_dict = {"psnr": float(psnr.item()), "ssim": float(ssim)}  # type: ignore
         metrics_dict["lpips"] = float(lpips)
 
-        images_dict = {"img": combined_rgb, "accumulation": combined_acc, "depth": combined_depth}
-
-        for i in range(self.config.num_proposal_iterations):
-            key = f"prop_depth_{i}"
-            prop_depth_i = colormaps.apply_depth_colormap(
-                outputs[key],
-                accumulation=outputs["accumulation"],
-            )
-            images_dict[key] = prop_depth_i
+        if self.config.debug:
+            images_dict = {"img": combined_rgb, "accumulation": combined_acc, "depth": combined_depth}
+        else:
+            images_dict = {"img": combined_rgb}
+
+        if not self.config.use_sample_network and self.config.debug:
+            for i in range(self.config.num_proposal_iterations):
+                key = f"prop_depth_{i}"
+                prop_depth_i = colormaps.apply_depth_colormap(
+                    outputs[key],
+                    accumulation=outputs["accumulation"],
+                )
+                images_dict[key] = prop_depth_i
 
         return metrics_dict, images_dict
 
diff --git a/MSTH/SpaceTimeHashing/stmodel_components.py b/MSTH/SpaceTimeHashing/stmodel_components.py
index 56064fc..2229aeb 100644
--- a/MSTH/SpaceTimeHashing/stmodel_components.py
+++ b/MSTH/SpaceTimeHashing/stmodel_components.py
@@ -1,44 +1,12 @@
 import torch
 import torch.nn as nn
 from MSTH.gridencoder import GridEncoder
+from MSTH.gridencoder import SpatialTemporalGridEncoder
 import tinycudann as tcnn
 from MSTH.utils import Timer
 from nerfstudio.field_components.activations import trunc_exp
 
 
-class SpaceTimeMixture(nn.Module):
-    def __init__(self, spatial_net, temporal_net, temporal_prod_net, mode="mst"):
-        """
-        mode: mst or mt, mst is for m * s + (1-m) * t, mt is for s + (1-m) * t
-        """
-        super().__init__()
-        self.spatial_net = spatial_net
-        self.temporal_net = temporal_net
-        self.temporal_prod_net = temporal_prod_net
-        self.mode = mode
-
-    # 
-    def forward(self, x):
-        # x should be B x 4
-        spatial_component = self.spatial_net(x[..., :3])
-        temporal_component = self.temporal_net(x)
-        temporal_prod_component = self.temporal_prod_net(x[..., :3]).sigmoid()
-
-        # torch.cuda.synchronize("cuda:0")
-
-        if self.mode == "mst":
-            output = spatial_component * temporal_prod_component + (1 - temporal_prod_component) * temporal_component
-        else:
-            assert self.mode == "mt"
-            output = spatial_component + (1 - temporal_prod_component) * temporal_component
-
-        return (
-            output,
-            # spatial_component * temporal_prod_component + (1 - temporal_prod_component) * temporal_component,
-            spatial_component,
-        )
-
-
 class SampleNetwork(nn.Module):
     def __init__(self, hidden_dim=64, num_layers=2):
         super().__init__()
@@ -65,16 +33,32 @@ class SampleNetwork(nn.Module):
             n_input_dims=self.position_encoding.n_output_dims
             + self.direction_encoding.n_output_dims
             + self.time_encoding.n_output_dims,
-            n_output_dims=2,
+            n_output_dims=128,
             network_config={
                 "otype": "FullyFusedMLP",
                 "activation": "ReLU",
-                "output_activation": "ReLU",
+                # "output_activation": "ReLU",
                 "n_neurons": hidden_dim,
                 "n_hidden_layers": num_layers - 1,
             },
         )
 
+    # def forward(self, rays_o, rays_d, rays_t):
+    #     # rays_o: B x 3
+    #     # rays_d: B x 3
+    #     # rays_t: B x 1
+    #     if len(rays_t.shape) == 1:
+    #         rays_t = rays_t.unsqueeze(-1)
+    #     o_rep = self.position_encoding(rays_o)
+    #     d_rep = self.direction_encoding(rays_d)
+    #     t_rep = self.time_encoding(rays_t)
+    #     input_rep = torch.cat([o_rep, d_rep, t_rep], dim=-1)
+    #     out = trunc_exp(self.network(input_rep))
+    #     # out = self.network(input_rep)
+    #     mean = out[..., 0:1]
+    #     std = out[..., 1:2]
+    #     return mean, std
+
     def forward(self, rays_o, rays_d, rays_t):
         # rays_o: B x 3
         # rays_d: B x 3
@@ -85,11 +69,16 @@ class SampleNetwork(nn.Module):
         d_rep = self.direction_encoding(rays_d)
         t_rep = self.time_encoding(rays_t)
         input_rep = torch.cat([o_rep, d_rep, t_rep], dim=-1)
-        # out = trunc_exp(self.network(input_rep))
-        out = self.network(input_rep)
-        mean = out[..., 0:1]
-        std = out[..., 1:2]
-        return mean, std
+        out = torch.nn.functional.softmax(self.network(input_rep), dim=-1)
+        # out = self.network(input_rep)
+        return out
+
+    # def get_pdf_at(self, rel_pos, mean, std):
+    #     rel_pos = rel_pos.squeeze()
+    #     eps = 1e-7
+    #     # rel_pos B x N, mean B x 1, std B x 1
+    #     P = 1 / (2.5066282532517663 * (std + eps)) * torch.exp(-0.5 * (rel_pos - mean) ** 2 / (std**2 + eps))
+    #     return P
 
 
 class STModule(nn.Module):
@@ -108,10 +97,19 @@ class STModule(nn.Module):
         mask_log2_hash_size,
         mode,
         st_mlp_mode="independent",
+        use_linear=False,
+        spatial_only=False,
+        interp="linear",
+        level_one_interp="linear",
+        nosigmoid=False,
+        ablation_add=False,
+        **kwargs,
     ):
         super().__init__()
         assert st_mlp_mode == "independent" or st_mlp_mode == "shared"
+        self.ablation_add = ablation_add
         self.st_mlp_mode = st_mlp_mode
+        self.spatial_only = spatial_only
         if st_mlp_mode == "independent":
             self.spatial_net = nn.Sequential(
                 GridEncoder(
@@ -122,8 +120,11 @@ class STModule(nn.Module):
                     base_resolution=base_res[:3],
                     log2_hashmap_size=log2_hashmap_size_spatial,
                     std=1e-4,
+                    interpolation=interp,
                 ),
-                tcnn.Network(
+                nn.Linear(features_per_level * num_levels, n_output_dim)
+                if use_linear
+                else tcnn.Network(
                     n_input_dims=features_per_level * num_levels,
                     n_output_dims=n_output_dim,
                     network_config={
@@ -145,8 +146,11 @@ class STModule(nn.Module):
                     base_resolution=base_res,
                     log2_hashmap_size=log2_hashmap_size_temporal,
                     std=1e-4,
+                    interpolation=interp,
                 ),
-                tcnn.Network(
+                nn.Linear(features_per_level * num_levels, n_output_dim)
+                if use_linear
+                else tcnn.Network(
                     n_input_dims=features_per_level * num_levels,
                     n_output_dims=n_output_dim,
                     network_config={
@@ -167,6 +171,7 @@ class STModule(nn.Module):
                 base_resolution=base_res[:3],
                 log2_hashmap_size=log2_hashmap_size_spatial,
                 std=1e-4,
+                interpolation=interp,
             )
 
             self.temporal_net = GridEncoder(
@@ -177,18 +182,23 @@ class STModule(nn.Module):
                 base_resolution=base_res,
                 log2_hashmap_size=log2_hashmap_size_temporal,
                 std=1e-4,
+                interpolation=interp,
             )
 
-            self.mlp_shared = tcnn.Network(
-                n_input_dims=features_per_level * num_levels,
-                n_output_dims=n_output_dim,
-                network_config={
-                    "otype": "FullyFusedMLP",
-                    "activation": "ReLU",
-                    "output_activation": "None",
-                    "n_neurons": hidden_dim,
-                    "n_hidden_layers": num_layers - 1,
-                },
+            self.mlp_shared = (
+                nn.Linear(features_per_level * num_levels, n_output_dim)
+                if use_linear
+                else tcnn.Network(
+                    n_input_dims=features_per_level * num_levels,
+                    n_output_dims=n_output_dim,
+                    network_config={
+                        "otype": "FullyFusedMLP",
+                        "activation": "ReLU",
+                        "output_activation": "None",
+                        "n_neurons": hidden_dim,
+                        "n_hidden_layers": num_layers - 1,
+                    },
+                )
             )
 
         self.temporal_prod_net = GridEncoder(
@@ -200,19 +210,41 @@ class STModule(nn.Module):
             log2_hashmap_size=mask_log2_hash_size,
             std=1e-4,
             gridtype="tiled",
+            interpolation=interp,
+            # interpolation="all_nearest",
+            mean=kwargs["mask_init_mean"],
         )
-
+        self.nosigmoid = nosigmoid
         self.mode = mode
 
     # 
     def forward(self, x):
         spatial_component = self.spatial_net(x[..., :3])
+        if self.spatial_only:
+            return spatial_component, spatial_component
         # torch.cuda.synchronize("cuda")
         temporal_component = self.temporal_net(x)
+
         # torch.cuda.synchronize("cuda")
-        temporal_prod_component = self.temporal_prod_net(x[..., :3]).sigmoid()
+        temporal_prod_component = self.temporal_prod_net(x[..., :3])
+        if not self.nosigmoid:
+            temporal_prod_component = temporal_prod_component.sigmoid()
         # torch.cuda.synchronize("cuda")
 
+        if self.ablation_add:
+            # print("spatial add temporal")
+            output = spatial_component + temporal_component
+            if self.st_mlp_mode == "shared":
+                # print("shared")
+                output = self.mlp_shared(output)
+                # spatial_component = self.mlp_shared(spatial_component)
+                spatial_component = None
+            return (
+                output,
+                # spatial_component * temporal_prod_component + (1 - temporal_prod_component) * temporal_component,
+                spatial_component,
+            )
+
         if self.mode == "mst":
             output = spatial_component * temporal_prod_component + (1 - temporal_prod_component) * temporal_component
         else:
@@ -221,7 +253,83 @@ class STModule(nn.Module):
 
         if self.st_mlp_mode == "shared":
             output = self.mlp_shared(output)
-            spatial_component = self.mlp_shared(spatial_component)
+            # spatial_component = self.mlp_shared(spatial_component)
+            spatial_component = None
+
+        return (
+            output,
+            # spatial_component * temporal_prod_component + (1 - temporal_prod_component) * temporal_component,
+            spatial_component,
+        )
+
+
+class STModuleFuse(nn.Module):
+    def __init__(
+        self,
+        n_output_dim,
+        num_levels,
+        features_per_level,
+        per_level_scale,
+        base_res,
+        log2_hashmap_size_spatial,
+        log2_hashmap_size_temporal,
+        hidden_dim,
+        num_layers,
+        mask_reso,
+        mask_log2_hash_size,
+        mode,
+        st_mlp_mode="independent",
+        use_linear=False,
+        spatial_only=False,
+        interp="linear",
+        level_one_interp="linear",
+        nosigmoid=False,
+        ablation_add=False,
+        **kwargs,
+    ):
+        super().__init__()
+        assert st_mlp_mode == "shared", "only suport fused operation for shared mode"
+        assert log2_hashmap_size_spatial == log2_hashmap_size_temporal
+        self.st_mlp_mode = st_mlp_mode
+        self.backbone = SpatialTemporalGridEncoder(
+            input_dim=4,
+            num_levels=num_levels,
+            level_dim=features_per_level,
+            per_level_scale=per_level_scale,
+            base_resolution=base_res,
+            log2_hashmap_size=log2_hashmap_size_spatial,
+            desired_resolution=None,
+            gridtype="hash",
+            align_corners=False,
+            interpolation="linear",
+            mask_resolution=mask_reso,
+            std=1e-4,
+        )
+
+        self.mlp_shared = (
+            nn.Linear(features_per_level * num_levels, n_output_dim)
+            if use_linear
+            else tcnn.Network(
+                n_input_dims=features_per_level * num_levels,
+                n_output_dims=n_output_dim,
+                network_config={
+                    "otype": "FullyFusedMLP",
+                    "activation": "ReLU",
+                    "output_activation": "None",
+                    "n_neurons": hidden_dim,
+                    "n_hidden_layers": num_layers - 1,
+                },
+            )
+        )
+
+        self.mode = mode
+
+    # 
+    def forward(self, x):
+        output = self.backbone(x)
+        output = self.mlp_shared(output)
+        # spatial_component = self.mlp_shared(spatial_component)
+        spatial_component = None
 
         return (
             output,
@@ -246,6 +354,13 @@ class STModuleHierarchicay(nn.Module):
         mask_log2_hash_size,
         mode,
         st_mlp_mode="independent",
+        use_linear=False,
+        spatial_only=False,
+        interp="linear",
+        level_one_interp="linear",
+        nosigmoid=False,
+        ablation_add=False,
+        **kwargs,
     ):
         super().__init__()
         assert st_mlp_mode == "independent" or st_mlp_mode == "shared"
@@ -264,8 +379,11 @@ class STModuleHierarchicay(nn.Module):
                     base_resolution=base_res[:3],
                     log2_hashmap_size=log2_hashmap_size_spatial,
                     std=1e-4,
+                    interpolation=interp,
                 ),
-                tcnn.Network(
+                nn.Linear(features_per_level * num_levels, n_output_dim)
+                if use_linear
+                else tcnn.Network(
                     n_input_dims=features_per_level * num_levels,
                     n_output_dims=n_output_dim,
                     network_config={
@@ -287,8 +405,11 @@ class STModuleHierarchicay(nn.Module):
                     base_resolution=base_res,
                     log2_hashmap_size=log2_hashmap_size_spatial,
                     std=1e-4,
+                    interpolation=level_one_interp,
                 ),
-                tcnn.Network(
+                nn.Linear(features_per_level * num_levels, n_output_dim)
+                if use_linear
+                else tcnn.Network(
                     n_input_dims=features_per_level * num_levels,
                     n_output_dims=n_output_dim,
                     network_config={
@@ -309,8 +430,11 @@ class STModuleHierarchicay(nn.Module):
                     base_resolution=base_res,
                     log2_hashmap_size=log2_hashmap_size_temporal,
                     std=1e-4,
+                    interpolation=interp,
                 ),
-                tcnn.Network(
+                nn.Linear(features_per_level * num_levels, n_output_dim)
+                if use_linear
+                else tcnn.Network(
                     n_input_dims=features_per_level * num_levels,
                     n_output_dims=n_output_dim,
                     network_config={
@@ -331,6 +455,7 @@ class STModuleHierarchicay(nn.Module):
                 base_resolution=base_res[:3],
                 log2_hashmap_size=log2_hashmap_size_spatial,
                 std=1e-4,
+                interpolation=interp,
             )
 
             self.level_one_temporal_net = GridEncoder(
@@ -341,6 +466,7 @@ class STModuleHierarchicay(nn.Module):
                 base_resolution=base_res,
                 log2_hashmap_size=log2_hashmap_size_spatial,
                 std=1e-4,
+                interpolation=level_one_interp,
             )
 
             self.temporal_net = GridEncoder(
@@ -351,20 +477,24 @@ class STModuleHierarchicay(nn.Module):
                 base_resolution=base_res,
                 log2_hashmap_size=log2_hashmap_size_temporal,
                 std=1e-4,
+                interpolation=interp,
             )
 
-            self.mlp_shared = tcnn.Network(
-                n_input_dims=features_per_level * num_levels,
-                n_output_dims=n_output_dim,
-                network_config={
-                    "otype": "FullyFusedMLP",
-                    "activation": "ReLU",
-                    "output_activation": "None",
-                    "n_neurons": hidden_dim * 2,
-                    "n_hidden_layers": num_layers - 1,
-                },
+            self.mlp_shared = (
+                nn.Linear(features_per_level * num_levels, n_output_dim)
+                if use_linear
+                else tcnn.Network(
+                    n_input_dims=features_per_level * num_levels,
+                    n_output_dims=n_output_dim,
+                    network_config={
+                        "otype": "FullyFusedMLP",
+                        "activation": "ReLU",
+                        "output_activation": "None",
+                        "n_neurons": hidden_dim * 2,
+                        "n_hidden_layers": num_layers - 1,
+                    },
+                )
             )
-
         self.temporal_prod_net = nn.Sequential(
             GridEncoder(
                 input_dim=3,
@@ -374,15 +504,17 @@ class STModuleHierarchicay(nn.Module):
                 base_resolution=mask_reso,
                 log2_hashmap_size=mask_log2_hash_size,
                 std=1e-4,
+                interpolation=interp,
             ),
-            # nn.Linear(2, 1 + self.level_one_bins),
-            tcnn.Network(
+            nn.Linear(2, 1 + self.level_one_bins)
+            if use_linear
+            else tcnn.Network(
                 n_input_dims=2,
                 n_output_dims=1 + self.level_one_bins,
                 network_config={
                     "otype": "FullyFusedMLP",
                     "activation": "ReLU",
-                    "output_activation": "Sigmoid",
+                    "output_activation": ("None" if nosigmoid else "Sigmoid"),
                     "n_neurons": 16,
                     "n_hidden_layers": num_layers - 1,
                 },
diff --git a/MSTH/SpaceTimeHashing/trainer.py b/MSTH/SpaceTimeHashing/trainer.py
index 951a0ae..0a1acf2 100644
--- a/MSTH/SpaceTimeHashing/trainer.py
+++ b/MSTH/SpaceTimeHashing/trainer.py
@@ -85,7 +85,7 @@ class SpaceTimeHashingTrainerConfig(TrainerConfig):
     """Optionally log gradients during training"""
 
     wandb_name: str = "none"
-    steps_full_video: int = 30000
+    steps_full_video: int = 10000000000
     eval_total_frames: Optional[int] = None
     save_eval_video: bool = False
 
diff --git a/MSTH/configs/method_configs.py b/MSTH/configs/method_configs.py
index 0d8e4d6..ca5fa3d 100755
--- a/MSTH/configs/method_configs.py
+++ b/MSTH/configs/method_configs.py
@@ -1390,9 +1390,11 @@ method_configs["nerfacto_profiling"] = TrainerConfig(
 
 
 import MSTH.configs.method_configs_tp as method_configs_tp
+import MSTH.configs.method_configs_tpa as method_configs_tpa
 from MSTH.configs.freeze import method_configs as freeze_configs
 
 method_configs.update(method_configs_tp.method_configs)
+method_configs.update(method_configs_tpa.method_configs)
 
 method_configs.update(freeze_configs)
 
diff --git a/MSTH/configs/method_configs_tp.py b/MSTH/configs/method_configs_tp.py
index 761a79f..a758959 100755
--- a/MSTH/configs/method_configs_tp.py
+++ b/MSTH/configs/method_configs_tp.py
@@ -1664,7 +1664,7 @@ method_configs["tp33_31_p_sample_network"] = SpaceTimeHashingTrainerConfig(
             use_sample_network=True,
             sample_network_hidden_dim=64,
             sample_network_num_layers=2,
-            sample_network_loss_mult=1.0,
+            sample_network_loss_mult=1,
             proposal_net_args_list=[
                 {
                     "hidden_dim": 16,
@@ -1706,3 +1706,2214 @@ method_configs["tp33_31_p_sample_network"] = SpaceTimeHashingTrainerConfig(
         },
     },
 )
+
+
+method_configs["tp34_hierarchicay_16384_small_mask"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=64,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=32768,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="hierarchical",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "hierarchical",
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+
+method_configs["tp35_hierarchicay_16384_small_mask"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=65536,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="hierarchical",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tp36_35_plus_linear"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=32768,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="hierarchical",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": True,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tp37_35_plus_alllinear"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=32768,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="hierarchical",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            use_linear_for_collision=True,
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": True,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tp38_small_hash_base36"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=17,
+            log2_hashmap_size_temporal=17,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=32768,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(32, 32, 32),
+            mask_log2_hash_size=15,
+            mask_type="hierarchical",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 21,
+                    "log2_hashmap_size_temporal": 25,
+                    "num_levels": 1,
+                    "features_per_level": 1,
+                    "max_res": (128, 128, 128, 16),
+                    "base_res": (128, 128, 128, 16),
+                    # "base_res": (16, 16, 16, 15),
+                    "use_linear": True,
+                    "mode": "mt",
+                    "mask_reso": (32, 32, 32),
+                    "mask_log2_hash_size": 15,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                    "spatial_only": True,
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+
+method_configs["tp39_35_p_allnearset"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=65536,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="hierarchical",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            interp="all_nearest",
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                    "interp": "all_nearest",
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tp40_same_as_35"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=65536,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="hierarchical",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            interp="linear",
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                    "interp": "linear",
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+
+method_configs["tp41_40_last_nearest_for_ps"] = copy.deepcopy(method_configs["tp40_same_as_35"])
+method_configs["tp41_40_last_nearest_for_ps"].pipeline.model.proposal_net_args_list[0]["interp"] = "last_nearest"
+
+method_configs["tp42_40_all_nearest_for_ps"] = copy.deepcopy(method_configs["tp40_same_as_35"])
+method_configs["tp42_40_all_nearest_for_ps"].pipeline.model.proposal_net_args_list[0]["interp"] = "all_nearest"
+
+method_configs["tp43_40_64"] = copy.deepcopy(method_configs["tp40_same_as_35"])
+method_configs["tp43_40_64"].pipeline.model.num_proposal_samples_per_ray = (64,)
+
+method_configs["tp44_40_global_64"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(64,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=65536,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="global",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            interp="linear",
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                    "interp": "linear",
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tp45_44_p_shared"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(64,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=65536,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="global",
+            st_mlp_mode="shared",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            interp="linear",
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                    "interp": "linear",
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tp46_45_p_50_0.1"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=0.1,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(64,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=65536,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="global",
+            # st_mlp_mode="",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            interp="linear",
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                    "interp": "linear",
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tp47_46_p_20"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=0.1,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(64,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=20,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=65536,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="global",
+            # st_mlp_mode="shared",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            interp="linear",
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                    "interp": "linear",
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tp48"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=0.1,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=20,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=65536,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="global",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            interp="linear",
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    # "st_mlp_mode": "shared",
+                    "interp": "linear",
+                },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tp49_hierarchicay_16384_small_mask_base34"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=0.1,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=64,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=32768,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="hierarchical",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "hierarchical",
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tp50_hierarchicay_16384_small_mask_base34_level_one_interp"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=0.1,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=64,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=32768,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="hierarchical",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            level_one_interp="last_nearest",
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "hierarchical",
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tp51_34_p_global"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=32768,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="global",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tp52_34_p_global_p_shared"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=32768,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="global",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            st_mlp_mode="shared",
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tp53_52_p_fuse"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_eval_image=500,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=32768,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="global_fuse",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            st_mlp_mode="shared",
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global_fuse",
+                    "st_mlp_mode": "shared",
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tp54_same_as_35_no_sigmoid"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=65536,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="hierarchical",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            interp="linear",
+            nosigmoid=True,
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                    "interp": "linear",
+                    "nosigmoid": True,
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+
+method_configs["tp52_34_p_global_p_shared"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            # far_plane=500,
+            # proposal_initial_sampler="uniform",
+            # sparse_loss_mult_h=0.01,
+            # sparse_loss_mult_f=0.01,
+            eval_num_rays_per_chunk=32768,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="global",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            st_mlp_mode="shared",
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+
+method_configs["tpa_1"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                # data=Path("/data/machine/data/flame_salmon_videos_2"),
+                data=Path("/data/machine/data/fit/videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            eval_num_rays_per_chunk=32768,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="global",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            interp="linear",
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                    "interp": "linear",
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tpa_2"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                # data=Path("/data/machine/data/flame_salmon_videos_2"),
+                data=Path("/data/machine/data/fit/videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            eval_num_rays_per_chunk=32768,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="global",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            interp="linear",
+            ablation_add=True,
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "independent",
+                    "interp": "linear",
+                    "ablation_add": True,
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tpa_1_20"] = copy.deepcopy(method_configs["tpa_1"])
+method_configs["tpa_1_20"].pipeline.model.log2_hashmap_size_temporal = 20
+method_configs["tpa_2_20"] = copy.deepcopy(method_configs["tpa_2"])
+method_configs["tpa_2_20"].pipeline.model.log2_hashmap_size_temporal = 20
+
+method_configs["tpa_1_smp"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                # data=Path("/data/machine/data/flame_salmon_videos_2"),
+                data=Path("/data/machine/data/fit/videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            num_proposal_samples_per_ray=(256, 96),
+            # num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            eval_num_rays_per_chunk=32768,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="global",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            interp="linear",
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                    "interp": "linear",
+                },
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (256, 256, 256, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                    "interp": "linear",
+                },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+method_configs["tpa_2_smp"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                # data=Path("/data/machine/data/flame_salmon_videos_2"),
+                data=Path("/data/machine/data/fit/videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            num_proposal_samples_per_ray=(256, 96),
+            # num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=19,
+            eval_num_rays_per_chunk=32768,
+            mask_loss_mult=0.0,
+            mst_mode="mt",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="global",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            interp="linear",
+            ablation_add=True,
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "independent",
+                    "interp": "linear",
+                    "ablation_add": True,
+                },
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (256, 256, 256, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mt",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "hierarchical",
+                    "mask_type": "global",
+                    "st_mlp_mode": "independent",
+                    "interp": "linear",
+                    "ablation_add": True,
+                },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
+
+
+method_configs["tpa_3"] = SpaceTimeHashingTrainerConfig(
+    method_name="Spatial_Time_Hashing_With_Base",
+    steps_per_eval_batch=1000,
+    steps_per_save=20000,
+    max_num_iterations=10000,
+    mixed_precision=True,
+    log_gradients=True,
+    pipeline=SpaceTimePipelineConfig(
+        datamanager=SpaceTimeDataManagerConfig(
+            dataparser=VideoDataParserConfig(
+                data=Path("/data/machine/data/flame_salmon_videos_2"),
+                downscale_factor=2,
+                # scale_factor=1.0 / 2.0,
+                scale_factor=0.5,
+            ),
+            train_num_rays_per_batch=16384,
+            # eval_num_rays_per_batch=32768,
+            camera_optimizer=CameraOptimizerConfig(mode="off"),
+            use_uint8=True,
+            use_stratified_pixel_sampler=True,
+            static_dynamic_sampling_ratio=50,
+            static_dynamic_sampling_ratio_end=10,
+            static_ratio_decay_total_steps=10000,
+        ),
+        model=DSpaceTimeHashingModelConfig(
+            # distortion_loss_mult=0.0,
+            max_res=(2048, 2048, 2048, 300),
+            base_res=(16, 16, 16, 15),
+            # num_proposal_samples_per_ray=(256, 96),
+            num_proposal_samples_per_ray=(128,),
+            num_nerf_samples_per_ray=48,
+            proposal_weights_anneal_max_num_iters=5000,
+            # proposal_weights_anneal_slope = 10.0,
+            log2_hashmap_size_spatial=19,
+            log2_hashmap_size_temporal=16,
+            eval_num_rays_per_chunk=32768,
+            mask_loss_mult=0.0,
+            mst_mode="mst",
+            mask_reso=(128, 128, 128),
+            mask_log2_hash_size=21,
+            mask_type="global",
+            num_proposal_iterations=1,
+            use_loss_static=False,
+            render_static=False,
+            interp="linear",
+            nosigmoid=False,
+            proposal_net_args_list=[
+                {
+                    "hidden_dim": 16,
+                    "log2_hashmap_size_spatial": 17,
+                    "log2_hashmap_size_temporal": 17,
+                    "num_levels": 5,
+                    "max_res": (128, 128, 128, 150),
+                    "base_res": (16, 16, 16, 15),
+                    "use_linear": False,
+                    "mode": "mst",
+                    "mask_reso": (64, 64, 64),
+                    "mask_log2_hash_size": 18,
+                    "mask_type": "global",
+                    "st_mlp_mode": "shared",
+                    "interp": "linear",
+                    "nosigmoid": False,
+                },
+                # {
+                #     "hidden_dim": 16,
+                #     "log2_hashmap_size_spatial": 17,
+                #     "log2_hashmap_size_temporal": 17,
+                #     "num_levels": 5,
+                #     "max_res": (256, 256, 256, 150),
+                #     "base_res": (16, 16, 16, 15),
+                #     "use_linear": False,
+                #     "mode": "mt",
+                #     "mask_reso": (64, 64, 64),
+                #     "mask_log2_hash_size": 18,
+                #     "mask_type": "hierarchical",
+                # },
+            ],
+        ),
+    ),
+    optimizers={
+        "proposal_networks": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+        "fields": {
+            "optimizer": AdamOptimizerConfig(lr=1e-2, eps=1e-15),
+            "scheduler": ExponentialDecaySchedulerConfig(lr_final=5e-4, max_steps=15000),
+        },
+    },
+)
diff --git a/MSTH/datamanager.py b/MSTH/datamanager.py
index fb3baa2..3e3ea6a 100644
--- a/MSTH/datamanager.py
+++ b/MSTH/datamanager.py
@@ -3,13 +3,14 @@ from dataclasses import dataclass, field
 from typing import Dict, List, Optional, Tuple, Type, Union
 
 try:
-    from typing import Literal
+    from typing import Literal, Callable
 except ImportError:
     from typing_extensions import Literal
 
 from pathlib import Path
 
 import torch
+import os
 from rich.progress import Console
 from torch.nn.parameter import Parameter
 from torch.utils.data.dataloader import DataLoader
@@ -28,7 +29,15 @@ from MSTH.dataparser import (
 
 # from MSTH.dataset import EvalVideoDataset, VideoDataset
 from MSTH.dataset import VideoDataset, VideoDatasetWithFeature, VideoDatasetAllCached, VideoDatasetAllCachedUint8
-from MSTH.sampler import CompletePixelSampler, CompletePixelSamplerIter, PixelTimeSampler, PixelTimeUniformSampler, spacetime_samplers, PixelTimeUniformSampler_origin
+from MSTH.sampler import (
+    CompletePixelSampler,
+    CompletePixelSamplerIter,
+    PixelTimeSampler,
+    PixelTimeUniformSampler,
+    spacetime_samplers,
+    PixelTimeUniformSampler_origin,
+    SpatioTemporalSampler,
+)
 from MSTH.utils import Timer
 
 CONSOLE = Console(width=120)
@@ -450,24 +459,31 @@ class SpaceTimeDataManagerConfig(DataManagerConfig):
 
     mask_extend_radius: int = 5
     use_uint8: bool = True
-    use_stratified_pixel_sampler: bool = False
-    static_dynamic_sampling_ratio: float = 1.0
-    use_static_dynamic_ratio_anealing: bool = False
-    ratio_anealing_start: int = 0
-    ratio_anealing_end: int = 20000
-    initial_ratio: float = 50
-    final_ratio: float = 4
+    # use_stratified_pixel_sampler: bool = False
     use_isg_sampler: bool = True
     static_dynamic_sampling_ratio_end: float = 1
     static_ratio_decay_total_steps: int = 6000
     use_all_uniform_sampler: bool = False
 
+    use_stratified_pixel_sampler: bool = False  # deprecated
+    spatial_temporal_sampler: Literal["uniform", "stratified", "st"] = "stratified"
+    use_static_dynamic_ratio_anealing: bool = False
+    static_dynamic_sampling_ratio: float = 1.0
+    ratio_anealing_start: int = 0
+    ratio_anealing_end: int = 20000
+    initial_ratio: float = 50
+    final_ratio: float = 10
+    # n_time_for_dynamic: int = 1  # parameters for spatial_temporal sampler, 1 is equal to stratified sampler
+    n_time_for_dynamic: Callable[
+        [int], float
+    ] = lambda x: 1  # parameters for spatial_temporal sampler, 1 is equal to stratified sampler
+
 
 class SpaceTimeDataManager(DataManager):
     train_dataset: Union[VideoDatasetAllCached, VideoDatasetAllCachedUint8]
     eval_dataset: Union[VideoDatasetAllCached, VideoDatasetAllCachedUint8]
     train_dataparser_outputs: VideoDataParserOutputs
-    train_pixel_sampler: Union[PixelTimeUniformSampler, PixelTimeSampler]
+    train_pixel_sampler: Union[PixelTimeUniformSampler, PixelTimeSampler, SpatioTemporalSampler]
     eval_pixel_sampler: Union[PixelTimeUniformSampler, PixelTimeSampler]
 
     def __init__(
@@ -506,7 +522,10 @@ class SpaceTimeDataManager(DataManager):
             )
         else:
             return VideoDatasetAllCachedUint8(
-                self.train_dataparser_outputs, self.config.camera_res_scale_factor, self.config.mask_extend_radius
+                self.train_dataparser_outputs,
+                self.config.camera_res_scale_factor,
+                self.config.mask_extend_radius,
+                precomputed_mask_path=os.path.join(self.dataparser.config.data, "masks.pt"),
             )
 
     def create_eval_dataset(self):
@@ -530,14 +549,35 @@ class SpaceTimeDataManager(DataManager):
         # sampler_args = {"dataset": self.train_dataset, "num_rays_per_batch": self.config.train_num_rays_per_batch}
         # sampler_args.update(self.config.sampler_extra_args)
         # self.train_pixel_sampler = sampler_cls(**sampler_args)
-        if not self.config.use_stratified_pixel_sampler:
+        # if not self.config.use_stratified_pixel_sampler:
+        if self.config.spatial_temporal_sampler == "uniform":
             if not self.config.use_all_uniform_sampler:
-                self.train_pixel_sampler = PixelTimeUniformSampler(self.train_dataset, self.config.train_num_rays_per_batch)
+                self.train_pixel_sampler = PixelTimeUniformSampler(
+                    self.train_dataset, self.config.train_num_rays_per_batch
+                )
             else:
-                self.train_pixel_sampler = PixelTimeUniformSampler_origin(self.train_dataset, self.config.train_num_rays_per_batch)
-            
-        else:
-            self.train_pixel_sampler = PixelTimeSampler(self.train_dataset, self.config.train_num_rays_per_batch, static_dynamic_ratio=self.config.static_dynamic_sampling_ratio, static_dynamic_ratio_end=self.config.static_dynamic_sampling_ratio_end, total_steps=self.config.static_ratio_decay_total_steps)
+                self.train_pixel_sampler = PixelTimeUniformSampler_origin(
+                    self.train_dataset, self.config.train_num_rays_per_batch
+                )
+
+        elif self.config.spatial_temporal_sampler == "stratified":
+            self.train_pixel_sampler = PixelTimeSampler(
+                self.train_dataset,
+                self.config.train_num_rays_per_batch,
+                static_dynamic_ratio=self.config.static_dynamic_sampling_ratio,
+                static_dynamic_ratio_end=self.config.static_dynamic_sampling_ratio_end,
+                total_steps=self.config.static_ratio_decay_total_steps,
+            )
+        elif self.config.spatial_temporal_sampler == "st":
+            self.train_pixel_sampler = SpatioTemporalSampler(
+                self.train_dataset,
+                self.config.train_num_rays_per_batch,
+                static_dynamic_ratio=self.config.static_dynamic_sampling_ratio,
+                static_dynamic_ratio_end=self.config.static_dynamic_sampling_ratio_end,
+                total_steps=self.config.static_ratio_decay_total_steps,
+                n_time_for_dynamic=self.config.n_time_for_dynamic,
+            )
+
         self.train_camera_optimizer = self.config.camera_optimizer.setup(
             num_cameras=self.train_dataset.cameras.size, device=self.device
         )
diff --git a/MSTH/gridencoder/__init__.py b/MSTH/gridencoder/__init__.py
index f1476ce..e91ec8a 100644
--- a/MSTH/gridencoder/__init__.py
+++ b/MSTH/gridencoder/__init__.py
@@ -1 +1,2 @@
-from .grid import GridEncoder
\ No newline at end of file
+from .grid import GridEncoder
+from .stgrid import SpatialTemporalGridEncoder
diff --git a/MSTH/gridencoder/grid.py b/MSTH/gridencoder/grid.py
index 95003eb..499576c 100644
--- a/MSTH/gridencoder/grid.py
+++ b/MSTH/gridencoder/grid.py
@@ -21,6 +21,8 @@ _gridtype_to_id = {
 _interp_to_id = {
     "linear": 0,
     "smoothstep": 1,
+    "last_nearest": 2,
+    "all_nearest": 3,
 }
 
 
@@ -182,9 +184,12 @@ class GridEncoder(nn.Module):
         interpolation="linear",
         specific_resolution_for_each_level=None,
         std=1e-4,
+        mean=0.0,
     ):
         super().__init__()
 
+        print("=" * 100)
+        print(interpolation)
         # the finest resolution desired at the last level, if provided, overridee per_level_scale
         is_rect = isinstance(base_resolution, (list, tuple))
         if is_rect:
@@ -248,10 +253,11 @@ class GridEncoder(nn.Module):
 
         self.is_rect = is_rect
         self.std = std
+        self.mean = mean
         self.reset_parameters()
 
     def get_mask_loss(self):
-        return (self.embeddings.sigmoid() * (1 - self.embeddings.sigmoid())).mean()
+        return (1 - self.embeddings.sigmoid()).mean()
 
     @torch.no_grad()
     def upsample(self, resolution=None):
@@ -290,7 +296,7 @@ class GridEncoder(nn.Module):
 
     def reset_parameters(self):
         # std = 1e-4
-        self.embeddings.data.uniform_(-self.std, self.std)
+        self.embeddings.data.uniform_(-self.std + self.mean, self.std + self.mean)
 
     def __repr__(self):
         return f"GridEncoder: input_dim={self.input_dim} num_levels={self.num_levels} level_dim={self.level_dim} resolution={self.base_resolution} -> {int(round(self.base_resolution * self.per_level_scale ** (self.num_levels - 1)))} per_level_scale={self.per_level_scale:.4f} params={tuple(self.embeddings.shape)} gridtype={self.gridtype} align_corners={self.align_corners} interpolation={self.interpolation}"
diff --git a/MSTH/gridencoder/setup.py b/MSTH/gridencoder/setup.py
index 714bf1c..648475a 100644
--- a/MSTH/gridencoder/setup.py
+++ b/MSTH/gridencoder/setup.py
@@ -5,6 +5,7 @@ from torch.utils.cpp_extension import BuildExtension, CUDAExtension
 _src_path = os.path.dirname(os.path.abspath(__file__))
 
 nvcc_flags = [
+    '-w',
     '-O3', '-std=c++14',
     '-U__CUDA_NO_HALF_OPERATORS__', '-U__CUDA_NO_HALF_CONVERSIONS__', '-U__CUDA_NO_HALF2_OPERATORS__',
 ]
@@ -47,4 +48,4 @@ setup(
     cmdclass={
         'build_ext': BuildExtension,
     }
-)
\ No newline at end of file
+)
diff --git a/MSTH/gridencoder/src/bindings.cpp b/MSTH/gridencoder/src/bindings.cpp
index 2de3b5a..ccf8e53 100644
--- a/MSTH/gridencoder/src/bindings.cpp
+++ b/MSTH/gridencoder/src/bindings.cpp
@@ -11,4 +11,6 @@ PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
     m.def("rect_grid_encode_forward", &rect_grid_encode_forward, "rect_grid_encode_forward (CUDA)");
     m.def("rect_grid_encode_backward", &rect_grid_encode_backward, "rect_grid_encode_backward (CUDA)");
     m.def("rect_grad_total_variation", &rect_grad_total_variation, "rect_grad_total_variation (CUDA)");
+    m.def("stgrid_encode_forward", &stgrid_encode_forward, "stgrid_encode_forward (CUDA)");
+    m.def("stgrid_encode_backward", &stgrid_encode_backward, "stgrid_encode_backward (CUDA)");
 }
\ No newline at end of file
diff --git a/MSTH/gridencoder/src/gridencoder.cu b/MSTH/gridencoder/src/gridencoder.cu
index f0a563a..51be24b 100644
--- a/MSTH/gridencoder/src/gridencoder.cu
+++ b/MSTH/gridencoder/src/gridencoder.cu
@@ -1065,53 +1065,225 @@ __global__ void kernel_grid_rect(
     for (uint32_t ch = 0; ch < C; ch++) {
         outputs[ch] = results[ch]; 
     }
+}
+
+template <typename scalar_t, uint32_t D, uint32_t C>
+__global__ void kernel_grid_rect_last_nearest(
+    const float * __restrict__ inputs, 
+    const scalar_t * __restrict__ grid, 
+    const int * __restrict__ offsets, 
+    scalar_t * __restrict__ outputs, 
+    const uint32_t B, const uint32_t L, const float *S, const int *H,
+    scalar_t * __restrict__ dy_dx,
+    const uint32_t gridtype,
+    const bool align_corners,
+    const uint32_t interp
+)
+{
+    const uint32_t b = blockIdx.x * blockDim.x + threadIdx.x;
+    
+    if (b >= B) return;
+
+    const uint32_t level = blockIdx.y;
+    
+    // locate
+    grid += (uint32_t)offsets[level] * C;
+    inputs += b * D;
+    outputs += level * B * C + b * C;
+
+    // check input range (should be in [0, 1])
+    bool flag_oob = false;
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) {
+        if (inputs[d] < 0 || inputs[d] > 1) {
+            flag_oob = true;
+        }
+    }
+
+    // if input out of bound, just set output to 0
+    if (flag_oob) {
+        #pragma unroll
+        for (uint32_t ch = 0; ch < C; ch++) {
+            outputs[ch] = 0; 
+        }
+        if (dy_dx) {
+            dy_dx += b * D * L * C + level * D * C; // B L D C
+            #pragma unroll
+            for (uint32_t d = 0; d < D; d++) {
+                #pragma unroll
+                for (uint32_t ch = 0; ch < C; ch++) {
+                    dy_dx[d * C + ch] = 0; 
+                }       
+            }
+        }
+        return;
+    }
+
+    const uint32_t hashmap_size = offsets[level + 1] - offsets[level];
+    // const float scale = exp2f(level * S) * H - 1.0f;
+    // const uint32_t resolution = (uint32_t)ceil(scale) + 1;
+    float scale[D];
+    uint32_t resolution[D];
+
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) 
+    {
+        scale[d] = exp2f(level * S[d]) * H[d] - 1.0f; 
+        resolution[d] = (uint32_t)ceil(scale[d]) + 1;
+    }
+
+    float pos[D];
+    uint32_t pos_grid[D];
+
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) {
+        pos[d] = inputs[d] * scale[d] + (align_corners ? 0.0f : 0.5f);
+        pos_grid[d] = floorf(pos[d]);
+        pos[d] -= (float)pos_grid[d];
+    }
+
+    scalar_t results[C] = {0};
+
+    #pragma unroll
+    for (uint32_t idx = 0; idx < (1 << (D-1)); idx++) {
+        float w = 1;
+        uint32_t pos_grid_local[D];
+        // pos_grid_local[D-1] = pos[D-1] < 0.5 ? pos_grid[D-1]: pos_grid[D-1] + 1;
+        pos_grid_local[D-1] = pos_grid[D-1] + rintf(pos[D-1]);
+
+        #pragma unroll
+        for (uint32_t d = 0; d < D-1; d++) {
+            if ((idx & (1 << d)) == 0) {
+                w *= 1 - pos[d];
+                pos_grid_local[d] = pos_grid[d];
+            } else {
+                w *= pos[d];
+                pos_grid_local[d] = pos_grid[d] + 1;
+            }
+        }
+
+        uint32_t index = get_grid_index_rect<D, C>(gridtype, align_corners, 0, hashmap_size, resolution, pos_grid_local);
+
+        // writing to register (fast)
+        #pragma unroll
+        for (uint32_t ch = 0; ch < C; ch++) {
+            results[ch] += w * grid[index + ch];
+        }
+    }
+
+    #pragma unroll
+    for (uint32_t ch = 0; ch < C; ch++) {
+        outputs[ch] = results[ch]; 
+    }
+
+   
+}
+
+template <typename scalar_t, uint32_t D, uint32_t C>
+__global__ void kernel_grid_rect_all_nearest(
+    const float * __restrict__ inputs, 
+    const scalar_t * __restrict__ grid, 
+    const int * __restrict__ offsets, 
+    scalar_t * __restrict__ outputs, 
+    const uint32_t B, const uint32_t L, const float *S, const int *H,
+    scalar_t * __restrict__ dy_dx,
+    const uint32_t gridtype,
+    const bool align_corners,
+    const uint32_t interp
+)
+{
+    const uint32_t b = blockIdx.x * blockDim.x + threadIdx.x;
+    
+    if (b >= B) return;
+
+    const uint32_t level = blockIdx.y;
+    
+    // locate
+    grid += (uint32_t)offsets[level] * C;
+    inputs += b * D;
+    outputs += level * B * C + b * C;
+
+    // check input range (should be in [0, 1])
+    bool flag_oob = false;
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) {
+        if (inputs[d] < 0 || inputs[d] > 1) {
+            flag_oob = true;
+        }
+    }
 
-    // TODO: add support for input gradient
+    // if input out of bound, just set output to 0
+    if (flag_oob) {
+        #pragma unroll
+        for (uint32_t ch = 0; ch < C; ch++) {
+            outputs[ch] = 0; 
+        }
+        if (dy_dx) {
+            dy_dx += b * D * L * C + level * D * C; // B L D C
+            #pragma unroll
+            for (uint32_t d = 0; d < D; d++) {
+                #pragma unroll
+                for (uint32_t ch = 0; ch < C; ch++) {
+                    dy_dx[d * C + ch] = 0; 
+                }       
+            }
+        }
+        return;
+    }
 
-    // if (dy_dx) {
+    const uint32_t hashmap_size = offsets[level + 1] - offsets[level];
+    // const float scale = exp2f(level * S) * H - 1.0f;
+    // const uint32_t resolution = (uint32_t)ceil(scale) + 1;
+    float scale[D];
+    uint32_t resolution[D];
 
-    //     dy_dx += b * D * L * C + level * D * C; // B L D C
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) 
+    {
+        scale[d] = exp2f(level * S[d]) * H[d] - 1.0f; 
+        resolution[d] = (uint32_t)ceil(scale[d]) + 1;
+    }
 
-    //     #pragma unroll
-    //     for (uint32_t gd = 0; gd < D; gd++) {
+    float pos[D];
+    float pos_deriv[D]; 
+    uint32_t pos_grid[D];
 
-    //         scalar_t results_grad[C] = {0};
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) {
+        pos[d] = inputs[d] * scale[d] + (align_corners ? 0.0f : 0.5f);
+        pos_grid[d] = floorf(pos[d]);
+        pos[d] -= (float)pos_grid[d];
+        // smoothstep instead of linear
+        if (interp == 1) {
+            pos_deriv[d] = smoothstep_derivative(pos[d]);
+            pos[d] = smoothstep(pos[d]);
+        } else {
+            pos_deriv[d] = 1.0f; // linear deriv is default to 1
+        }
 
-    //         #pragma unroll
-    //         for (uint32_t idx = 0; idx < (1 << (D - 1)); idx++) {
-    //             float w = scale;
-    //             uint32_t pos_grid_local[D];
+    }
 
-    //             #pragma unroll
-    //             for (uint32_t nd = 0; nd < D - 1; nd++) {
-    //                 const uint32_t d = (nd >= gd) ? (nd + 1) : nd;
+    scalar_t results[C] = {0};
 
-    //                 if ((idx & (1 << nd)) == 0) {
-    //                     w *= 1 - pos[d];
-    //                     pos_grid_local[d] = pos_grid[d];
-    //                 } else {
-    //                     w *= pos[d];
-    //                     pos_grid_local[d] = pos_grid[d] + 1;
-    //                 }
-    //             }
+    uint32_t pos_grid_local[D];
+    #pragma unroll
+    for(uint32_t d = 0; d < D; ++d){
+        pos_grid_local[d] = rintf(pos[d]) + pos_grid[d];
+        // pos_grid_local[d] = pos[d] < 0.5 ? pos_grid[d]: pos_grid[d] + 1;
+    }
+    uint32_t index = get_grid_index_rect<D, C>(gridtype, align_corners, 0, hashmap_size, resolution, pos_grid_local);
 
-    //             pos_grid_local[gd] = pos_grid[gd];
-    //             uint32_t index_left = get_grid_index_rect<D, C>(gridtype, align_corners, 0, hashmap_size, resolution, pos_grid_local);
-    //             pos_grid_local[gd] = pos_grid[gd] + 1;
-    //             uint32_t index_right = get_grid_index_rect<D, C>(gridtype, align_corners, 0, hashmap_size, resolution, pos_grid_local);
+    #pragma unroll
+    for (uint32_t ch = 0; ch < C; ch++) {
+        results[ch] += 1.0 * grid[index + ch];
+    }
 
-    //             #pragma unroll
-    //             for (uint32_t ch = 0; ch < C; ch++) {
-    //                 results_grad[ch] += w * (grid[index_right + ch] - grid[index_left + ch]) * pos_deriv[gd];
-    //             }
-    //         }
+    #pragma unroll
+    for (uint32_t ch = 0; ch < C; ch++) {
+        outputs[ch] = results[ch]; 
+    }
 
-    //         #pragma unroll
-    //         for (uint32_t ch = 0; ch < C; ch++) {
-    //             dy_dx[gd * C + ch] = results_grad[ch];
-    //         }
-    //     }
-    // }
+   
 }
 
 template <typename scalar_t, uint32_t D, uint32_t C, uint32_t N_C>
@@ -1155,29 +1327,989 @@ __global__ void kernel_grid_backward_rect(
         if (inputs[d] < 0 || inputs[d] > 1) {
             return; // grad is init as 0, so we simply return.
         }
-    }
+    }
+
+    float pos[D];
+    uint32_t pos_grid[D];
+
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) {
+        pos[d] = inputs[d] * scale[d] + (align_corners ? 0.0f : 0.5f);
+        pos_grid[d] = floorf(pos[d]);
+        pos[d] -= (float)pos_grid[d];
+        // smoothstep instead of linear
+        if (interp == 1) {
+            pos[d] = smoothstep(pos[d]);
+        }
+    }
+
+    scalar_t grad_cur[N_C] = {0}; // fetch to register
+    #pragma unroll
+    for (uint32_t c = 0; c < N_C; c++) {
+        grad_cur[c] = grad[c];
+    }
+
+    // interpolate
+    #pragma unroll
+    for (uint32_t idx = 0; idx < (1 << D); idx++) {
+        float w = 1;
+        uint32_t pos_grid_local[D];
+
+        #pragma unroll
+        for (uint32_t d = 0; d < D; d++) {
+            if ((idx & (1 << d)) == 0) {
+                w *= 1 - pos[d];
+                pos_grid_local[d] = pos_grid[d];
+            } else {
+                w *= pos[d];
+                pos_grid_local[d] = pos_grid[d] + 1;
+            }
+        }
+
+        uint32_t index = get_grid_index_rect<D, C>(gridtype, align_corners, ch, hashmap_size, resolution, pos_grid_local);
+
+        // atomicAdd for __half is slow (especially for large values), so we use __half2 if N_C % 2 == 0
+        // TODO: use float which is better than __half, if N_C % 2 != 0
+        if (std::is_same<scalar_t, at::Half>::value && N_C % 2 == 0) {
+            #pragma unroll
+            for (uint32_t c = 0; c < N_C; c += 2) {
+                // process two __half at once (by interpreting as a __half2)
+                __half2 v = {(__half)(w * grad_cur[c]), (__half)(w * grad_cur[c + 1])};
+                atomicAdd((__half2*)&grad_grid[index + c], v);
+            }
+        // float, or __half when N_C % 2 != 0 (which means C == 1)
+        } else {
+            #pragma unroll
+            for (uint32_t c = 0; c < N_C; c++) {
+                atomicAdd(&grad_grid[index + c], w * grad_cur[c]);
+            }
+        }
+    }
+}
+
+template <typename scalar_t, uint32_t D, uint32_t C, uint32_t N_C>
+__global__ void kernel_grid_backward_rect_last_nearest(
+    const scalar_t * __restrict__ grad,
+    const float * __restrict__ inputs, 
+    const scalar_t * __restrict__ grid, 
+    const int * __restrict__ offsets, 
+    scalar_t * __restrict__ grad_grid, 
+    const uint32_t B, const uint32_t L, const float *S, const int *H,
+    const uint32_t gridtype,
+    const bool align_corners,
+    const uint32_t interp
+)
+{
+    const uint32_t b = (blockIdx.x * blockDim.x + threadIdx.x) * N_C / C;
+    if (b >= B) return;
+
+    const uint32_t level = blockIdx.y;
+    const uint32_t ch = (blockIdx.x * blockDim.x + threadIdx.x) * N_C - b * C;
+
+    // locate
+    grad_grid += offsets[level] * C;
+    inputs += b * D;
+    grad += level * B * C + b * C + ch; // L, B, C
+
+    const uint32_t hashmap_size = offsets[level + 1] - offsets[level];
+    float scale[D];
+    uint32_t resolution[D];
+
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) 
+    {
+        scale[d] = exp2f(level * S[d]) * H[d] - 1.0f; 
+        resolution[d] = (uint32_t)ceil(scale[d]) + 1;
+    }
+
+    // check input range (should be in [0, 1])
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) {
+        if (inputs[d] < 0 || inputs[d] > 1) {
+            return; // grad is init as 0, so we simply return.
+        }
+    }
+
+    float pos[D];
+    uint32_t pos_grid[D];
+
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) {
+        pos[d] = inputs[d] * scale[d] + (align_corners ? 0.0f : 0.5f);
+        pos_grid[d] = floorf(pos[d]);
+        pos[d] -= (float)pos_grid[d];
+        // smoothstep instead of linear
+        if (interp == 1) {
+            pos[d] = smoothstep(pos[d]);
+        }
+    }
+
+    scalar_t grad_cur[N_C] = {0}; // fetch to register
+    #pragma unroll
+    for (uint32_t c = 0; c < N_C; c++) {
+        grad_cur[c] = grad[c];
+    }
+
+    // interpolate
+    
+    #pragma unroll
+    for (uint32_t idx = 0; idx < (1 << (D-1)); idx++) {
+        float w = 1;
+        uint32_t pos_grid_local[D];
+        // pos_grid_local[D-1] = pos_grid[D-1];
+        // pos_grid_local[D-1] = pos[D-1] < 0.5 ? pos_grid[D-1]: pos_grid[D-1] + 1;
+        pos_grid_local[D-1] = rintf(pos[D-1]) + pos_grid[D-1];
+
+        #pragma unroll
+        for (uint32_t d = 0; d < (D-1); d++) {
+            if ((idx & (1 << d)) == 0) {
+                w *= 1 - pos[d];
+                pos_grid_local[d] = pos_grid[d];
+            } else {
+                w *= pos[d];
+                pos_grid_local[d] = pos_grid[d] + 1;
+            }
+        }
+
+        uint32_t index = get_grid_index_rect<D, C>(gridtype, align_corners, ch, hashmap_size, resolution, pos_grid_local);
+
+        // atomicAdd for __half is slow (especially for large values), so we use __half2 if N_C % 2 == 0
+        // TODO: use float which is better than __half, if N_C % 2 != 0
+        if (std::is_same<scalar_t, at::Half>::value && N_C % 2 == 0) {
+            #pragma unroll
+            for (uint32_t c = 0; c < N_C; c += 2) {
+                // process two __half at once (by interpreting as a __half2)
+                __half2 v = {(__half)(w * grad_cur[c]), (__half)(w * grad_cur[c + 1])};
+                atomicAdd((__half2*)&grad_grid[index + c], v);
+            }
+        // float, or __half when N_C % 2 != 0 (which means C == 1)
+        } else {
+            #pragma unroll
+            for (uint32_t c = 0; c < N_C; c++) {
+                atomicAdd(&grad_grid[index + c], w * grad_cur[c]);
+            }
+        }
+    }
+}
+
+template <typename scalar_t, uint32_t D, uint32_t C, uint32_t N_C>
+__global__ void kernel_grid_backward_rect_all_nearest(
+    const scalar_t * __restrict__ grad,
+    const float * __restrict__ inputs, 
+    const scalar_t * __restrict__ grid, 
+    const int * __restrict__ offsets, 
+    scalar_t * __restrict__ grad_grid, 
+    const uint32_t B, const uint32_t L, const float *S, const int *H,
+    const uint32_t gridtype,
+    const bool align_corners,
+    const uint32_t interp
+)
+{
+    const uint32_t b = (blockIdx.x * blockDim.x + threadIdx.x) * N_C / C;
+    if (b >= B) return;
+
+    const uint32_t level = blockIdx.y;
+    const uint32_t ch = (blockIdx.x * blockDim.x + threadIdx.x) * N_C - b * C;
+
+    // locate
+    grad_grid += offsets[level] * C;
+    inputs += b * D;
+    grad += level * B * C + b * C + ch; // L, B, C
+
+    const uint32_t hashmap_size = offsets[level + 1] - offsets[level];
+    float scale[D];
+    uint32_t resolution[D];
+
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) 
+    {
+        scale[d] = exp2f(level * S[d]) * H[d] - 1.0f; 
+        resolution[d] = (uint32_t)ceil(scale[d]) + 1;
+    }
+
+    // check input range (should be in [0, 1])
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) {
+        if (inputs[d] < 0 || inputs[d] > 1) {
+            return; // grad is init as 0, so we simply return.
+        }
+    }
+
+    float pos[D];
+    uint32_t pos_grid[D];
+
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) {
+        pos[d] = inputs[d] * scale[d] + (align_corners ? 0.0f : 0.5f);
+        pos_grid[d] = floorf(pos[d]);
+        pos[d] -= (float)pos_grid[d];
+        // smoothstep instead of linear
+        if (interp == 1) {
+            pos[d] = smoothstep(pos[d]);
+        }
+    }
+
+    scalar_t grad_cur[N_C] = {0}; // fetch to register
+    #pragma unroll
+    for (uint32_t c = 0; c < N_C; c++) {
+        grad_cur[c] = grad[c];
+    }
+
+    // interpolate
+    float w = 1;
+    uint32_t pos_grid_local[D];
+    #pragma unroll
+    for(uint32_t d = 0; d < D; ++d){
+        // pos_grid_local[d] = pos[d] < 0.5 ? pos_grid[d]: pos_grid[d] + 1;
+        pos_grid_local[d] = rintf(pos[d]) + pos_grid[d];
+    }
+    uint32_t index = get_grid_index_rect<D, C>(gridtype, align_corners, 0, hashmap_size, resolution, pos_grid_local);
+
+    if (std::is_same<scalar_t, at::Half>::value && N_C % 2 == 0) {
+            #pragma unroll
+            for (uint32_t c = 0; c < N_C; c += 2) {
+                // process two __half at once (by interpreting as a __half2)
+                __half2 v = {(__half)(w * grad_cur[c]), (__half)(w * grad_cur[c + 1])};
+                atomicAdd((__half2*)&grad_grid[index + c], v);
+            }
+        // float, or __half when N_C % 2 != 0 (which means C == 1)
+    } else {
+            #pragma unroll
+            for (uint32_t c = 0; c < N_C; c++) {
+                atomicAdd(&grad_grid[index + c], w * grad_cur[c]);
+            }
+    }
+}
+
+template <typename scalar_t, uint32_t D>
+void kernel_grid_rect_wrapper(const float *inputs, const scalar_t *embeddings, const int *offsets, scalar_t *outputs, const uint32_t B, const uint32_t C, const uint32_t L, const float *S, const int *H, scalar_t *dy_dx, const uint32_t gridtype, const bool align_corners, const uint32_t interp) {
+    static constexpr uint32_t N_THREAD = 512;
+    const dim3 blocks_hashgrid = { div_round_up(B, N_THREAD), L, 1 };
+    if(interp<2){
+        switch (C) {
+            case 1: kernel_grid_rect<scalar_t, D, 1><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+            case 2: kernel_grid_rect<scalar_t, D, 2><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+            case 4: kernel_grid_rect<scalar_t, D, 4><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+            case 8: kernel_grid_rect<scalar_t, D, 8><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+            default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
+        }
+    }
+    if(interp==2){//last nearest
+        switch (C) {
+            case 1: kernel_grid_rect_last_nearest<scalar_t, D, 1><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+            case 2: kernel_grid_rect_last_nearest<scalar_t, D, 2><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+            case 4: kernel_grid_rect_last_nearest<scalar_t, D, 4><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+            case 8: kernel_grid_rect_last_nearest<scalar_t, D, 8><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+            default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
+        }
+    }
+    if(interp==3){//all nearest
+        switch (C) {
+            case 1: kernel_grid_rect_all_nearest<scalar_t, D, 1><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+            case 2: kernel_grid_rect_all_nearest<scalar_t, D, 2><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+            case 4: kernel_grid_rect_all_nearest<scalar_t, D, 4><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+            case 8: kernel_grid_rect_all_nearest<scalar_t, D, 8><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+            default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
+        }
+    }
+}
+
+template <typename scalar_t>
+void rect_grid_encode_forward_cuda(const float *inputs, const scalar_t *embeddings, const int *offsets, scalar_t *outputs, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const float *S, const int *H, scalar_t *dy_dx, const uint32_t gridtype, const bool align_corners, const uint32_t interp) {
+    switch (D) {
+        case 2: kernel_grid_rect_wrapper<scalar_t, 2>(inputs, embeddings, offsets, outputs, B, C, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+        case 3: kernel_grid_rect_wrapper<scalar_t, 3>(inputs, embeddings, offsets, outputs, B, C, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+        case 4: kernel_grid_rect_wrapper<scalar_t, 4>(inputs, embeddings, offsets, outputs, B, C, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+        case 5: kernel_grid_rect_wrapper<scalar_t, 5>(inputs, embeddings, offsets, outputs, B, C, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+        default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
+    }   
+}
+
+void rect_grid_encode_forward(const at::Tensor inputs, const at::Tensor embeddings, const at::Tensor offsets, at::Tensor outputs, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const at::Tensor S, const at::Tensor H, at::optional<at::Tensor> dy_dx, const uint32_t gridtype, const bool align_corners, const uint32_t interp) {
+    CHECK_CUDA(inputs);
+    CHECK_CUDA(embeddings);
+    CHECK_CUDA(offsets);
+    CHECK_CUDA(outputs);
+    CHECK_CUDA(S);
+    CHECK_CUDA(H);
+    // CHECK_CUDA(dy_dx);
+    
+    CHECK_CONTIGUOUS(inputs);
+    CHECK_CONTIGUOUS(embeddings);
+    CHECK_CONTIGUOUS(offsets);
+    CHECK_CONTIGUOUS(outputs);
+    CHECK_CONTIGUOUS(S);
+    CHECK_CONTIGUOUS(H);
+    // CHECK_CONTIGUOUS(dy_dx);
+
+    CHECK_IS_FLOATING(inputs);
+    CHECK_IS_FLOATING(embeddings);
+    CHECK_IS_INT(offsets);
+    CHECK_IS_FLOATING(outputs);
+    CHECK_IS_INT(H);
+    CHECK_IS_FLOATING(S);
+    // CHECK_IS_FLOATING(dy_dx);
+
+    AT_DISPATCH_FLOATING_TYPES_AND_HALF(
+    embeddings.scalar_type(), "rect_grid_encode_forward", ([&] {
+        rect_grid_encode_forward_cuda<scalar_t>(inputs.data_ptr<float>(), embeddings.data_ptr<scalar_t>(), offsets.data_ptr<int>(), outputs.data_ptr<scalar_t>(), B, D, C, L, S.data_ptr<float>(), H.data_ptr<int>(), dy_dx.has_value() ? dy_dx.value().data_ptr<scalar_t>() : nullptr, gridtype, align_corners, interp);
+    }));
+}
+
+template <typename scalar_t, uint32_t D>
+void kernel_grid_rect_backward_wrapper(const scalar_t *grad, const float *inputs, const scalar_t *embeddings, const int *offsets, scalar_t *grad_embeddings, const uint32_t B, const uint32_t C, const uint32_t L, const float *S, const int *H, scalar_t *dy_dx, scalar_t *grad_inputs, const uint32_t gridtype, const bool align_corners, const uint32_t interp) {
+    static constexpr uint32_t N_THREAD = 256;
+    const uint32_t N_C = std::min(2u, C); // n_features_per_thread
+    const dim3 blocks_hashgrid = { div_round_up(B * C / N_C, N_THREAD), L, 1 };
+    if(interp < 2){
+        switch (C) {
+            case 1: 
+                kernel_grid_backward_rect<scalar_t, D, 1, 1><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, embeddings, offsets, grad_embeddings, B, L, S, H, gridtype, align_corners, interp); 
+                if (dy_dx) kernel_input_backward<scalar_t, D, 1><<<div_round_up(B * D, N_THREAD), N_THREAD>>>(grad, dy_dx, grad_inputs, B, L);
+                break;
+            case 2: 
+                kernel_grid_backward_rect<scalar_t, D, 2, 2><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, embeddings, offsets, grad_embeddings, B, L, S, H, gridtype, align_corners, interp);
+                if (dy_dx) kernel_input_backward<scalar_t, D, 2><<<div_round_up(B * D, N_THREAD), N_THREAD>>>(grad, dy_dx, grad_inputs, B, L);
+                break;
+            case 4: 
+                kernel_grid_backward_rect<scalar_t, D, 4, 2><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, embeddings, offsets, grad_embeddings, B, L, S, H, gridtype, align_corners, interp);
+                if (dy_dx) kernel_input_backward<scalar_t, D, 4><<<div_round_up(B * D, N_THREAD), N_THREAD>>>(grad, dy_dx, grad_inputs, B, L);
+                break;
+            case 8: 
+                kernel_grid_backward_rect<scalar_t, D, 8, 2><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, embeddings, offsets, grad_embeddings, B, L, S, H, gridtype, align_corners, interp);
+                if (dy_dx) kernel_input_backward<scalar_t, D, 8><<<div_round_up(B * D, N_THREAD), N_THREAD>>>(grad, dy_dx, grad_inputs, B, L);
+                break;
+            default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
+        }
+    }
+    if(interp==2){
+        switch (C) {
+            case 1: 
+                kernel_grid_backward_rect_last_nearest<scalar_t, D, 1, 1><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, embeddings, offsets, grad_embeddings, B, L, S, H, gridtype, align_corners, interp); 
+                if (dy_dx) kernel_input_backward<scalar_t, D, 1><<<div_round_up(B * D, N_THREAD), N_THREAD>>>(grad, dy_dx, grad_inputs, B, L);
+                break;
+            case 2: 
+                kernel_grid_backward_rect_last_nearest<scalar_t, D, 2, 2><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, embeddings, offsets, grad_embeddings, B, L, S, H, gridtype, align_corners, interp);
+                if (dy_dx) kernel_input_backward<scalar_t, D, 2><<<div_round_up(B * D, N_THREAD), N_THREAD>>>(grad, dy_dx, grad_inputs, B, L);
+                break;
+            case 4: 
+                kernel_grid_backward_rect_last_nearest<scalar_t, D, 4, 2><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, embeddings, offsets, grad_embeddings, B, L, S, H, gridtype, align_corners, interp);
+                if (dy_dx) kernel_input_backward<scalar_t, D, 4><<<div_round_up(B * D, N_THREAD), N_THREAD>>>(grad, dy_dx, grad_inputs, B, L);
+                break;
+            case 8: 
+                kernel_grid_backward_rect_last_nearest<scalar_t, D, 8, 2><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, embeddings, offsets, grad_embeddings, B, L, S, H, gridtype, align_corners, interp);
+                if (dy_dx) kernel_input_backward<scalar_t, D, 8><<<div_round_up(B * D, N_THREAD), N_THREAD>>>(grad, dy_dx, grad_inputs, B, L);
+                break;
+            default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
+        }
+    }
+    if(interp==3){
+        switch (C) {
+            case 1: 
+                kernel_grid_backward_rect_all_nearest<scalar_t, D, 1, 1><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, embeddings, offsets, grad_embeddings, B, L, S, H, gridtype, align_corners, interp); 
+                if (dy_dx) kernel_input_backward<scalar_t, D, 1><<<div_round_up(B * D, N_THREAD), N_THREAD>>>(grad, dy_dx, grad_inputs, B, L);
+                break;
+            case 2: 
+                kernel_grid_backward_rect_all_nearest<scalar_t, D, 2, 2><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, embeddings, offsets, grad_embeddings, B, L, S, H, gridtype, align_corners, interp);
+                if (dy_dx) kernel_input_backward<scalar_t, D, 2><<<div_round_up(B * D, N_THREAD), N_THREAD>>>(grad, dy_dx, grad_inputs, B, L);
+                break;
+            case 4: 
+                kernel_grid_backward_rect_all_nearest<scalar_t, D, 4, 2><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, embeddings, offsets, grad_embeddings, B, L, S, H, gridtype, align_corners, interp);
+                if (dy_dx) kernel_input_backward<scalar_t, D, 4><<<div_round_up(B * D, N_THREAD), N_THREAD>>>(grad, dy_dx, grad_inputs, B, L);
+                break;
+            case 8: 
+                kernel_grid_backward_rect_all_nearest<scalar_t, D, 8, 2><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, embeddings, offsets, grad_embeddings, B, L, S, H, gridtype, align_corners, interp);
+                if (dy_dx) kernel_input_backward<scalar_t, D, 8><<<div_round_up(B * D, N_THREAD), N_THREAD>>>(grad, dy_dx, grad_inputs, B, L);
+                break;
+            default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
+        }
+    }
+}
+
+template <typename scalar_t>
+void rect_grid_encode_backward_cuda(const scalar_t *grad, const float *inputs, const scalar_t *embeddings, const int *offsets, scalar_t *grad_embeddings, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const float *S, const int *H, scalar_t *dy_dx, scalar_t *grad_inputs, const uint32_t gridtype, const bool align_corners, const uint32_t interp) {
+    switch (D) {
+        case 2: kernel_grid_rect_backward_wrapper<scalar_t, 2>(grad, inputs, embeddings, offsets, grad_embeddings, B, C, L, S, H, dy_dx, grad_inputs, gridtype, align_corners, interp); break;
+        case 3: kernel_grid_rect_backward_wrapper<scalar_t, 3>(grad, inputs, embeddings, offsets, grad_embeddings, B, C, L, S, H, dy_dx, grad_inputs, gridtype, align_corners, interp); break;
+        case 4: kernel_grid_rect_backward_wrapper<scalar_t, 4>(grad, inputs, embeddings, offsets, grad_embeddings, B, C, L, S, H, dy_dx, grad_inputs, gridtype, align_corners, interp); break;
+        case 5: kernel_grid_rect_backward_wrapper<scalar_t, 5>(grad, inputs, embeddings, offsets, grad_embeddings, B, C, L, S, H, dy_dx, grad_inputs, gridtype, align_corners, interp); break;
+        default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
+    }
+}
+
+void rect_grid_encode_backward(const at::Tensor grad, const at::Tensor inputs, const at::Tensor embeddings, const at::Tensor offsets, at::Tensor grad_embeddings, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const at::Tensor S, const at::Tensor H, const at::optional<at::Tensor> dy_dx, at::optional<at::Tensor> grad_inputs, const uint32_t gridtype, const bool align_corners, const uint32_t interp) {
+    CHECK_CUDA(grad);
+    CHECK_CUDA(inputs);
+    CHECK_CUDA(embeddings);
+    CHECK_CUDA(offsets);
+    CHECK_CUDA(grad_embeddings);
+    CHECK_CUDA(S);
+    CHECK_CUDA(H);
+    // CHECK_CUDA(dy_dx);
+    // CHECK_CUDA(grad_inputs);
+    
+    CHECK_CONTIGUOUS(grad);
+    CHECK_CONTIGUOUS(inputs);
+    CHECK_CONTIGUOUS(embeddings);
+    CHECK_CONTIGUOUS(offsets);
+    CHECK_CONTIGUOUS(grad_embeddings);
+    CHECK_CONTIGUOUS(S);
+    CHECK_CONTIGUOUS(H);
+    // CHECK_CONTIGUOUS(dy_dx);
+    // CHECK_CONTIGUOUS(grad_inputs);
+
+    CHECK_IS_FLOATING(grad);
+    CHECK_IS_FLOATING(inputs);
+    CHECK_IS_FLOATING(embeddings);
+    CHECK_IS_INT(offsets);
+    CHECK_IS_FLOATING(grad_embeddings);
+    CHECK_IS_INT(H);
+    CHECK_IS_FLOATING(S);
+    // CHECK_IS_FLOATING(dy_dx);
+    // CHECK_IS_FLOATING(grad_inputs);
+
+    AT_DISPATCH_FLOATING_TYPES_AND_HALF(
+    grad.scalar_type(), "rect_grid_encode_backward", ([&] {
+        rect_grid_encode_backward_cuda<scalar_t>(grad.data_ptr<scalar_t>(), inputs.data_ptr<float>(), embeddings.data_ptr<scalar_t>(), offsets.data_ptr<int>(), grad_embeddings.data_ptr<scalar_t>(), B, D, C, L, S.data_ptr<float>(), H.data_ptr<int>(), dy_dx.has_value() ? dy_dx.value().data_ptr<scalar_t>() : nullptr, grad_inputs.has_value() ? grad_inputs.value().data_ptr<scalar_t>() : nullptr, gridtype, align_corners, interp);
+    }));
+    
+}
+
+template <typename scalar_t, uint32_t D, uint32_t C>
+__global__ void kernel_rect_grad_tv(
+    const scalar_t * __restrict__ inputs,
+    const scalar_t * __restrict__ grid, 
+    scalar_t * __restrict__ grad, 
+    const int * __restrict__ offsets, 
+    const float weight,
+    const uint32_t B, const uint32_t L, const float *S, const int *H,
+    const uint32_t gridtype,
+    const bool align_corners
+) 
+{
+    const uint32_t b = blockIdx.x * blockDim.x + threadIdx.x;
+    
+    if (b >= B) return;
+
+    const uint32_t level = blockIdx.y;
+
+    grid += (uint32_t)offsets[level] * C;
+    grad += (uint32_t)offsets[level] * C;
+
+    // check input range (should be in [0, 1])
+    bool flag_oob = false;
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) {
+        if (inputs[d] < 0 || inputs[d] > 1) {
+            flag_oob = true;
+        }
+    }
+
+    // if input out of bound, do nothing
+    if (flag_oob) return;
+
+    const uint32_t hashmap_size = offsets[level + 1] - offsets[level];
+    float scale[D];
+    uint32_t resolution[D];
+
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) 
+    {
+        scale[d] = exp2f(level * S[d]) * H[d] - 1.0f; 
+        resolution[d] = (uint32_t)ceil(scale[d]) + 1;
+    }
+    
+    // calculate coordinate
+    float pos[D];
+    uint32_t pos_grid[D]; // [0, resolution]
+
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) {
+        pos[d] = inputs[d] * scale[d] + (align_corners ? 0.0f : 0.5f);
+        pos_grid[d] = floorf(pos[d]);
+        // pos[d] -= (float)pos_grid[d]; // not used
+    }
+
+    //printf("[b=%d, l=%d] pos=(%f, %f)+(%d, %d)\n", b, level, pos[0], pos[1], pos_grid[0], pos_grid[1]);
+
+    // total variation on pos_grid
+    scalar_t results[C] = {0}; // temp results in register
+    scalar_t idelta[C] = {0};
+
+    uint32_t index = get_grid_index_rect<D, C>(gridtype, align_corners, 0, hashmap_size, resolution, pos_grid);
+
+    scalar_t w = weight / (2 * D);
+
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) {
+
+        uint32_t cur_d = pos_grid[d];
+        scalar_t grad_val;
+
+        // right side
+        if (cur_d < resolution[d]) {
+            pos_grid[d] = cur_d + 1;
+            uint32_t index_right = get_grid_index_rect<D, C>(gridtype, align_corners, 0, hashmap_size, resolution, pos_grid);
+
+            #pragma unroll
+            for (uint32_t ch = 0; ch < C; ch++) {
+                // results[ch] += w * clamp(grid[index + ch] - grid[index_right + ch], -1.0f, 1.0f);
+                grad_val = (grid[index + ch] - grid[index_right + ch]);
+                results[ch] += grad_val;
+                idelta[ch] += grad_val * grad_val;
+            }
+        }
+
+        // left side
+        if (cur_d > 0) {
+            pos_grid[d] = cur_d - 1;
+            uint32_t index_left = get_grid_index_rect<D, C>(gridtype, align_corners, 0, hashmap_size, resolution, pos_grid);
+
+            #pragma unroll
+            for (uint32_t ch = 0; ch < C; ch++) {
+                // results[ch] += w * clamp(grid[index + ch] - grid[index_left + ch], -1.0f, 1.0f);
+                grad_val = (grid[index + ch] - grid[index_left + ch]);
+                results[ch] += grad_val;
+                idelta[ch] += grad_val * grad_val;
+            }
+        }
+
+        // reset
+        pos_grid[d] = cur_d;
+    }
+
+    // writing to global memory (slow)
+    #pragma unroll
+    for (uint32_t ch = 0; ch < C; ch++) {
+        // index may collide, so use atomic!
+        atomicAdd(&grad[index + ch], w * results[ch] * rsqrtf(idelta[ch] + 1e-9f));
+    }
+}
+
+template <typename scalar_t, uint32_t D>
+void kernel_rect_grad_tv_wrapper(const scalar_t *inputs, const scalar_t *embeddings, scalar_t *grad, const int *offsets, const float weight, const uint32_t B, const uint32_t C, const uint32_t L, const float *S, const int *H, const uint32_t gridtype, const bool align_corners) {
+    static constexpr uint32_t N_THREAD = 512;
+    const dim3 blocks_hashgrid = { div_round_up(B, N_THREAD), L, 1 };
+    switch (C) {
+        case 1: kernel_rect_grad_tv<scalar_t, D, 1><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, grad, offsets, weight, B, L, S, H, gridtype, align_corners); break;
+        case 2: kernel_rect_grad_tv<scalar_t, D, 2><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, grad, offsets, weight, B, L, S, H, gridtype, align_corners); break;
+        case 4: kernel_rect_grad_tv<scalar_t, D, 4><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, grad, offsets, weight, B, L, S, H, gridtype, align_corners); break;
+        case 8: kernel_rect_grad_tv<scalar_t, D, 8><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, grad, offsets, weight, B, L, S, H, gridtype, align_corners); break;
+        default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
+    }
+}
+
+template <typename scalar_t>
+void rect_grad_total_variation_cuda(const scalar_t *inputs, const scalar_t *embeddings, scalar_t *grad, const int *offsets, const float weight, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const float *S, const int *H, const uint32_t gridtype, const bool align_corners) {
+    switch (D) {
+        case 2: kernel_rect_grad_tv_wrapper<scalar_t, 2>(inputs, embeddings, grad, offsets, weight, B, C, L, S, H, gridtype, align_corners); break;
+        case 3: kernel_rect_grad_tv_wrapper<scalar_t, 3>(inputs, embeddings, grad, offsets, weight, B, C, L, S, H, gridtype, align_corners); break;
+        case 4: kernel_rect_grad_tv_wrapper<scalar_t, 4>(inputs, embeddings, grad, offsets, weight, B, C, L, S, H, gridtype, align_corners); break;
+        case 5: kernel_rect_grad_tv_wrapper<scalar_t, 5>(inputs, embeddings, grad, offsets, weight, B, C, L, S, H, gridtype, align_corners); break;
+        default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
+    }   
+}
+
+void rect_grad_total_variation(const at::Tensor inputs, const at::Tensor embeddings, at::Tensor grad, const at::Tensor offsets, const float weight, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const at::Tensor S, const at::Tensor H, const uint32_t gridtype, const bool align_corners) {
+
+    AT_DISPATCH_FLOATING_TYPES_AND_HALF(
+    embeddings.scalar_type(), "rect_grad_total_variation", ([&] {
+        rect_grad_total_variation_cuda<scalar_t>(inputs.data_ptr<scalar_t>(), embeddings.data_ptr<scalar_t>(), grad.data_ptr<scalar_t>(), offsets.data_ptr<int>(), weight, B, D, C, L, S.data_ptr<float>(), H.data_ptr<int>(), gridtype, align_corners);
+    }));
+}
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+template <typename scalar_t, uint32_t D, uint32_t C>
+__global__ void kernel_stgrid(
+    const float * __restrict__ inputs, 
+    const scalar_t * __restrict__ sgrid, 
+    const scalar_t * __restrict__ tgrid, 
+    const scalar_t * __restrict__ mgrid, 
+    const int * __restrict__ soffsets, 
+    const int * __restrict__ toffsets, 
+    scalar_t * __restrict__ outputs, 
+    scalar_t * __restrict__ tout, 
+    scalar_t * __restrict__ mout, 
+    const uint32_t B, const uint32_t L, const float *S, const int *H,
+    const int *M,
+    scalar_t * __restrict__ dy_dx,
+    const uint32_t gridtype,
+    const bool align_corners,
+    const uint32_t interp
+)
+{
+    const uint32_t b = blockIdx.x * blockDim.x + threadIdx.x;
+    
+    if (b >= B) return;
+
+    const uint32_t level = blockIdx.y;
+    
+    // locate
+    inputs += b * D;
+    outputs += level * B * C + b * C;
+    tout += level * B * C + b * C;
+    mout += b * 1;
+
+    // check input range (should be in [0, 1])
+    bool flag_oob = false;
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) {
+        if (inputs[d] < 0 || inputs[d] > 1) {
+            flag_oob = true;
+        }
+    }
+
+    // if input out of bound, just set output to 0
+    if (flag_oob) {
+        #pragma unroll
+        for (uint32_t ch = 0; ch < C; ch++) {
+            outputs[ch] = 0; 
+        }
+        if (dy_dx) {
+            dy_dx += b * D * L * C + level * D * C; // B L D C
+            #pragma unroll
+            for (uint32_t d = 0; d < D; d++) {
+                #pragma unroll
+                for (uint32_t ch = 0; ch < C; ch++) {
+                    dy_dx[d * C + ch] = 0; 
+                }       
+            }
+        }
+        return;
+    }
+
+    sgrid += (uint32_t)soffsets[level] * C;
+    const uint32_t shashmap_size = soffsets[level + 1] - soffsets[level];
+
+    tgrid += (uint32_t)toffsets[level] * C;
+    const uint32_t thashmap_size = toffsets[level + 1] - toffsets[level];
+
+    float scale[D];
+    uint32_t resolution[D];
+    uint32_t spatial_resolution[D-1];
+    uint32_t mask_resolution[D-1];
+
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) 
+    {
+        scale[d] = exp2f(level * S[d]) * H[d] - 1.0f; 
+        resolution[d] = (uint32_t)ceil(scale[d]) + 1;
+    }
+
+    #pragma unroll
+    for (uint32_t d=0; d<D-1; ++d){
+        spatial_resolution[d] = resolution[d];
+    }
+
+    #pragma unroll
+    for (uint32_t d=0; d<D-1;++d)
+    {
+        mask_resolution[d] = (uint32_t)M[d];
+    }
+
+    float pos[D];
+    uint32_t pos_grid[D];
+    uint32_t pos_mask[D-1];
+
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) {
+        pos[d] = inputs[d] * scale[d] + (align_corners ? 0.0f : 0.5f);
+        pos_grid[d] = floorf(pos[d]);
+        pos[d] -= (float)pos_grid[d];
+    }
+
+    #pragma unroll
+    for (uint32_t d=0; d<D-1; ++d){
+        pos_mask[d] = inputs[d] * (mask_resolution[d]-1) + (align_corners ? 0.0f : 0.5f);
+        pos_mask[d] = rint(pos_mask[d]);
+    }
+
+    uint32_t mask_index = get_grid_index_rect<D-1, 1>(1, align_corners, 0, 2^30, mask_resolution, pos_mask);
+    float mask_value = mgrid[mask_index];
+    mask_value = 1./(1 + exp2f(-mask_value));
+    mout[0] = mask_value;
+
+    scalar_t results[C] = {0};
+    scalar_t tresults[C] = {0};
+    
+    // spatial query
+    #pragma unroll
+    for (uint32_t idx = 0; idx < (1 << (D-1)); idx++) {
+        float w = 1;
+        uint32_t pos_grid_local[D-1];
+
+        #pragma unroll
+        for (uint32_t d = 0; d < D-1; d++) {
+            if ((idx & (1 << d)) == 0) {
+                w *= 1 - pos[d];
+                pos_grid_local[d] = pos_grid[d];
+            } else {
+                w *= pos[d];
+                pos_grid_local[d] = pos_grid[d] + 1;
+            }
+        }
+
+        uint32_t index = get_grid_index_rect<D-1, C>(gridtype, align_corners, 0, shashmap_size, spatial_resolution, pos_grid_local);
+
+        // writing to register (fast)
+        #pragma unroll
+        for (uint32_t ch = 0; ch < C; ch++) {
+            results[ch] += w * sgrid[index + ch];
+        }
+    }
+
+    // temporal query
+    for (uint32_t idx = 0; idx < (1 << D); idx++) {
+        float w = 1;
+        uint32_t pos_grid_local[D];
+
+        #pragma unroll
+        for (uint32_t d = 0; d < D; d++) {
+            if ((idx & (1 << d)) == 0) {
+                w *= 1 - pos[d];
+                pos_grid_local[d] = pos_grid[d];
+            } else {
+                w *= pos[d];
+                pos_grid_local[d] = pos_grid[d] + 1;
+            }
+        }
+
+        uint32_t index = get_grid_index_rect<D, C>(gridtype, align_corners, 0, thashmap_size, resolution, pos_grid_local);
+
+        // writing to register (fast)
+        #pragma unroll
+        for (uint32_t ch = 0; ch < C; ch++) {
+            scalar_t temp = tgrid[index+ch];
+            results[ch] += (1-mask_value) * w * temp;
+            tresults[ch] += (1-mask_value) * w * temp;
+        }
+    }
+
+    #pragma unroll
+    for (uint32_t ch = 0; ch < C; ch++) {
+        outputs[ch] = results[ch]; 
+    }
+
+    #pragma unroll
+    for (uint32_t ch = 0; ch < C; ch++) {
+        tout[ch] = tresults[ch]; 
+    }
+}
+
+
+template <typename scalar_t, uint32_t D, uint32_t C, uint32_t N_C>
+__global__ void kernel_stgrid_backward(
+    const scalar_t * __restrict__ grad,// L x B x C
+    const float * __restrict__ inputs, 
+    // const scalar_t * __restrict__ sout,// L x B x C
+    const scalar_t * __restrict__ tout, 
+    const scalar_t * __restrict__ mout, 
+    const int * __restrict__ soffsets, 
+    const int * __restrict__ toffsets, 
+    scalar_t * __restrict__ grad_sgrid, 
+    scalar_t * __restrict__ grad_tgrid, 
+    scalar_t * __restrict__ grad_mgrid, 
+    const uint32_t B, const uint32_t L, const float *S, const int *H,
+    const int *M,
+    const uint32_t gridtype,
+    const bool align_corners,
+    const uint32_t interp
+)
+{
+    const uint32_t b = (blockIdx.x * blockDim.x + threadIdx.x) * N_C / C;
+    if (b >= B) return;
+
+    const uint32_t level = blockIdx.y;
+    const uint32_t ch = (blockIdx.x * blockDim.x + threadIdx.x) * N_C - b * C;
+
+    // locate
+    grad_sgrid += soffsets[level] * C;
+    grad_tgrid += toffsets[level] * C;
+    inputs += b * D;
+
+    grad += level * B * C + b * C + ch; // L, B, C
+    // sout += level * B * C + b * C + ch; // L, B, C
+    tout += level * B * C + b * C + ch; // L, B, C
+    mout += b * 1 ; // B, 1
+    float mask_value = mout[0];
+    // out = sout + mout * tout
+
+    const uint32_t shashmap_size = soffsets[level + 1] - soffsets[level];
+    const uint32_t thashmap_size = toffsets[level + 1] - toffsets[level];
+
+    float scale[D];
+    uint32_t resolution[D];
+    uint32_t spatial_resolution[D-1];
+    uint32_t mask_resolution[D-1];
+
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) 
+    {
+        scale[d] = exp2f(level * S[d]) * H[d] - 1.0f; 
+        resolution[d] = (uint32_t)ceil(scale[d]) + 1;
+    }
+
+    #pragma unroll
+    for (uint32_t d=0; d<D-1; ++d){
+        spatial_resolution[d] = resolution[d];
+    }
+
+    #pragma unroll
+    for (uint32_t d=0; d<D-1;++d)
+    {
+        mask_resolution[d] = (uint32_t)M[d];
+    }
+
+    // check input range (should be in [0, 1])
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) {
+        if (inputs[d] < 0 || inputs[d] > 1) {
+            return; // grad is init as 0, so we simply return.
+        }
+    }
+
+    float pos[D];
+    uint32_t pos_grid[D];
+    uint32_t pos_mask[D-1];
+
+    #pragma unroll
+    for (uint32_t d = 0; d < D; d++) {
+        pos[d] = inputs[d] * scale[d] + (align_corners ? 0.0f : 0.5f);
+        pos_grid[d] = floorf(pos[d]);
+        pos[d] -= (float)pos_grid[d];
+        // smoothstep instead of linear
+        if (interp == 1) {
+            pos[d] = smoothstep(pos[d]);
+        }
+    }
+
+    #pragma unroll
+    for (uint32_t d=0; d<D-1; ++d){
+        pos_mask[d] = inputs[d] * (mask_resolution[d]-1) + (align_corners ? 0.0f : 0.5f);
+        pos_mask[d] = rint(pos_mask[d]);
+    }
+
+    // spatial backward
+    scalar_t grad_cur[N_C] = {0}; // fetch to register
+    scalar_t tout_cur[N_C] = {0}; // fetch to register
+
+    #pragma unroll
+    for (uint32_t c = 0; c < N_C; c++) {
+        grad_cur[c] = grad[c];
+    }
+
+    #pragma unroll
+    for (uint32_t c = 0; c < N_C; c++) {
+        tout_cur[c] = tout[c];
+    }
+
+    // update grad_mgrid
+    if(level == 0){
+        uint32_t mask_index = get_grid_index_rect<D-1, 1>(1, align_corners, 0, 2^30, mask_resolution, pos_mask);
+        if (std::is_same<scalar_t, at::Half>::value && N_C % 2 == 0) {
+            __half tv = 0;
+
+            #pragma unroll
+            for (uint32_t c = 0; c < N_C; ++c) {
+                tv += -tout_cur[c] * grad_cur[c];
+            }
+
+            #pragma unroll
+            for (uint32_t l=1; l < L; ++l){
+                grad += B * C; // L, B, C
+                tout += B * C; // L, B, C
+                #pragma unroll
+                for (uint32_t c = 0; c < N_C; ++c) {
+                    tv += -grad[c] * tout[c];
+                }
+            }
+            tv = tv * (__half(mask_value) * __half(1.-mask_value));
+            atomicAdd((__half*)&grad_mgrid[mask_index], tv);
+            grad -= (L-1) * B * C; // L, B, C
+            tout -= (L-1) * B * C; // L, B, C
+        // float, or __half when N_C % 2 != 0 (which means C == 1)
+        } else {
+            float tv = 0;
+
+            #pragma unroll
+            for (uint32_t c = 0; c < N_C; c++) {
+                tv += -tout_cur[c] * grad_cur[c];
+            }
+
+            #pragma unroll
+            for (uint32_t l=1; l < L; ++l){
+                grad += B * C; // L, B, C
+                tout += B * C; // L, B, C
+                #pragma unroll
+                for (uint32_t c = 0; c < N_C; ++c) {
+                    tv += -grad[c] * tout[c];
+                }
+            }
+            tv = tv * mask_value * (1.-mask_value);
+            atomicAdd(&grad_mgrid[mask_index], tv);
+            grad -= (L-1) * B * C; // L, B, C
+            tout -= (L-1) * B * C; // L, B, C
+        }
+    }
+
+    // update for grad_sgrid
+    #pragma unroll
+    for (uint32_t idx = 0; idx < (1 << (D-1)); idx++) {
+        float w = 1;
+        uint32_t pos_grid_local[D-1];
+
+        #pragma unroll
+        for (uint32_t d = 0; d < D-1; d++) {
+            if ((idx & (1 << d)) == 0) {
+                w *= 1 - pos[d];
+                pos_grid_local[d] = pos_grid[d];
+            } else {
+                w *= pos[d];
+                pos_grid_local[d] = pos_grid[d] + 1;
+            }
+        }
 
-    float pos[D];
-    uint32_t pos_grid[D];
+        uint32_t index = get_grid_index_rect<D-1, C>(gridtype, align_corners, ch, shashmap_size, spatial_resolution, pos_grid_local);
 
-    #pragma unroll
-    for (uint32_t d = 0; d < D; d++) {
-        pos[d] = inputs[d] * scale[d] + (align_corners ? 0.0f : 0.5f);
-        pos_grid[d] = floorf(pos[d]);
-        pos[d] -= (float)pos_grid[d];
-        // smoothstep instead of linear
-        if (interp == 1) {
-            pos[d] = smoothstep(pos[d]);
+        // atomicAdd for __half is slow (especially for large values), so we use __half2 if N_C % 2 == 0
+        // TODO: use float which is better than __half, if N_C % 2 != 0
+        if (std::is_same<scalar_t, at::Half>::value && N_C % 2 == 0) {
+            #pragma unroll
+            for (uint32_t c = 0; c < N_C; c += 2) {
+                // process two __half at once (by interpreting as a __half2)
+                __half2 v = {(__half)(w * grad_cur[c]), (__half)(w * grad_cur[c + 1])};
+                atomicAdd((__half2*)&grad_sgrid[index + c], v);
+            }
+        // float, or __half when N_C % 2 != 0 (which means C == 1)
+        } else {
+            #pragma unroll
+            for (uint32_t c = 0; c < N_C; c++) {
+                atomicAdd(&grad_sgrid[index + c], w * grad_cur[c]);
+            }
         }
     }
 
-    scalar_t grad_cur[N_C] = {0}; // fetch to register
-    #pragma unroll
-    for (uint32_t c = 0; c < N_C; c++) {
-        grad_cur[c] = grad[c];
-    }
 
-    // interpolate
+    // update temporal ones
     #pragma unroll
     for (uint32_t idx = 0; idx < (1 << D); idx++) {
         float w = 1;
@@ -1194,102 +2326,219 @@ __global__ void kernel_grid_backward_rect(
             }
         }
 
-        uint32_t index = get_grid_index_rect<D, C>(gridtype, align_corners, ch, hashmap_size, resolution, pos_grid_local);
+        uint32_t index = get_grid_index_rect<D, C>(gridtype, align_corners, ch, thashmap_size, resolution, pos_grid_local);
 
-        // atomicAdd for __half is slow (especially for large values), so we use __half2 if N_C % 2 == 0
-        // TODO: use float which is better than __half, if N_C % 2 != 0
         if (std::is_same<scalar_t, at::Half>::value && N_C % 2 == 0) {
             #pragma unroll
             for (uint32_t c = 0; c < N_C; c += 2) {
                 // process two __half at once (by interpreting as a __half2)
-                __half2 v = {(__half)(w * grad_cur[c]), (__half)(w * grad_cur[c + 1])};
-                atomicAdd((__half2*)&grad_grid[index + c], v);
+                __half2 v = {(__half)((1-mask_value) * w * grad_cur[c]), (__half)((1-mask_value) * w * grad_cur[c + 1])};
+                atomicAdd((__half2*)&grad_tgrid[index + c], v);
             }
         // float, or __half when N_C % 2 != 0 (which means C == 1)
         } else {
             #pragma unroll
             for (uint32_t c = 0; c < N_C; c++) {
-                atomicAdd(&grad_grid[index + c], w * grad_cur[c]);
+                atomicAdd(&grad_tgrid[index + c], (1-mask_value) * w * grad_cur[c]);
             }
         }
     }
 }
 
+
 template <typename scalar_t, uint32_t D>
-void kernel_grid_rect_wrapper(const float *inputs, const scalar_t *embeddings, const int *offsets, scalar_t *outputs, const uint32_t B, const uint32_t C, const uint32_t L, const float *S, const int *H, scalar_t *dy_dx, const uint32_t gridtype, const bool align_corners, const uint32_t interp) {
+void kernel_stgrid_wrapper(
+    const float *inputs, 
+    const scalar_t *sembeddings, 
+    const scalar_t *tembeddings, 
+    const scalar_t *membeddings, 
+    const int *soffsets, 
+    const int *toffsets, 
+    scalar_t *outputs, 
+    scalar_t *tout, 
+    scalar_t *mout, 
+    const uint32_t B, 
+    const uint32_t C, 
+    const uint32_t L, 
+    const float *S, 
+    const int *H, 
+    const int *M, 
+    scalar_t *dy_dx, 
+    const uint32_t gridtype, 
+    const bool align_corners, 
+    const uint32_t interp
+) {
     static constexpr uint32_t N_THREAD = 512;
     const dim3 blocks_hashgrid = { div_round_up(B, N_THREAD), L, 1 };
     switch (C) {
-        case 1: kernel_grid_rect<scalar_t, D, 1><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
-        case 2: kernel_grid_rect<scalar_t, D, 2><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
-        case 4: kernel_grid_rect<scalar_t, D, 4><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
-        case 8: kernel_grid_rect<scalar_t, D, 8><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+        case 1: kernel_stgrid<scalar_t, D, 1><<<blocks_hashgrid, N_THREAD>>>(inputs, sembeddings, tembeddings, membeddings, soffsets, toffsets, outputs, tout, mout, B, L, S, H, M, dy_dx, gridtype, align_corners, interp); break;
+        case 2: kernel_stgrid<scalar_t, D, 2><<<blocks_hashgrid, N_THREAD>>>(inputs, sembeddings, tembeddings, membeddings, soffsets, toffsets, outputs, tout, mout, B, L, S, H, M, dy_dx, gridtype, align_corners, interp); break;
+        case 4: kernel_stgrid<scalar_t, D, 4><<<blocks_hashgrid, N_THREAD>>>(inputs, sembeddings, tembeddings, membeddings, soffsets, toffsets, outputs, tout, mout, B, L, S, H, M, dy_dx, gridtype, align_corners, interp); break;
+        case 8: kernel_stgrid<scalar_t, D, 8><<<blocks_hashgrid, N_THREAD>>>(inputs, sembeddings, tembeddings, membeddings, soffsets, toffsets, outputs, tout, mout, B, L, S, H, M, dy_dx, gridtype, align_corners, interp); break;
         default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
     }
 }
 
 template <typename scalar_t>
-void rect_grid_encode_forward_cuda(const float *inputs, const scalar_t *embeddings, const int *offsets, scalar_t *outputs, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const float *S, const int *H, scalar_t *dy_dx, const uint32_t gridtype, const bool align_corners, const uint32_t interp) {
+void stgrid_encode_forward_cuda(
+    const float *inputs, 
+    const scalar_t *sembeddings, 
+    const scalar_t *tembeddings, 
+    const scalar_t *membeddings, 
+    const int *soffsets, 
+    const int *toffsets, 
+    scalar_t *outputs, 
+    scalar_t *tout, 
+    scalar_t *mout, 
+    const uint32_t B, 
+    const uint32_t D, 
+    const uint32_t C, 
+    const uint32_t L, 
+    const float *S, 
+    const int *H, 
+    const int *M, 
+    scalar_t *dy_dx, 
+    const uint32_t gridtype, 
+    const bool align_corners, 
+    const uint32_t interp
+) {
     switch (D) {
-        case 2: kernel_grid_rect_wrapper<scalar_t, 2>(inputs, embeddings, offsets, outputs, B, C, L, S, H, dy_dx, gridtype, align_corners, interp); break;
-        case 3: kernel_grid_rect_wrapper<scalar_t, 3>(inputs, embeddings, offsets, outputs, B, C, L, S, H, dy_dx, gridtype, align_corners, interp); break;
-        case 4: kernel_grid_rect_wrapper<scalar_t, 4>(inputs, embeddings, offsets, outputs, B, C, L, S, H, dy_dx, gridtype, align_corners, interp); break;
-        case 5: kernel_grid_rect_wrapper<scalar_t, 5>(inputs, embeddings, offsets, outputs, B, C, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+        case 2: kernel_stgrid_wrapper<scalar_t, 2>(inputs, sembeddings, tembeddings, membeddings, soffsets, toffsets, outputs, tout, mout, B, C, L, S, H, M, dy_dx, gridtype, align_corners, interp); break;
+        case 3: kernel_stgrid_wrapper<scalar_t, 3>(inputs, sembeddings, tembeddings, membeddings, soffsets, toffsets, outputs, tout, mout, B, C, L, S, H, M, dy_dx, gridtype, align_corners, interp); break;
+        case 4: kernel_stgrid_wrapper<scalar_t, 4>(inputs, sembeddings, tembeddings, membeddings, soffsets, toffsets, outputs, tout, mout, B, C, L, S, H, M, dy_dx, gridtype, align_corners, interp); break;
+        case 5: kernel_stgrid_wrapper<scalar_t, 5>(inputs, sembeddings, tembeddings, membeddings, soffsets, toffsets, outputs, tout, mout, B, C, L, S, H, M, dy_dx, gridtype, align_corners, interp); break;
         default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
     }   
 }
 
-void rect_grid_encode_forward(const at::Tensor inputs, const at::Tensor embeddings, const at::Tensor offsets, at::Tensor outputs, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const at::Tensor S, const at::Tensor H, at::optional<at::Tensor> dy_dx, const uint32_t gridtype, const bool align_corners, const uint32_t interp) {
+void stgrid_encode_forward(
+    const at::Tensor inputs, 
+    const at::Tensor sembeddings, 
+    const at::Tensor tembeddings, 
+    const at::Tensor membeddings, 
+    const at::Tensor soffsets, 
+    const at::Tensor toffsets, 
+    at::Tensor outputs, 
+    at::Tensor tout, 
+    at::Tensor mout, 
+    const uint32_t B, 
+    const uint32_t D, 
+    const uint32_t C, 
+    const uint32_t L, 
+    const at::Tensor S, 
+    const at::Tensor H, 
+    const at::Tensor M, 
+    at::optional<at::Tensor> dy_dx, 
+    const uint32_t gridtype, 
+    const bool align_corners, 
+    const uint32_t interp
+) {
     CHECK_CUDA(inputs);
-    CHECK_CUDA(embeddings);
-    CHECK_CUDA(offsets);
+    CHECK_CUDA(sembeddings);
+    CHECK_CUDA(tembeddings);
+    CHECK_CUDA(membeddings);
+    CHECK_CUDA(soffsets);
+    CHECK_CUDA(toffsets);
     CHECK_CUDA(outputs);
+    CHECK_CUDA(tout);
+    CHECK_CUDA(mout);
     CHECK_CUDA(S);
     CHECK_CUDA(H);
+    CHECK_CUDA(M);
     // CHECK_CUDA(dy_dx);
     
     CHECK_CONTIGUOUS(inputs);
-    CHECK_CONTIGUOUS(embeddings);
-    CHECK_CONTIGUOUS(offsets);
+    CHECK_CONTIGUOUS(sembeddings);
+    CHECK_CONTIGUOUS(tembeddings);
+    CHECK_CONTIGUOUS(membeddings);
+    CHECK_CONTIGUOUS(soffsets);
+    CHECK_CONTIGUOUS(toffsets);
     CHECK_CONTIGUOUS(outputs);
+    CHECK_CONTIGUOUS(tout);
+    CHECK_CONTIGUOUS(mout);
     CHECK_CONTIGUOUS(S);
     CHECK_CONTIGUOUS(H);
+    CHECK_CONTIGUOUS(M);
     // CHECK_CONTIGUOUS(dy_dx);
 
     CHECK_IS_FLOATING(inputs);
-    CHECK_IS_FLOATING(embeddings);
-    CHECK_IS_INT(offsets);
+    CHECK_IS_FLOATING(sembeddings);
+    CHECK_IS_FLOATING(tembeddings);
+    CHECK_IS_FLOATING(membeddings);
+    CHECK_IS_INT(soffsets);
+    CHECK_IS_INT(toffsets);
     CHECK_IS_FLOATING(outputs);
+    CHECK_IS_FLOATING(tout);
+    CHECK_IS_FLOATING(mout);
     CHECK_IS_INT(H);
     CHECK_IS_FLOATING(S);
+    CHECK_IS_INT(M);
     // CHECK_IS_FLOATING(dy_dx);
 
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(
-    embeddings.scalar_type(), "rect_grid_encode_forward", ([&] {
-        rect_grid_encode_forward_cuda<scalar_t>(inputs.data_ptr<float>(), embeddings.data_ptr<scalar_t>(), offsets.data_ptr<int>(), outputs.data_ptr<scalar_t>(), B, D, C, L, S.data_ptr<float>(), H.data_ptr<int>(), dy_dx.has_value() ? dy_dx.value().data_ptr<scalar_t>() : nullptr, gridtype, align_corners, interp);
+    sembeddings.scalar_type(), "rect_grid_encode_forward", ([&] {
+        stgrid_encode_forward_cuda<scalar_t>(
+            inputs.data_ptr<float>(), 
+            sembeddings.data_ptr<scalar_t>(), 
+            tembeddings.data_ptr<scalar_t>(), 
+            membeddings.data_ptr<scalar_t>(), 
+            soffsets.data_ptr<int>(), 
+            toffsets.data_ptr<int>(), 
+            outputs.data_ptr<scalar_t>(), 
+            tout.data_ptr<scalar_t>(), 
+            mout.data_ptr<scalar_t>(), 
+            B, D, C, L, S.data_ptr<float>(), H.data_ptr<int>(), M.data_ptr<int>(),
+            dy_dx.has_value() ? dy_dx.value().data_ptr<scalar_t>() : nullptr, 
+            gridtype, 
+            align_corners, 
+            interp
+        );
     }));
 }
 
 template <typename scalar_t, uint32_t D>
-void kernel_grid_rect_backward_wrapper(const scalar_t *grad, const float *inputs, const scalar_t *embeddings, const int *offsets, scalar_t *grad_embeddings, const uint32_t B, const uint32_t C, const uint32_t L, const float *S, const int *H, scalar_t *dy_dx, scalar_t *grad_inputs, const uint32_t gridtype, const bool align_corners, const uint32_t interp) {
+void kernel_stgrid_backward_wrapper(
+    const scalar_t *grad, 
+    const float *inputs, 
+    // const scalar_t *embeddings, 
+    // const scalar_t * sout,
+    const scalar_t * tout,
+    const scalar_t * mout,
+    const int *soffsets, 
+    const int *toffsets, 
+    scalar_t *grad_sembeddings, 
+    scalar_t *grad_tembeddings, 
+    scalar_t *grad_membeddings, 
+    const uint32_t B, 
+    const uint32_t C, 
+    const uint32_t L, 
+    const float *S, 
+    const int *H, 
+    const int *M,
+    scalar_t *dy_dx, 
+    scalar_t *grad_inputs, 
+    const uint32_t gridtype, 
+    const bool align_corners, 
+    const uint32_t interp
+) {
     static constexpr uint32_t N_THREAD = 256;
     const uint32_t N_C = std::min(2u, C); // n_features_per_thread
     const dim3 blocks_hashgrid = { div_round_up(B * C / N_C, N_THREAD), L, 1 };
     switch (C) {
         case 1: 
-            kernel_grid_backward_rect<scalar_t, D, 1, 1><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, embeddings, offsets, grad_embeddings, B, L, S, H, gridtype, align_corners, interp); 
+            kernel_stgrid_backward<scalar_t, D, 1, 1><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, tout, mout, soffsets, toffsets, grad_sembeddings, grad_tembeddings, grad_membeddings, B, L, S, H, M, gridtype, align_corners, interp); 
             if (dy_dx) kernel_input_backward<scalar_t, D, 1><<<div_round_up(B * D, N_THREAD), N_THREAD>>>(grad, dy_dx, grad_inputs, B, L);
             break;
         case 2: 
-            kernel_grid_backward_rect<scalar_t, D, 2, 2><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, embeddings, offsets, grad_embeddings, B, L, S, H, gridtype, align_corners, interp);
+            kernel_stgrid_backward<scalar_t, D, 2, 2><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, tout, mout, soffsets, toffsets, grad_sembeddings, grad_tembeddings, grad_membeddings, B, L, S, H, M, gridtype, align_corners, interp);
             if (dy_dx) kernel_input_backward<scalar_t, D, 2><<<div_round_up(B * D, N_THREAD), N_THREAD>>>(grad, dy_dx, grad_inputs, B, L);
             break;
         case 4: 
-            kernel_grid_backward_rect<scalar_t, D, 4, 2><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, embeddings, offsets, grad_embeddings, B, L, S, H, gridtype, align_corners, interp);
+            kernel_stgrid_backward<scalar_t, D, 4, 2><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, tout, mout, soffsets, toffsets, grad_sembeddings, grad_tembeddings, grad_membeddings, B, L, S, H, M, gridtype, align_corners, interp);
             if (dy_dx) kernel_input_backward<scalar_t, D, 4><<<div_round_up(B * D, N_THREAD), N_THREAD>>>(grad, dy_dx, grad_inputs, B, L);
             break;
         case 8: 
-            kernel_grid_backward_rect<scalar_t, D, 8, 2><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, embeddings, offsets, grad_embeddings, B, L, S, H, gridtype, align_corners, interp);
+            kernel_stgrid_backward<scalar_t, D, 8, 2><<<blocks_hashgrid, N_THREAD>>>(grad, inputs, tout, mout, soffsets, toffsets, grad_sembeddings, grad_tembeddings, grad_membeddings, B, L, S, H, M, gridtype, align_corners, interp);
             if (dy_dx) kernel_input_backward<scalar_t, D, 8><<<div_round_up(B * D, N_THREAD), N_THREAD>>>(grad, dy_dx, grad_inputs, B, L);
             break;
         default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
@@ -1297,193 +2546,131 @@ void kernel_grid_rect_backward_wrapper(const scalar_t *grad, const float *inputs
 }
 
 template <typename scalar_t>
-void rect_grid_encode_backward_cuda(const scalar_t *grad, const float *inputs, const scalar_t *embeddings, const int *offsets, scalar_t *grad_embeddings, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const float *S, const int *H, scalar_t *dy_dx, scalar_t *grad_inputs, const uint32_t gridtype, const bool align_corners, const uint32_t interp) {
+void stgrid_encode_backward_cuda(
+    const scalar_t *grad, 
+    const float *inputs, 
+    // const scalar_t *sout, 
+    const scalar_t *tout, 
+    const scalar_t *mout, 
+    const int *soffsets, 
+    const int *toffsets, 
+    scalar_t *grad_sembeddings, 
+    scalar_t *grad_tembeddings, 
+    scalar_t *grad_membeddings, 
+    const uint32_t B, 
+    const uint32_t D, 
+    const uint32_t C, 
+    const uint32_t L, 
+    const float *S, 
+    const int *H, 
+    const int *M, 
+    scalar_t *dy_dx, 
+    scalar_t *grad_inputs, 
+    const uint32_t gridtype, 
+    const bool align_corners, 
+    const uint32_t interp
+) {
     switch (D) {
-        case 2: kernel_grid_rect_backward_wrapper<scalar_t, 2>(grad, inputs, embeddings, offsets, grad_embeddings, B, C, L, S, H, dy_dx, grad_inputs, gridtype, align_corners, interp); break;
-        case 3: kernel_grid_rect_backward_wrapper<scalar_t, 3>(grad, inputs, embeddings, offsets, grad_embeddings, B, C, L, S, H, dy_dx, grad_inputs, gridtype, align_corners, interp); break;
-        case 4: kernel_grid_rect_backward_wrapper<scalar_t, 4>(grad, inputs, embeddings, offsets, grad_embeddings, B, C, L, S, H, dy_dx, grad_inputs, gridtype, align_corners, interp); break;
-        case 5: kernel_grid_rect_backward_wrapper<scalar_t, 5>(grad, inputs, embeddings, offsets, grad_embeddings, B, C, L, S, H, dy_dx, grad_inputs, gridtype, align_corners, interp); break;
+        case 2: kernel_stgrid_backward_wrapper<scalar_t, 2>(grad, inputs, tout, mout, soffsets, toffsets, grad_sembeddings, grad_tembeddings, grad_membeddings, B, C, L, S, H, M, dy_dx, grad_inputs, gridtype, align_corners, interp); break;
+        case 3: kernel_stgrid_backward_wrapper<scalar_t, 3>(grad, inputs, tout, mout, soffsets, toffsets, grad_sembeddings, grad_tembeddings, grad_membeddings, B, C, L, S, H, M, dy_dx, grad_inputs, gridtype, align_corners, interp); break;
+        case 4: kernel_stgrid_backward_wrapper<scalar_t, 4>(grad, inputs, tout, mout, soffsets, toffsets, grad_sembeddings, grad_tembeddings, grad_membeddings, B, C, L, S, H, M, dy_dx, grad_inputs, gridtype, align_corners, interp); break;
+        case 5: kernel_stgrid_backward_wrapper<scalar_t, 5>(grad, inputs, tout, mout, soffsets, toffsets, grad_sembeddings, grad_tembeddings, grad_membeddings, B, C, L, S, H, M, dy_dx, grad_inputs, gridtype, align_corners, interp); break;
         default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
     }
 }
 
-void rect_grid_encode_backward(const at::Tensor grad, const at::Tensor inputs, const at::Tensor embeddings, const at::Tensor offsets, at::Tensor grad_embeddings, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const at::Tensor S, const at::Tensor H, const at::optional<at::Tensor> dy_dx, at::optional<at::Tensor> grad_inputs, const uint32_t gridtype, const bool align_corners, const uint32_t interp) {
+void stgrid_encode_backward(
+    const at::Tensor grad, 
+    const at::Tensor inputs, 
+    // const at::Tensor embeddings, 
+    // const at::Tensor sout, 
+    const at::Tensor tout, 
+    const at::Tensor mout, 
+    const at::Tensor soffsets, 
+    const at::Tensor toffsets, 
+    at::Tensor grad_sembeddings, 
+    at::Tensor grad_tembeddings, 
+    at::Tensor grad_membeddings, 
+    const uint32_t B, 
+    const uint32_t D, 
+    const uint32_t C, 
+    const uint32_t L, 
+    const at::Tensor S, 
+    const at::Tensor H, 
+    const at::Tensor M, 
+    const at::optional<at::Tensor> dy_dx, 
+    at::optional<at::Tensor> grad_inputs, 
+    const uint32_t gridtype, 
+    const bool align_corners, 
+    const uint32_t interp
+) {
     CHECK_CUDA(grad);
     CHECK_CUDA(inputs);
-    CHECK_CUDA(embeddings);
-    CHECK_CUDA(offsets);
-    CHECK_CUDA(grad_embeddings);
+    // CHECK_CUDA(sout);
+    CHECK_CUDA(tout);
+    CHECK_CUDA(mout);
+    CHECK_CUDA(soffsets);
+    CHECK_CUDA(toffsets);
+    CHECK_CUDA(grad_sembeddings);
+    CHECK_CUDA(grad_tembeddings);
+    CHECK_CUDA(grad_membeddings);
     CHECK_CUDA(S);
     CHECK_CUDA(H);
+    CHECK_CUDA(M);
     // CHECK_CUDA(dy_dx);
     // CHECK_CUDA(grad_inputs);
     
     CHECK_CONTIGUOUS(grad);
     CHECK_CONTIGUOUS(inputs);
-    CHECK_CONTIGUOUS(embeddings);
-    CHECK_CONTIGUOUS(offsets);
-    CHECK_CONTIGUOUS(grad_embeddings);
+    // CHECK_CONTIGUOUS(sout);
+    CHECK_CONTIGUOUS(tout);
+    CHECK_CONTIGUOUS(mout);
+    CHECK_CONTIGUOUS(soffsets);
+    CHECK_CONTIGUOUS(toffsets);
+    CHECK_CONTIGUOUS(grad_sembeddings);
+    CHECK_CONTIGUOUS(grad_tembeddings);
+    CHECK_CONTIGUOUS(grad_membeddings);
     CHECK_CONTIGUOUS(S);
     CHECK_CONTIGUOUS(H);
+    CHECK_CONTIGUOUS(M);
     // CHECK_CONTIGUOUS(dy_dx);
     // CHECK_CONTIGUOUS(grad_inputs);
 
     CHECK_IS_FLOATING(grad);
     CHECK_IS_FLOATING(inputs);
-    CHECK_IS_FLOATING(embeddings);
-    CHECK_IS_INT(offsets);
-    CHECK_IS_FLOATING(grad_embeddings);
+    // CHECK_IS_FLOATING(sout);
+    CHECK_IS_FLOATING(tout);
+    CHECK_IS_FLOATING(mout);
+    CHECK_IS_INT(soffsets);
+    CHECK_IS_INT(toffsets);
+    CHECK_IS_FLOATING(grad_sembeddings);
+    CHECK_IS_FLOATING(grad_tembeddings);
+    CHECK_IS_FLOATING(grad_membeddings);
     CHECK_IS_INT(H);
     CHECK_IS_FLOATING(S);
+    CHECK_IS_INT(M);
     // CHECK_IS_FLOATING(dy_dx);
     // CHECK_IS_FLOATING(grad_inputs);
 
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(
     grad.scalar_type(), "rect_grid_encode_backward", ([&] {
-        rect_grid_encode_backward_cuda<scalar_t>(grad.data_ptr<scalar_t>(), inputs.data_ptr<float>(), embeddings.data_ptr<scalar_t>(), offsets.data_ptr<int>(), grad_embeddings.data_ptr<scalar_t>(), B, D, C, L, S.data_ptr<float>(), H.data_ptr<int>(), dy_dx.has_value() ? dy_dx.value().data_ptr<scalar_t>() : nullptr, grad_inputs.has_value() ? grad_inputs.value().data_ptr<scalar_t>() : nullptr, gridtype, align_corners, interp);
+        stgrid_encode_backward_cuda<scalar_t>(
+            grad.data_ptr<scalar_t>(), 
+            inputs.data_ptr<float>(), 
+            // sout.data_ptr<scalar_t>(), 
+            tout.data_ptr<scalar_t>(), 
+            mout.data_ptr<scalar_t>(), 
+            soffsets.data_ptr<int>(), 
+            toffsets.data_ptr<int>(), 
+            grad_sembeddings.data_ptr<scalar_t>(), 
+            grad_tembeddings.data_ptr<scalar_t>(), 
+            grad_membeddings.data_ptr<scalar_t>(), 
+            B, D, C, L, S.data_ptr<float>(), H.data_ptr<int>(), M.data_ptr<int>(), 
+            dy_dx.has_value() ? dy_dx.value().data_ptr<scalar_t>() : nullptr, 
+            grad_inputs.has_value() ? grad_inputs.value().data_ptr<scalar_t>() : nullptr, 
+            gridtype, 
+            align_corners, 
+            interp);
     }));
     
 }
-
-template <typename scalar_t, uint32_t D, uint32_t C>
-__global__ void kernel_rect_grad_tv(
-    const scalar_t * __restrict__ inputs,
-    const scalar_t * __restrict__ grid, 
-    scalar_t * __restrict__ grad, 
-    const int * __restrict__ offsets, 
-    const float weight,
-    const uint32_t B, const uint32_t L, const float *S, const int *H,
-    const uint32_t gridtype,
-    const bool align_corners
-) 
-{
-    const uint32_t b = blockIdx.x * blockDim.x + threadIdx.x;
-    
-    if (b >= B) return;
-
-    const uint32_t level = blockIdx.y;
-
-    grid += (uint32_t)offsets[level] * C;
-    grad += (uint32_t)offsets[level] * C;
-
-    // check input range (should be in [0, 1])
-    bool flag_oob = false;
-    #pragma unroll
-    for (uint32_t d = 0; d < D; d++) {
-        if (inputs[d] < 0 || inputs[d] > 1) {
-            flag_oob = true;
-        }
-    }
-
-    // if input out of bound, do nothing
-    if (flag_oob) return;
-
-    const uint32_t hashmap_size = offsets[level + 1] - offsets[level];
-    float scale[D];
-    uint32_t resolution[D];
-
-    #pragma unroll
-    for (uint32_t d = 0; d < D; d++) 
-    {
-        scale[d] = exp2f(level * S[d]) * H[d] - 1.0f; 
-        resolution[d] = (uint32_t)ceil(scale[d]) + 1;
-    }
-    
-    // calculate coordinate
-    float pos[D];
-    uint32_t pos_grid[D]; // [0, resolution]
-
-    #pragma unroll
-    for (uint32_t d = 0; d < D; d++) {
-        pos[d] = inputs[d] * scale[d] + (align_corners ? 0.0f : 0.5f);
-        pos_grid[d] = floorf(pos[d]);
-        // pos[d] -= (float)pos_grid[d]; // not used
-    }
-
-    //printf("[b=%d, l=%d] pos=(%f, %f)+(%d, %d)\n", b, level, pos[0], pos[1], pos_grid[0], pos_grid[1]);
-
-    // total variation on pos_grid
-    scalar_t results[C] = {0}; // temp results in register
-    scalar_t idelta[C] = {0};
-
-    uint32_t index = get_grid_index_rect<D, C>(gridtype, align_corners, 0, hashmap_size, resolution, pos_grid);
-
-    scalar_t w = weight / (2 * D);
-
-    #pragma unroll
-    for (uint32_t d = 0; d < D; d++) {
-
-        uint32_t cur_d = pos_grid[d];
-        scalar_t grad_val;
-
-        // right side
-        if (cur_d < resolution[d]) {
-            pos_grid[d] = cur_d + 1;
-            uint32_t index_right = get_grid_index_rect<D, C>(gridtype, align_corners, 0, hashmap_size, resolution, pos_grid);
-
-            #pragma unroll
-            for (uint32_t ch = 0; ch < C; ch++) {
-                // results[ch] += w * clamp(grid[index + ch] - grid[index_right + ch], -1.0f, 1.0f);
-                grad_val = (grid[index + ch] - grid[index_right + ch]);
-                results[ch] += grad_val;
-                idelta[ch] += grad_val * grad_val;
-            }
-        }
-
-        // left side
-        if (cur_d > 0) {
-            pos_grid[d] = cur_d - 1;
-            uint32_t index_left = get_grid_index_rect<D, C>(gridtype, align_corners, 0, hashmap_size, resolution, pos_grid);
-
-            #pragma unroll
-            for (uint32_t ch = 0; ch < C; ch++) {
-                // results[ch] += w * clamp(grid[index + ch] - grid[index_left + ch], -1.0f, 1.0f);
-                grad_val = (grid[index + ch] - grid[index_left + ch]);
-                results[ch] += grad_val;
-                idelta[ch] += grad_val * grad_val;
-            }
-        }
-
-        // reset
-        pos_grid[d] = cur_d;
-    }
-
-    // writing to global memory (slow)
-    #pragma unroll
-    for (uint32_t ch = 0; ch < C; ch++) {
-        // index may collide, so use atomic!
-        atomicAdd(&grad[index + ch], w * results[ch] * rsqrtf(idelta[ch] + 1e-9f));
-    }
-}
-
-template <typename scalar_t, uint32_t D>
-void kernel_rect_grad_tv_wrapper(const scalar_t *inputs, const scalar_t *embeddings, scalar_t *grad, const int *offsets, const float weight, const uint32_t B, const uint32_t C, const uint32_t L, const float *S, const int *H, const uint32_t gridtype, const bool align_corners) {
-    static constexpr uint32_t N_THREAD = 512;
-    const dim3 blocks_hashgrid = { div_round_up(B, N_THREAD), L, 1 };
-    switch (C) {
-        case 1: kernel_rect_grad_tv<scalar_t, D, 1><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, grad, offsets, weight, B, L, S, H, gridtype, align_corners); break;
-        case 2: kernel_rect_grad_tv<scalar_t, D, 2><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, grad, offsets, weight, B, L, S, H, gridtype, align_corners); break;
-        case 4: kernel_rect_grad_tv<scalar_t, D, 4><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, grad, offsets, weight, B, L, S, H, gridtype, align_corners); break;
-        case 8: kernel_rect_grad_tv<scalar_t, D, 8><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, grad, offsets, weight, B, L, S, H, gridtype, align_corners); break;
-        default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
-    }
-}
-
-template <typename scalar_t>
-void rect_grad_total_variation_cuda(const scalar_t *inputs, const scalar_t *embeddings, scalar_t *grad, const int *offsets, const float weight, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const float *S, const int *H, const uint32_t gridtype, const bool align_corners) {
-    switch (D) {
-        case 2: kernel_rect_grad_tv_wrapper<scalar_t, 2>(inputs, embeddings, grad, offsets, weight, B, C, L, S, H, gridtype, align_corners); break;
-        case 3: kernel_rect_grad_tv_wrapper<scalar_t, 3>(inputs, embeddings, grad, offsets, weight, B, C, L, S, H, gridtype, align_corners); break;
-        case 4: kernel_rect_grad_tv_wrapper<scalar_t, 4>(inputs, embeddings, grad, offsets, weight, B, C, L, S, H, gridtype, align_corners); break;
-        case 5: kernel_rect_grad_tv_wrapper<scalar_t, 5>(inputs, embeddings, grad, offsets, weight, B, C, L, S, H, gridtype, align_corners); break;
-        default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
-    }   
-}
-
-void rect_grad_total_variation(const at::Tensor inputs, const at::Tensor embeddings, at::Tensor grad, const at::Tensor offsets, const float weight, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const at::Tensor S, const at::Tensor H, const uint32_t gridtype, const bool align_corners) {
-
-    AT_DISPATCH_FLOATING_TYPES_AND_HALF(
-    embeddings.scalar_type(), "rect_grad_total_variation", ([&] {
-        rect_grad_total_variation_cuda<scalar_t>(inputs.data_ptr<scalar_t>(), embeddings.data_ptr<scalar_t>(), grad.data_ptr<scalar_t>(), offsets.data_ptr<int>(), weight, B, D, C, L, S.data_ptr<float>(), H.data_ptr<int>(), gridtype, align_corners);
-    }));
-}
\ No newline at end of file
diff --git a/MSTH/gridencoder/src/gridencoder.h b/MSTH/gridencoder/src/gridencoder.h
index 37e4e08..ab2804c 100644
--- a/MSTH/gridencoder/src/gridencoder.h
+++ b/MSTH/gridencoder/src/gridencoder.h
@@ -28,4 +28,54 @@ void rect_grid_encode_backward(const at::Tensor grad, const at::Tensor inputs, c
 
 void rect_grad_total_variation(const at::Tensor inputs, const at::Tensor embeddings, at::Tensor grad, const at::Tensor offsets, const float weight, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const at::Tensor S, const at::Tensor H, const uint32_t gridtype, const bool align_corners);
 
+// stgrid
+void stgrid_encode_forward(
+    const at::Tensor inputs, 
+    const at::Tensor sembeddings, 
+    const at::Tensor tembeddings, 
+    const at::Tensor membeddings, 
+    const at::Tensor soffsets, 
+    const at::Tensor toffsets, 
+    at::Tensor outputs, 
+    at::Tensor tout, 
+    at::Tensor mout, 
+    const uint32_t B, 
+    const uint32_t D, 
+    const uint32_t C, 
+    const uint32_t L, 
+    const at::Tensor S, 
+    const at::Tensor H, 
+    const at::Tensor M, 
+    at::optional<at::Tensor> dy_dx, 
+    const uint32_t gridtype, 
+    const bool align_corners, 
+    const uint32_t interp
+);
+
+void stgrid_encode_backward(
+    const at::Tensor grad, 
+    const at::Tensor inputs, 
+    // const at::Tensor embeddings, 
+    // const at::Tensor sout, 
+    const at::Tensor tout, 
+    const at::Tensor mout, 
+    const at::Tensor soffsets, 
+    const at::Tensor toffsets, 
+    at::Tensor grad_sembeddings, 
+    at::Tensor grad_tembeddings, 
+    at::Tensor grad_membeddings, 
+    const uint32_t B, 
+    const uint32_t D, 
+    const uint32_t C, 
+    const uint32_t L, 
+    const at::Tensor S, 
+    const at::Tensor H, 
+    const at::Tensor M, 
+    const at::optional<at::Tensor> dy_dx, 
+    at::optional<at::Tensor> grad_inputs, 
+    const uint32_t gridtype, 
+    const bool align_corners, 
+    const uint32_t interp
+);
+
 #endif
\ No newline at end of file
diff --git a/MSTH/sampler.py b/MSTH/sampler.py
index 80530da..ed46f1c 100644
--- a/MSTH/sampler.py
+++ b/MSTH/sampler.py
@@ -6,6 +6,7 @@ from torchtyping import TensorType
 from MSTH.dataset import VideoDatasetAllCached, VideoDatasetAllCachedUint8
 from nerfstudio.data.pixel_samplers import PixelSampler
 import torch.nn.functional as F
+from einops import repeat
 
 from rich.console import Console
 
@@ -409,10 +410,132 @@ class PixelTimeSampler:
         batch["is_static"] = is_static.bool()
         return batch
 
-    # def set_static_dynamic_ratio(self, ratio):
-    #     self.static_dynamic_ratio = ratio
-    #     self.num_static_rays_per_batch = int(self.num_rays_per_batch * self.static_dynamic_ratio / (1 + self.static_dynamic_ratio))
-    #     self.num_dynamic_rays_per_batch = self.num_rays_per_batch - self.num_static_rays_per_batch
+
+class SpatioTemporalSampler:
+    def __init__(
+        self,
+        dataset: Union[VideoDatasetAllCached, VideoDatasetAllCachedUint8],
+        num_rays_per_batch: int,
+        static_dynamic_ratio,
+        drop_last: bool = False,
+        static_dynamic_ratio_end=None,
+        total_steps=None,
+        n_time_for_dynamic=lambda x: 1,
+    ) -> None:
+        self.n_time_for_dynamic = n_time_for_dynamic
+        self.num_rays_per_batch = num_rays_per_batch
+        self.step = 0
+        self.total_steps = total_steps
+        assert self.total_steps is not None
+        self.static_dynamic_ratio = static_dynamic_ratio
+        self.static_dynamic_ratio_end = static_dynamic_ratio_end
+        self.set_static_dynamic_ratio()
+        # self.num_static_rays_per_batch = int(num_rays_per_batch * static_dynamic_ratio / (1 + static_dynamic_ratio))
+        # self.num_dynamic_rays_per_batch = num_rays_per_batch - self.num_static_rays_per_batch
+        self.static_sample_ptr = 0
+        self.dynamic_sample_ptr = 0
+        self.drop_last = drop_last
+        self.dataset = dataset
+        self.static_indices = torch.nonzero(~self.dataset.masks[..., 0], as_tuple=False)
+        self.dynamic_indices = torch.nonzero(self.dataset.masks[..., 0], as_tuple=False)
+        # [n_cams, h, w]
+        self._reset_static()
+        self._reset_dynamic()
+
+    def set_static_dynamic_ratio(self):
+        if self.static_dynamic_ratio_end is None:
+            self.num_static_rays_per_batch = int(
+                self.num_rays_per_batch * self.static_dynamic_ratio / (1 + self.static_dynamic_ratio)
+            )
+            self.num_dynamic_rays_per_batch = self.num_rays_per_batch - self.num_static_rays_per_batch
+        else:
+            current_ratio = self.static_dynamic_ratio + (
+                self.static_dynamic_ratio_end - self.static_dynamic_ratio
+            ) * np.clip(self.step / self.total_steps, 0, 1)
+            self.num_static_rays_per_batch = int(self.num_rays_per_batch * current_ratio / (1 + current_ratio))
+            self.num_dynamic_rays_per_batch = self.num_rays_per_batch - self.num_static_rays_per_batch
+        self.step += 1
+
+    def _reset_static(self):
+        self.static_indices = self.static_indices[torch.randperm(self.static_indices.size(0))]
+        self.static_sample_ptr = 0
+
+    def _reset_dynamic(self):
+        self.dynamic_indices = self.dynamic_indices[torch.randperm(self.dynamic_indices.size(0))]
+        self.dynamic_sample_ptr = 0
+
+    def static_sample_indices(self):
+        sampled = self.static_indices[self.static_sample_ptr : self.static_sample_ptr + self.num_static_rays_per_batch]
+        self.static_sample_ptr += self.num_rays_per_batch
+        return sampled
+
+    def dynamic_sample_indices(self):
+        sampled = self.dynamic_indices[
+            self.dynamic_sample_ptr : self.dynamic_sample_ptr + self.num_dynamic_rays_per_batch
+        ]
+        self.dynamic_sample_ptr += self.num_rays_per_batch
+        return sampled
+
+    def get_batch(self, indices, is_static):
+        c, y, x = (i.flatten() for i in torch.split(indices, 1, dim=-1))
+        batch_size = c.shape[0]
+        c_static = c[is_static]
+        y_static = y[is_static]
+        x_static = x[is_static]
+        t_static = torch.floor(torch.rand(*c_static.shape) * self.dataset.num_frames).to(c_static)
+
+        c_dynamic = c[~is_static]
+        y_dynamic = y[~is_static]
+        x_dynamic = x[~is_static]
+        c_dynamic = repeat(c_dynamic, "b -> (n b)", n=int(self.n_time_for_dynamic(self.step)))
+        y_dynamic = repeat(y_dynamic, "b -> (n b)", n=int(self.n_time_for_dynamic(self.step)))
+        x_dynamic = repeat(x_dynamic, "b -> (n b)", n=int(self.n_time_for_dynamic(self.step)))
+        t_dynamic = torch.floor(torch.rand(*c_dynamic.shape) * self.dataset.num_frames).to(c_dynamic)
+
+        c = torch.cat([c_static, c_dynamic], dim=0)
+        x = torch.cat([x_static, x_dynamic], dim=0)
+        y = torch.cat([y_static, y_dynamic], dim=0)
+        t = torch.cat([t_static, t_dynamic], dim=0)
+
+        _perm = torch.randperm(c.size(0))
+        c = c[_perm][:batch_size]
+        x = x[_perm][:batch_size]
+        y = y[_perm][:batch_size]
+        t = t[_perm][:batch_size]
+
+        indices = torch.stack([c, y, x], dim=-1)
+
+        images = self.dataset.frames[c, t, y, x]
+        if images.dtype != torch.float32:
+            images = images.to(torch.float32) / 255.0
+
+        batch = {"image": images}
+        # batch["indices"] = indices[..., [0, 2, 3]]
+        batch["indices"] = indices
+        # batch["time"] = t
+        batch["time"] = t.to(torch.float32) / self.dataset.num_frames
+
+        return batch
+
+    def sample(self):
+        if self.static_sample_ptr + self.num_rays_per_batch > self.static_indices.size(0):
+            self._reset_static()
+        if self.dynamic_sample_ptr + self.num_rays_per_batch > self.dynamic_indices.size(0):
+            self._reset_dynamic()
+
+        _static_indices = self.static_sample_indices()
+        _dynamic_indices = self.dynamic_sample_indices()
+        indices = torch.cat([_static_indices, _dynamic_indices], dim=0)
+        is_static = torch.cat([torch.ones(_static_indices.shape[0]), torch.zeros(_dynamic_indices.shape[0])])
+        self.set_static_dynamic_ratio()
+
+        _perm = torch.randperm(indices.size(0))
+        indices = indices[_perm]
+        is_static = is_static[_perm].bool()
+
+        batch = self.get_batch(indices, is_static)
+        batch["is_static"] = is_static.bool()
+        return batch
 
 
 class ISGSampler:
diff --git a/MSTH/test.py b/MSTH/test.py
index 8b301aa..e1a50ed 100644
--- a/MSTH/test.py
+++ b/MSTH/test.py
@@ -1,406 +1,28 @@
-import time
-
-import cv2
-import matplotlib.pyplot as plt
-import numpy as np
-
-# import pytest
-import torch
-from MSTH.dataparser import VideoDataParser, VideoDataParserConfig
-from MSTH.dataset import VideoDataset
-from MSTH.sampler import CompletePixelSampler, CompletePixelSamplerIter
-from MSTH.utils import Timer
-import argparse
-
-
-def test_video_dataparaser():
-    parser = VideoDataParserConfig().setup()
-    outputs = parser._generate_dataparser_outputs("train")
-
-    print(outputs)
-
-
-def test_video_dataset_basics():
-    parser = VideoDataParserConfig().setup()
-    outputs = parser._generate_dataparser_outputs("train")
-    print(len(outputs.video_filenames))
-    vd = VideoDataset(outputs, 1)
-
-    frame0 = vd[0]["image"]
-    plt.imshow(frame0)
-    # plt.show()
-    vd.tick()
-    frame1 = vd[0]["image"]
-    plt.imshow(frame1)
-    # plt.show()
-    mask = vd[0]["mask"]
-
-    plt.imshow(mask)
-    plt.show()
-
-    mask_gt = np.linalg.norm(frame1.numpy() - frame0.numpy(), ord=2, axis=-1)
-    print(np.mean(mask_gt))
-    plt.imshow(mask_gt)
-    plt.show()
-
-    del vd
-
-
-def test_video_dataset_stress():
-    parser = VideoDataParserConfig().setup()
-    outputs = parser._generate_dataparser_outputs("train")
-    print(f"Number of videos loaded: {len(outputs.video_filenames)}")
-    vd = VideoDataset(outputs, 1.0)
-
-    for i in range(50):
-        with Timer(f"{i}-th tick", record=True):
-            vd.tick()
-
-    Timer.show_recorder()
-
-
-def test_complete_pixel_sampler():
-    parser = VideoDataParserConfig().setup()
-    outputs = parser._generate_dataparser_outputs("train")
-    print(f"Number of videos loaded: {len(outputs.video_filenames)}")
-    vd = VideoDataset(outputs, 1.0)
-
-    vd.tick()
-    masks = vd.mask
-    indices = torch.nonzero(masks[..., 0])
-    print(indices.size())
-
-    data = vd.get_all_data()
-
-    # test iter version of sampler
-    sampler = CompletePixelSamplerIter(1024, data, False)
-
-    num = 0
-
-    for sample in sampler:
-        num += sample["image"].shape[0]
-
-    print(num)
-    assert num == indices.size(0)
-
-    # test original version of sampler
-    sampler = CompletePixelSampler(1024, True)
-
-
-def test_space_time_video_dataset():
-    from pathlib import Path
-    from MSTH.dataset import VideoDatasetAllCached
-    from MSTH.sampler import PixelTimeSampler, PixelTimeUniformSampler
-
-    parser = VideoDataParserConfig(data=Path("/data/machine/data/flame_salmon_videos_2"), downscale_factor=2).setup()
-    outputs = parser._generate_dataparser_outputs("train")
-    with Timer("caching all video frames"):
-        vd = VideoDatasetAllCached(outputs)
-    sampler = PixelTimeUniformSampler(vd, 64, True)
-    sample = sampler.sample()
-    print(sample["time"].shape)
-    print(sample["time"].max())
-
-
-def test_ray_samplers():
-    from pathlib import Path
-    from MSTH.dataset import VideoDatasetAllCached
-    from MSTH.sampler import PixelTimeSampler, PixelTimeUniformSampler
-    from nerfstudio.model_components.ray_generators import RayGenerator
-    from MSTH.datamanager import SpaceTimeDataManagerConfig
-    from pprint import pprint
-
-    parser = VideoDataParserConfig(data=Path("/data/machine/data/flame_salmon_videos_test"), downscale_factor=2)
-    # outputs = parser._generate_dataparser_outputs("train")
-    # with Timer("caching all video frames"):
-    #     vd = VideoDatasetAllCached(outputs)
-    # sampler = PixelTimeUniformSampler(vd, 64, True)
-    # sample = sampler.sample()
-    dm = SpaceTimeDataManagerConfig(dataparser=parser).setup()
-    ray_bundle, batch = dm.next_train(0)
-    print(ray_bundle)
-    print(batch.keys())
-    print(batch["time"])
-
-    ## test model
-    from MSTH.SpaceTimeHashing.model import SpaceTimeHashingModelConfig
-
-    model = SpaceTimeHashingModelConfig().setup(
-        scene_box=dm.train_dataset.scene_box, num_train_data=18, metadata=dm.train_dataset.metadata
-    )
-    model_outputs = model(ray_bundle)
-
-    model.train()
-    ray_samples, weights_list, ray_samples_list = model.proposal_sampler(ray_bundle, density_fns=model.density_fns)
-
-    print(ray_samples_list[0].shape)
-    print(ray_samples_list[1].shape)
-    # print(ray_samples_list[0] == ray_samples[1])
-    # print(weights_list)
-    # print(weights_list[0].max())
-    # print(weights_list[0].min())
-
-    # print(weights_list[0].max())
-    # print(weights_list[1].max())
-    loss = torch.sum(weights_list[0]) + torch.sum(weights_list[1])
-    loss.backward()
-
-    print(model.get_param_groups()["proposal_networks"][0].grad.max())
-    print(model.get_param_groups()["proposal_networks"][0].grad.min())
-    print(model.get_param_groups()["proposal_networks"][1].grad.max())
-    print(model.get_param_groups()["proposal_networks"][1].grad.min())
-
-    # inputs = torch.randn([100, 256, 4]).clamp(0, 1)
-    # wl = model.density_fns[0](inputs)
-    # wl = rs.get_weights(wl)
-    # # print(wl.shape)
-    # # loss = torch.sum(wl[0]) + torch.sum(wl[1])
-    # loss = torch.sum(wl)
-    # loss.backward()
-    # print(model.get_param_groups()["proposal_networks"][0].grad.max())
-
-
-def test_pdf_samples():
-    from MSTH.SpaceTimeHashing.ray_samplers import PDFSamplerSpatial, UniformSamplerSpatial
-    from pathlib import Path
-    from MSTH.dataset import VideoDatasetAllCached
-    from MSTH.sampler import PixelTimeSampler, PixelTimeUniformSampler
-    from nerfstudio.model_components.ray_generators import RayGenerator
-    from MSTH.datamanager import SpaceTimeDataManagerConfig
-
-    parser = VideoDataParserConfig(data=Path("/data/machine/data/flame_salmon_videos_test"), downscale_factor=2)
-    # outputs = parser._generate_dataparser_outputs("train")
-    # with Timer("caching all video frames"):
-    #     vd = VideoDatasetAllCached(outputs)
-    # sampler = PixelTimeUniformSampler(vd, 64, True)
-    # sample = sampler.sample()
-    dm = SpaceTimeDataManagerConfig(dataparser=parser).setup()
-    uni_sampler = UniformSamplerSpatial(256)
-    ray_bundle, batch = dm.next_train(0)
-    ray_bundle.nears = torch.zeros(ray_bundle.origins.shape[0], 1) + 5e-3
-    ray_bundle.fars = torch.zeros(ray_bundle.origins.shape[0], 1) + 1e2
-    ray_samples = uni_sampler(ray_bundle, 256)
-    weights = torch.randn(*ray_samples.shape[:-1], 1).clamp(0)
-    sampler = PDFSamplerSpatial()
-    samples = sampler(ray_bundle, ray_samples, weights, num_samples=48)
-    print(samples.shape)
-
-
-def test_video_cached_dataset_uint8():
-    from MSTH.dataset import VideoDatasetAllCachedUint8
-    from pathlib import Path
-
-    parser = VideoDataParserConfig(data=Path("/data/machine/data/flame_salmon_videos_2"), downscale_factor=2).setup()
-    outputs = parser._generate_dataparser_outputs("train")
-    with Timer("caching all video frames"):
-        vd = VideoDatasetAllCachedUint8(outputs)
-
-
-def test_use_mask():
-    from MSTH.dataset import VideoDatasetAllCachedUint8
-    from pathlib import Path
-
-    parser = VideoDataParserConfig(data=Path("/data/machine/data/flame_salmon_videos_2"), downscale_factor=2).setup()
-    outputs = parser._generate_dataparser_outputs("train")
-    with Timer("caching all video frames"):
-        vd = VideoDatasetAllCachedUint8(outputs, use_mask=True, use_precomputed_mask=False)
-
-
-def test_pixel_time_sampler():
-    from MSTH.dataset import VideoDatasetAllCachedUint8
-    from pathlib import Path
-
-    parser = VideoDataParserConfig(data=Path("/data/machine/data/flame_salmon_videos_2"), downscale_factor=2).setup()
-    outputs = parser._generate_dataparser_outputs("train")
-    with Timer("caching all video frames"):
-        vd = VideoDatasetAllCachedUint8(outputs, use_mask=True, use_precomputed_mask=True)
-    from MSTH.sampler import PixelTimeSampler
-
-    sampler = PixelTimeSampler(vd, 1024, 1.0)
-    samples = sampler.sample()
-    indices = samples["indices"]
-    c, y, x = (i.flatten() for i in torch.split(indices, 1, dim=-1))
-    masks = vd.masks[c, y, x]
-    print("mask is one: {} / {}".format(torch.count_nonzero(masks), masks.numel()))
-
-
-def test_rect_model():
-    from MSTH.SpaceTimeHashing.rect_model import RectSpaceTimeHashingModelConfig
-    from pathlib import Path
-    from MSTH.dataset import VideoDatasetAllCached
-    from MSTH.sampler import PixelTimeSampler, PixelTimeUniformSampler
-    from nerfstudio.model_components.ray_generators import RayGenerator
-    from MSTH.datamanager import SpaceTimeDataManagerConfig
-    from pprint import pprint
-
-    parser = VideoDataParserConfig(data=Path("/data/machine/data/flame_salmon_videos_test"), downscale_factor=2)
-
-    # torch.set_default_tensor_type(torch.cuda.FloatTensor)
-    dm = SpaceTimeDataManagerConfig(dataparser=parser).setup()
-    ray_bundle, batch = dm.next_train(0)
-    print(ray_bundle)
-    print(batch.keys())
-    print(batch["time"])
-
-    ## test model
-    model = (
-        RectSpaceTimeHashingModelConfig()
-        .setup(scene_box=dm.train_dataset.scene_box, num_train_data=18, metadata=dm.train_dataset.metadata)
-        .to("cuda")
-    )
-    model_outputs = model(ray_bundle.to("cuda"))
-    print(model_outputs)
-
-    # ray_samples, weights_list, ray_samples_list = model.proposal_sampler(ray_bundle, density_fns=model.density_fns)
-
-    # model = RectSpaceTimeHashingModelConfig().setup()
-
-
-def test_ndc():
-    from MSTH.SpaceTimeHashing.rect_model import RectSpaceTimeHashingModelConfig
-    from pathlib import Path
-    from MSTH.dataset import VideoDatasetAllCached
-    from MSTH.sampler import PixelTimeSampler, PixelTimeUniformSampler
-    from nerfstudio.model_components.ray_generators import RayGenerator
-    from MSTH.datamanager import SpaceTimeDataManagerConfig
-    from pprint import pprint
-
-    parser = VideoDataParserConfig(data=Path("/data/machine/data/flame_salmon_videos_test"), downscale_factor=2)
-    from MSTH.utils import convert_to_ndc
-
-    # torch.set_default_tensor_type(torch.cuda.FloatTensor)
-    dm = SpaceTimeDataManagerConfig(dataparser=parser).setup()
-    ray_bundle, batch = dm.next_train(0)
-    print(ray_bundle)
-    cameras = dm.train_dataparser_outputs.cameras
-    convert_to_ndc(ray_bundle, dm.train_dataset.metadata["ndc_coeffs"])
-    print(ray_bundle)
-    # print(batch.keys())
-    # print(batch["time"])
-
-    # ## test model
-    # model = RectSpaceTimeHashingModelConfig(use_ndc=True).setup(scene_box=dm.train_dataset.scene_box, num_train_data=18, metadata=dm.train_dataset.metadata).to("cuda")
-    # model_outputs = model(ray_bundle.to("cuda"))
-
-
-def test_dataset_get_median():
-    from MSTH.dataset import VideoDatasetAllCachedUint8
-    from MSTH.dataset import VideoDatasetAllCachedUint8
-    from pathlib import Path
-
-    parser = VideoDataParserConfig(data=Path("/data/machine/data/flame_salmon_videos_2"), downscale_factor=2).setup()
-    outputs = parser._generate_dataparser_outputs("train")
-    with Timer("caching all video frames"):
-        vd = VideoDatasetAllCachedUint8(outputs, use_median=True)
-
-
-def test_isg_sampler():
-    from MSTH.sampler import ISGSampler
-    from MSTH.dataset import VideoDatasetAllCachedUint8
-    from pathlib import Path
-
-    parser = VideoDataParserConfig(data=Path("/data/machine/data/flame_salmon_videos_2"), downscale_factor=2).setup()
-    outputs = parser._generate_dataparser_outputs("train")
-    with Timer("caching all video frames"):
-        vd = VideoDatasetAllCachedUint8(outputs, use_median=True)
-    sampler = ISGSampler(vd, 128, 32, 1e-3)
-    with Timer("sampler once from ISG sampler"):
-        sampler.sample()
-
-
-def test_torchvision_video():
-    from torchvision.io import write_video
-
-    frames = torch.zeros([100, 512, 512, 3], dtype=torch.uint8)
-    frames[::10] = 255
-    write_video("/data/czl/tmp/test_video.mp4", frames, 30)
-
-
-def test_render_spiral(path, save_path):
-    from MSTH.video_pipeline import VideoPipeline
-    from MSTH.SpaceTimeHashing.trainer import SpaceTimeHashingTrainerConfig
-    from MSTH.configs.method_configs import method_configs
-    from nerfstudio.utils.eval_utils import eval_setup
-    from pathlib import Path
-
-    # trainer = method_configs["dsth_with_base"].setup(local_rank=0, world_size=1)
-    # trainer.setup()
-    # pipeline = trainer.pipeline
-    # config = torch.load("/data/czl/nerf/MSTH_new/MSTH/tmp/dsth_with_base/Spatial_Time_Hashing_With_Base/2023-04-06_013551/nerfstudio_models/step-000029999.ckpt")
-    # pipeline.load_pipeline(config["pipeline"], 29999)
-    # # pipeline.render_from_cameras(1.0, 5.0, save_path="/data/czl/tmp/test.mp4", fps=5, num_frames=5)
-    # trainer.mock_eval()
-    config_path = Path(path)
-    _, pipeline, _ = eval_setup(config_path)
-    print(pipeline.config)
-    pipeline.mock_eval()
-    pipeline.render_from_cameras(1.0, 5.0, save_path=save_path, fps=30, num_frames=300)
-
-
-def test_load():
-    from MSTH.SpaceTimeHashing.trainer import SpaceTimeHashingTrainer
-    from MSTH.configs.method_configs import method_configs
-    from MSTH.video_pipeline import VideoPipeline
-    from MSTH.SpaceTimeHashing.trainer import SpaceTimeHashingTrainerConfig
-    from MSTH.configs.method_configs import method_configs
-    from nerfstudio.utils.eval_utils import eval_setup
-    from pathlib import Path
-
-    config = method_configs["dsth_with_base"]
-    config.save_only_latest_checkpoint = False
-    config.max_num_iterations = 500
-    config.viewer.quit_on_train_completion = True
-    trainer = config.setup()
-    config.save_config()
-    trainer.setup()
-    trainer.train()
-
-    ## save ckpt
-    trainer.save_checkpoint(0)
-
-    ckpt_dir = trainer.checkpoint_dir
-
-    config_path = ckpt_dir.parent.absolute() / "config.yml"
-
-    _, pipeline, _ = eval_setup(config_path)
-
-    trainer.mock_eval()
-    cpipeline = trainer.pipeline
-    pipeline.mock_eval()
-
-    cf = cpipeline.get_param_groups()["fields"]
-    f = pipeline.get_param_groups()["fields"]
-    with torch.no_grad():
-        for p, q in zip(cf, f):
-            print(torch.abs(p - q).max())
-
-    print("hello")
-
-
-if __name__ == "__main__":
-    # test_ray_samplers()
-    # test_video_cached_dataset_uint8()
-    # test_pdf_samples()
-    # test_use_mask()
-    # test_pixel_time_sampler()
-    # test_use_mask()
-    # test_rect_model()
-    # test_ray_samplers()
-    # test_ndc()
-    # test_dataset_get_median()
-    # test_isg_sampler()
-    # test_torchvision_video()
-    parser = argparse.ArgumentParser()
-    parser.add_argument(
-        "--path",
-        type=str,
-        default="/data/czl/nerf/MSTH_new/MSTH/tmp/dsth_with_base/Spatial_Time_Hashing_With_Base/2023-04-06_013551/config.yml",
-    )
-    parser.add_argument(
-        "--save_path",
-        type=str,
-        default="/data/czl/tmp/test_v1.2_rawvideo.avi",
-    )
-    args = parser.parse_args()
-    test_render_spiral(args.path, args.save_path)
-    # test_load()
+import wandb
+import random
+
+# start a new wandb run to track this script
+wandb.init(
+    # set the wandb project where this run will be logged
+    project="my-awesome-project",
+    # track hyperparameters and run metadata
+    config={
+        "learning_rate": 0.02,
+        "architecture": "CNN",
+        "dataset": "CIFAR-100",
+        "epochs": 10,
+    },
+)
+
+# simulate training
+epochs = 10
+offset = random.random() / 5
+for epoch in range(2, epochs):
+    acc = 1 - 2**-epoch - random.random() / epoch - offset
+    loss = 2**-epoch + random.random() / epoch + offset
+
+    # log metrics to wandb
+    wandb.log({"acc": acc, "loss": loss})
+
+# [optional] finish the wandb run, necessary in notebooks
+wandb.finish()
diff --git a/MSTH/utils.py b/MSTH/utils.py
index e3cfbaa..90b9fda 100644
--- a/MSTH/utils.py
+++ b/MSTH/utils.py
@@ -1,6 +1,7 @@
 import time
 from collections import defaultdict
 from pprint import pprint
+import torch
 
 
 class Timer:
@@ -12,14 +13,23 @@ class Timer:
         self.record = record
 
     def __enter__(self):
+        return self
         self.start = time.time()
+        self.start_cuda = torch.cuda.Event(enable_timing=True)
+        self.end_cuda = torch.cuda.Event(enable_timing=True)
+        self.start_cuda.record()
         return self
 
     def __exit__(self, *args):
+        return
         self.end = time.time()
+        self.end_cuda.record()
         self.interval = self.end - self.start
         if self.verbose:
-            print(f"{self.des} consuming {self.interval:.2f}")
+            torch.cuda.synchronize()
+            print(f"[cudasync]{self.des} consuming {self.start_cuda.elapsed_time(self.end_cuda)/1000.:.8f}")
+
+            print(f"{self.des} consuming {self.interval:.8f}")
         if self.record:
             Timer.recorder[self.des].append(self.interval)
 
diff --git a/MSTH/video_pipeline.py b/MSTH/video_pipeline.py
index 0fd9c88..12a8701 100644
--- a/MSTH/video_pipeline.py
+++ b/MSTH/video_pipeline.py
@@ -355,7 +355,8 @@ class SpaceTimePipeline(Pipeline):
     def get_eval_image_metrics_and_images(self, step: int):
         # TODO: eval several frame at one call
         self.eval()
-        frame_idx = random.sample([0, 150, 299], 1)[0]
+        n_f = self.datamanager.eval_dataset.frames.size(1)
+        frame_idx = random.sample([0, n_f // 2, n_f - 1], 1)[0]
         image_idx, camera_ray_bundle, batch = self.datamanager.next_eval_image(frame_idx)
         outputs = self.model.get_outputs_for_camera_ray_bundle(camera_ray_bundle)
         metrics_dict, images_dict = self.model.get_image_metrics_and_images(outputs, batch)
diff --git a/nerfstudio/model_components/ray_samplers.py b/nerfstudio/model_components/ray_samplers.py
index 866218b..1c44044 100755
--- a/nerfstudio/model_components/ray_samplers.py
+++ b/nerfstudio/model_components/ray_samplers.py
@@ -386,7 +386,6 @@ class VolumetricSampler(Sampler):
         density_fn: Optional[Callable[[TensorType[..., 3]], TensorType[..., 1]]] = None,
         scene_aabb: Optional[TensorType[2, 3]] = None,
     ) -> None:
-
         super().__init__()
         self.scene_aabb = scene_aabb
         self.density_fn = density_fn
diff --git a/nerfstudio/models/base_model.py b/nerfstudio/models/base_model.py
index 51de441..0d382c8 100755
--- a/nerfstudio/models/base_model.py
+++ b/nerfstudio/models/base_model.py
@@ -35,6 +35,8 @@ from nerfstudio.engine.callbacks import TrainingCallback, TrainingCallbackAttrib
 from nerfstudio.model_components.scene_colliders import NearFarCollider
 
 from MSTH.utils import Timer
+import time
+
 
 # Model related configs
 @dataclass
@@ -172,6 +174,7 @@ class Model(nn.Module):
         num_rays = len(camera_ray_bundle)
         outputs_lists = defaultdict(list)
         with Timer("forwarding"):
+            _t1 = time.time()
             for i in range(0, num_rays, num_rays_per_chunk):
                 start_idx = i
                 end_idx = i + num_rays_per_chunk
@@ -179,6 +182,7 @@ class Model(nn.Module):
                 outputs = self.forward(ray_bundle=ray_bundle)
                 for output_name, output in outputs.items():  # type: ignore
                     outputs_lists[output_name].append(output)
+            print(f"forwarding took {time.time() - _t1} seconds")
         outputs = {}
         for output_name, outputs_list in outputs_lists.items():
             if not torch.is_tensor(outputs_list[0]):
Submodule tiny-cuda-nn contains untracked content
Submodule tiny-cuda-nn contains modified content
diff --git a/tiny-cuda-nn/include/tiny-cuda-nn/encodings/grid.h b/tiny-cuda-nn/include/tiny-cuda-nn/encodings/grid.h
index acda558..61d73a4 100644
--- a/tiny-cuda-nn/include/tiny-cuda-nn/encodings/grid.h
+++ b/tiny-cuda-nn/include/tiny-cuda-nn/encodings/grid.h
@@ -217,6 +217,102 @@ __global__ void extract_position(
 	output[i + dim_idx * num_elements] = (T)data_in(i)[dim_idx];
 }
 
+template <typename T, uint32_t N_POS_DIMS, uint32_t N_FEATURES_PER_LEVEL, HashType HASH_TYPE>
+__global__ void kernel_grid_reset(
+	pcg32& rnd,
+	const uint32_t num_elements,
+	const uint32_t num_grid_features,
+	const GridOffsetTable offset_table,
+	const uint32_t base_resolution,
+	const float log2_per_level_scale,
+	const float quantize_threshold,
+	float max_level,
+	const float* __restrict__ max_level_gpu,
+	const InterpolationType interpolation_type,
+	const GridType grid_type,
+	const T* __restrict__ grid,
+	MatrixView<const float> positions_in,
+	float scale = 1,
+) {
+	const uint32_t i = blockIdx.x * blockDim.x + threadIdx.x;
+	if (i >= num_elements) return;
+
+	const uint32_t level = blockIdx.y; // <- the level is the same for all threads
+
+	if (max_level_gpu) {
+		max_level = (max_level_gpu[i] * num_grid_features) / N_FEATURES_PER_LEVEL;
+	} else {
+		max_level = (max_level * num_grid_features) / N_FEATURES_PER_LEVEL;
+	}
+
+	if (level >= max_level + 1e-3f) {
+		return;
+	}
+
+	grid += offset_table.data[level] * N_FEATURES_PER_LEVEL;
+	const uint32_t hashmap_size = offset_table.data[level + 1] - offset_table.data[level];
+
+	const float scale = grid_scale(level, log2_per_level_scale, base_resolution);
+	const uint32_t resolution = grid_resolution(scale);
+
+	float pos[N_POS_DIMS];
+	float pos_derivative[N_POS_DIMS];
+	uint32_t pos_grid[N_POS_DIMS];
+
+	if (interpolation_type == InterpolationType::Nearest || interpolation_type == InterpolationType::Linear) {
+		TCNN_PRAGMA_UNROLL
+		for (uint32_t dim = 0; dim < N_POS_DIMS; ++dim) {
+			pos_fract(positions_in(dim, i), &pos[dim], &pos_derivative[dim], &pos_grid[dim], scale, identity_fun, identity_derivative);
+		}
+	} else {
+		TCNN_PRAGMA_UNROLL
+		for (uint32_t dim = 0; dim < N_POS_DIMS; ++dim) {
+			pos_fract(positions_in(dim, i), &pos[dim], &pos_derivative[dim], &pos_grid[dim], scale, smoothstep, smoothstep_derivative);
+		}
+	}
+
+	auto grid_val = [&](const uint32_t local_pos[N_POS_DIMS]) {
+		const uint32_t index = grid_index<N_POS_DIMS, HASH_TYPE>(grid_type, hashmap_size, resolution, local_pos) * N_FEATURES_PER_LEVEL;
+		return *(vector_t<T, N_FEATURES_PER_LEVEL>*)&grid[index];
+	};
+
+	if (interpolation_type == InterpolationType::Nearest) {
+		auto result = grid_val(pos_grid);
+		return;
+	}
+
+	// N-linear interpolation
+	vector_t<T, N_FEATURES_PER_LEVEL> result = {};
+
+	rnd.advance(i*N_FEATURES_PER_LEVEL);
+	TCNN_PRAGMA_UNROLL
+	for (uint32_t idx = 0; idx < (1 << N_POS_DIMS); ++idx) {
+		float weight = 1;
+		uint32_t pos_grid_local[N_POS_DIMS];
+
+		TCNN_PRAGMA_UNROLL
+		for (uint32_t dim = 0; dim < N_POS_DIMS; ++dim) {
+			if ((idx & (1<<dim)) == 0) {
+				weight *= 1 - pos[dim];
+				pos_grid_local[dim] = pos_grid[dim];
+			} else {
+				weight *= pos[dim];
+				pos_grid_local[dim] = pos_grid[dim] + 1;
+			}
+		}
+
+		auto val = grid_val(pos_grid_local);
+		
+		TCNN_PRAGMA_UNROLL
+		for (uint32_t feature = 0; feature < N_FEATURES_PER_LEVEL; ++feature) {
+			rnd_value = rnd.next_float();
+			rnd_value = rnd_value * (2e-4f) * scale - 1e-4f * scale;
+			((T*)&val)[feature] = (T)rnd_value;
+		}
+	}
+
+}
+
 template <typename T, uint32_t N_POS_DIMS, uint32_t N_FEATURES_PER_LEVEL, HashType HASH_TYPE>
 __global__ void kernel_grid(
 	const uint32_t num_elements,
@@ -1021,6 +1117,37 @@ public:
 		}
 	}
 
+	void reset_params(
+		cudaStream_t stream,
+		const GPUMatrixDynamic<float>& input,
+		pcg32& rnd,
+	){
+		auto forward = std::make_unique<ForwardContext>();
+		const uint32_t num_elements = input.n();
+
+		SyncedMultiStream synced_streams{stream, m_n_to_pad > 0 ? 2u : 1u};
+
+		static constexpr uint32_t N_THREADS_HASHGRID = 512;
+		const dim3 blocks_hashgrid = { div_round_up(num_elements, N_THREADS_HASHGRID), m_n_levels, 1 };
+
+		kernel_grid_reset<T, N_POS_DIMS, N_FEATURES_PER_LEVEL, HASH_TYPE><<<blocks_hashgrid, N_THREADS_HASHGRID, 0, synced_streams.get(0)>>>(
+			rnd,
+			num_elements,
+			m_n_features,
+			m_offset_table,
+			m_base_resolution,
+			std::log2(m_per_level_scale),
+			this->m_quantize_threshold,
+			this->m_max_level,
+			this->m_max_level_gpu,
+			m_interpolation_type,
+			m_grid_type,
+			use_inference_params ? this->inference_params() : this->params(),
+			forward->positions.data() ? forward->positions.view() : input.view()
+		);
+		rnd.advance(num_elements);
+	}
+
 	std::unique_ptr<Context> forward_impl(
 		cudaStream_t stream,
 		const GPUMatrixDynamic<float>& input,
Submodule torch-ngp contains untracked content
Submodule torch-ngp contains modified content
diff --git a/torch-ngp/gridencoder/grid.py b/torch-ngp/gridencoder/grid.py
index 32b8bea..35b2f66 100644
--- a/torch-ngp/gridencoder/grid.py
+++ b/torch-ngp/gridencoder/grid.py
@@ -8,7 +8,9 @@ from torch.cuda.amp import custom_bwd, custom_fwd
 
 try:
     import _gridencoder as _backend
+    print("NO")
 except ImportError:
+    print("NO!!!!!!!!!")
     from .backend import _backend
 
 _gridtype_to_id = {
diff --git a/torch-ngp/gridencoder/src/gridencoder.cu b/torch-ngp/gridencoder/src/gridencoder.cu
index cba5e94..e840a88 100644
--- a/torch-ngp/gridencoder/src/gridencoder.cu
+++ b/torch-ngp/gridencoder/src/gridencoder.cu
@@ -94,7 +94,8 @@ __global__ void kernel_grid(
     scalar_t * __restrict__ dy_dx,
     const uint32_t gridtype,
     const bool align_corners,
-    const uint32_t interp
+    const uint32_t interp,
+    const bool interp_last_dimension,
 ) {
     const uint32_t b = blockIdx.x * blockDim.x + threadIdx.x;
     
@@ -370,14 +371,14 @@ __global__ void kernel_input_backward(
 
 
 template <typename scalar_t, uint32_t D>
-void kernel_grid_wrapper(const float *inputs, const scalar_t *embeddings, const int *offsets, scalar_t *outputs, const uint32_t B, const uint32_t C, const uint32_t L, const float S, const uint32_t H, scalar_t *dy_dx, const uint32_t gridtype, const bool align_corners, const uint32_t interp) {
+void kernel_grid_wrapper(const float *inputs, const scalar_t *embeddings, const int *offsets, scalar_t *outputs, const uint32_t B, const uint32_t C, const uint32_t L, const float S, const uint32_t H, scalar_t *dy_dx, const uint32_t gridtype, const bool align_corners, const uint32_t interp, const bool interp_last_dimension) {
     static constexpr uint32_t N_THREAD = 512;
     const dim3 blocks_hashgrid = { div_round_up(B, N_THREAD), L, 1 };
     switch (C) {
-        case 1: kernel_grid<scalar_t, D, 1><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
-        case 2: kernel_grid<scalar_t, D, 2><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
-        case 4: kernel_grid<scalar_t, D, 4><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
-        case 8: kernel_grid<scalar_t, D, 8><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+        case 1: kernel_grid<scalar_t, D, 1><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp, interp_last_dimension); break;
+        case 2: kernel_grid<scalar_t, D, 2><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp, interp_last_dimension); break;
+        case 4: kernel_grid<scalar_t, D, 4><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp, interp_last_dimension); break;
+        case 8: kernel_grid<scalar_t, D, 8><<<blocks_hashgrid, N_THREAD>>>(inputs, embeddings, offsets, outputs, B, L, S, H, dy_dx, gridtype, align_corners, interp, interp_last_dimension); break;
         default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
     }
 }
@@ -389,12 +390,12 @@ void kernel_grid_wrapper(const float *inputs, const scalar_t *embeddings, const
 // H: base resolution
 // dy_dx: [B, L * D * C]
 template <typename scalar_t>
-void grid_encode_forward_cuda(const float *inputs, const scalar_t *embeddings, const int *offsets, scalar_t *outputs, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const float S, const uint32_t H, scalar_t *dy_dx, const uint32_t gridtype, const bool align_corners, const uint32_t interp) {
+void grid_encode_forward_cuda(const float *inputs, const scalar_t *embeddings, const int *offsets, scalar_t *outputs, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const float S, const uint32_t H, scalar_t *dy_dx, const uint32_t gridtype, const bool align_corners, const uint32_t interp, const bool interp_last_dimension) {
     switch (D) {
-        case 2: kernel_grid_wrapper<scalar_t, 2>(inputs, embeddings, offsets, outputs, B, C, L, S, H, dy_dx, gridtype, align_corners, interp); break;
-        case 3: kernel_grid_wrapper<scalar_t, 3>(inputs, embeddings, offsets, outputs, B, C, L, S, H, dy_dx, gridtype, align_corners, interp); break;
-        case 4: kernel_grid_wrapper<scalar_t, 4>(inputs, embeddings, offsets, outputs, B, C, L, S, H, dy_dx, gridtype, align_corners, interp); break;
-        case 5: kernel_grid_wrapper<scalar_t, 5>(inputs, embeddings, offsets, outputs, B, C, L, S, H, dy_dx, gridtype, align_corners, interp); break;
+        case 2: kernel_grid_wrapper<scalar_t, 2>(inputs, embeddings, offsets, outputs, B, C, L, S, H, dy_dx, gridtype, align_corners, interp, interp_last_dimension); break;
+        case 3: kernel_grid_wrapper<scalar_t, 3>(inputs, embeddings, offsets, outputs, B, C, L, S, H, dy_dx, gridtype, align_corners, interp, interp_last_dimension); break;
+        case 4: kernel_grid_wrapper<scalar_t, 4>(inputs, embeddings, offsets, outputs, B, C, L, S, H, dy_dx, gridtype, align_corners, interp, interp_last_dimension); break;
+        case 5: kernel_grid_wrapper<scalar_t, 5>(inputs, embeddings, offsets, outputs, B, C, L, S, H, dy_dx, gridtype, align_corners, interp, interp_last_dimension); break;
         default: throw std::runtime_error{"GridEncoding: C must be 1, 2, 4, or 8."};
     }   
 }
@@ -445,7 +446,7 @@ void grid_encode_backward_cuda(const scalar_t *grad, const float *inputs, const
 
 
 
-void grid_encode_forward(const at::Tensor inputs, const at::Tensor embeddings, const at::Tensor offsets, at::Tensor outputs, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const float S, const uint32_t H, at::optional<at::Tensor> dy_dx, const uint32_t gridtype, const bool align_corners, const uint32_t interp) {
+void grid_encode_forward(const at::Tensor inputs, const at::Tensor embeddings, const at::Tensor offsets, at::Tensor outputs, const uint32_t B, const uint32_t D, const uint32_t C, const uint32_t L, const float S, const uint32_t H, at::optional<at::Tensor> dy_dx, const uint32_t gridtype, const bool align_corners, const uint32_t interp, const bool interp_last_dimension) {
     CHECK_CUDA(inputs);
     CHECK_CUDA(embeddings);
     CHECK_CUDA(offsets);
@@ -466,7 +467,7 @@ void grid_encode_forward(const at::Tensor inputs, const at::Tensor embeddings, c
 
     AT_DISPATCH_FLOATING_TYPES_AND_HALF(
     embeddings.scalar_type(), "grid_encode_forward", ([&] {
-        grid_encode_forward_cuda<scalar_t>(inputs.data_ptr<float>(), embeddings.data_ptr<scalar_t>(), offsets.data_ptr<int>(), outputs.data_ptr<scalar_t>(), B, D, C, L, S, H, dy_dx.has_value() ? dy_dx.value().data_ptr<scalar_t>() : nullptr, gridtype, align_corners, interp);
+        grid_encode_forward_cuda<scalar_t>(inputs.data_ptr<float>(), embeddings.data_ptr<scalar_t>(), offsets.data_ptr<int>(), outputs.data_ptr<scalar_t>(), B, D, C, L, S, H, dy_dx.has_value() ? dy_dx.value().data_ptr<scalar_t>() : nullptr, gridtype, align_corners, interp, interp_last_dimension);
     }));
 }
 
diff --git a/torch-ngp/scripts/llff2nerf.py b/torch-ngp/scripts/llff2nerf.py
index ac39a72..1bca353 100644
--- a/torch-ngp/scripts/llff2nerf.py
+++ b/torch-ngp/scripts/llff2nerf.py
@@ -6,12 +6,13 @@ import json
 import trimesh
 import argparse
 
+
 # returns point closest to both rays of form o+t*d, and a weight factor that goes to 0 if the lines are parallel
-def closest_point_2_lines(oa, da, ob, db): 
+def closest_point_2_lines(oa, da, ob, db):
     da = da / np.linalg.norm(da)
     db = db / np.linalg.norm(db)
     c = np.cross(da, db)
-    denom = np.linalg.norm(c)**2
+    denom = np.linalg.norm(c) ** 2
     t = ob - oa
     ta = np.linalg.det([t, db, c]) / (denom + 1e-10)
     tb = np.linalg.det([t, da, c]) / (denom + 1e-10)
@@ -19,18 +20,19 @@ def closest_point_2_lines(oa, da, ob, db):
         ta = 0
     if tb > 0:
         tb = 0
-    return (oa+ta*da+ob+tb*db) * 0.5, denom
+    return (oa + ta * da + ob + tb * db) * 0.5, denom
+
 
 def rotmat(a, b):
-	a, b = a / np.linalg.norm(a), b / np.linalg.norm(b)
-	v = np.cross(a, b)
-	c = np.dot(a, b)
-	# handle exception for the opposite direction input
-	if c < -1 + 1e-10:
-		return rotmat(a + np.random.uniform(-1e-2, 1e-2, 3), b)
-	s = np.linalg.norm(v)
-	kmat = np.array([[0, -v[2], v[1]], [v[2], 0, -v[0]], [-v[1], v[0], 0]])
-	return np.eye(3) + kmat + kmat.dot(kmat) * ((1 - c) / (s ** 2 + 1e-10))
+    a, b = a / np.linalg.norm(a), b / np.linalg.norm(b)
+    v = np.cross(a, b)
+    c = np.dot(a, b)
+    # handle exception for the opposite direction input
+    if c < -1 + 1e-10:
+        return rotmat(a + np.random.uniform(-1e-2, 1e-2, 3), b)
+    s = np.linalg.norm(v)
+    kmat = np.array([[0, -v[2], v[1]], [v[2], 0, -v[0]], [-v[1], v[0], 0]])
+    return np.eye(3) + kmat + kmat.dot(kmat) * ((1 - c) / (s**2 + 1e-10))
 
 
 def visualize_poses(poses, size=0.1):
@@ -59,60 +61,71 @@ def visualize_poses(poses, size=0.1):
 
     trimesh.Scene(objects).show()
 
-if __name__ == '__main__':
 
+if __name__ == "__main__":
     parser = argparse.ArgumentParser()
-    parser.add_argument('path', type=str, help="root directory to the LLFF dataset (contains images/ and pose_bounds.npy)")
-    parser.add_argument('--images', type=str, default='images_8', help="images folder (do not include full path, e.g., just use `images_4`)")
-    parser.add_argument('--downscale', type=float, default=8, help="image size down scale, e.g., 4")
-    parser.add_argument('--hold', type=int, default=8, help="hold out for validation every $ images")
+    parser.add_argument(
+        "path", type=str, help="root directory to the LLFF dataset (contains images/ and pose_bounds.npy)"
+    )
+    parser.add_argument(
+        "--images",
+        type=str,
+        default="images_8",
+        help="images folder (do not include full path, e.g., just use `images_4`)",
+    )
+    parser.add_argument("--downscale", type=float, default=8, help="image size down scale, e.g., 4")
+    parser.add_argument("--hold", type=int, default=8, help="hold out for validation every $ images")
 
     opt = parser.parse_args()
-    print(f'[INFO] process {opt.path}')
+    print(f"[INFO] process {opt.path}")
 
     # path must end with / to make sure image path is relative
-    if opt.path[-1] != '/':
-        opt.path += '/'
-    
+    if opt.path[-1] != "/":
+        opt.path += "/"
+
     # load data
-    images = [f[len(opt.path):] for f in sorted(glob.glob(os.path.join(opt.path, opt.images, "*"))) if f.lower().endswith('png') or f.lower().endswith('jpg') or f.lower().endswith('jpeg')]
-    
-    poses_bounds = np.load(os.path.join(opt.path, 'poses_bounds.npy'))
+    images = [
+        f[len(opt.path) :]
+        for f in sorted(glob.glob(os.path.join(opt.path, opt.images, "*")))
+        if f.lower().endswith("png") or f.lower().endswith("jpg") or f.lower().endswith("jpeg")
+    ]
+
+    poses_bounds = np.load(os.path.join(opt.path, "poses_bounds.npy"))
     N = poses_bounds.shape[0]
 
-    print(f'[INFO] loaded {len(images)} images, {N} poses_bounds as {poses_bounds.shape}')
+    print(f"[INFO] loaded {len(images)} images, {N} poses_bounds as {poses_bounds.shape}")
 
     assert N == len(images)
 
-    poses = poses_bounds[:, :15].reshape(-1, 3, 5) # (N, 3, 5)
-    bounds = poses_bounds[:, -2:] # (N, 2)
+    poses = poses_bounds[:, :15].reshape(-1, 3, 5)  # (N, 3, 5)
+    bounds = poses_bounds[:, -2:]  # (N, 2)
 
-    H, W, fl = poses[0, :, -1] 
+    H, W, fl = poses[0, :, -1]
 
     H = H // opt.downscale
     W = W // opt.downscale
     fl = fl / opt.downscale
 
-    print(f'[INFO] H = {H}, W = {W}, fl = {fl} (downscale = {opt.downscale})')
+    print(f"[INFO] H = {H}, W = {W}, fl = {fl} (downscale = {opt.downscale})")
 
     # inversion of this: https://github.com/Fyusion/LLFF/blob/c6e27b1ee59cb18f054ccb0f87a90214dbe70482/llff/poses/pose_utils.py#L51
-    poses = np.concatenate([poses[..., 1:2], poses[..., 0:1], -poses[..., 2:3], poses[..., 3:4]], -1) # (N, 3, 4)
+    poses = np.concatenate([poses[..., 1:2], poses[..., 0:1], -poses[..., 2:3], poses[..., 3:4]], -1)  # (N, 3, 4)
 
-    # to homogeneous 
-    last_row = np.tile(np.array([0, 0, 0, 1]), (len(poses), 1, 1)) # (N, 1, 4)
-    poses = np.concatenate([poses, last_row], axis=1) # (N, 4, 4) 
+    # to homogeneous
+    last_row = np.tile(np.array([0, 0, 0, 1]), (len(poses), 1, 1))  # (N, 1, 4)
+    poses = np.concatenate([poses, last_row], axis=1)  # (N, 4, 4)
 
     # visualize_poses(poses)
 
     # the following stuff are from colmap2nerf... [flower fails, the camera must be in-ward...]
     poses[:, 0:3, 1] *= -1
     poses[:, 0:3, 2] *= -1
-    poses = poses[:, [1, 0, 2, 3], :] # swap y and z
-    poses[:, 2, :] *= -1 # flip whole world upside down
+    poses = poses[:, [1, 0, 2, 3], :]  # swap y and z
+    poses[:, 2, :] *= -1  # flip whole world upside down
 
     up = poses[:, 0:3, 1].sum(0)
     up = up / np.linalg.norm(up)
-    R = rotmat(up, [0, 0, 1]) # rotate up vector to [0,0,1]
+    R = rotmat(up, [0, 0, 1])  # rotate up vector to [0,0,1]
     R = np.pad(R, [0, 1])
     R[-1, -1] = 1
 
@@ -124,60 +137,62 @@ if __name__ == '__main__':
         mf = poses[i, :3, :]
         for j in range(i + 1, N):
             mg = poses[j, :3, :]
-            p, w = closest_point_2_lines(mf[:,3], mf[:,2], mg[:,3], mg[:,2])
-            #print(i, j, p, w)
+            p, w = closest_point_2_lines(mf[:, 3], mf[:, 2], mg[:, 3], mg[:, 2])
+            # print(i, j, p, w)
             if w > 0.01:
                 totp += p * w
                 totw += w
     totp /= totw
-    print(f'[INFO] totp = {totp}')
+    print(f"[INFO] totp = {totp}")
     poses[:, :3, 3] -= totp
     avglen = np.linalg.norm(poses[:, :3, 3], axis=-1).mean()
     poses[:, :3, 3] *= 4.0 / avglen
-    print(f'[INFO] average radius = {avglen}')
+    print(f"[INFO] average radius = {avglen}")
 
     # visualize_poses(poses)
 
     # construct frames
 
     all_ids = np.arange(N)
-    test_ids = all_ids[::opt.hold]
+    test_ids = all_ids[:: opt.hold]
     train_ids = np.array([i for i in all_ids if i not in test_ids])
 
     frames_train = []
     frames_test = []
     for i in train_ids:
-        frames_train.append({
-            'file_path': images[i],
-            'transform_matrix': poses[i].tolist(),
-        })
+        frames_train.append(
+            {
+                "file_path": images[i].split("/")[-1].split("_")[0] + ".mp4",
+                "transform_matrix": poses[i].tolist(),
+            }
+        )
     for i in test_ids:
-        frames_test.append({
-            'file_path': images[i],
-            'transform_matrix': poses[i].tolist(),
-        })
+        frames_test.append(
+            {
+                "file_path": images[i].split("/")[-1].split("_")[0] + ".mp4",
+                "transform_matrix": poses[i].tolist(),
+            }
+        )
 
     def write_json(filename, frames):
-
         # construct a transforms.json
         out = {
-            'w': W,
-            'h': H,
-            'fl_x': fl,
-            'fl_y': fl,
-            'cx': W // 2,
-            'cy': H // 2,
-            'aabb_scale': 2,
-            'frames': frames,
+            "w": W,
+            "h": H,
+            "fl_x": fl,
+            "fl_y": fl,
+            "cx": W // 2,
+            "cy": H // 2,
+            "aabb_scale": 2,
+            "frames": frames,
         }
 
         # write
         output_path = os.path.join(opt.path, filename)
-        print(f'[INFO] write {len(frames)} images to {output_path}')
-        with open(output_path, 'w') as f:
+        print(f"[INFO] write {len(frames)} images to {output_path}")
+        with open(output_path, "w") as f:
             json.dump(out, f, indent=2)
 
-    write_json('transforms_train.json', frames_train)
-    write_json('transforms_val.json', frames_test[::10])
-    write_json('transforms_test.json', frames_test)
-
+    write_json("transforms_train.json", frames_train)
+    write_json("transforms_val.json", frames_test[::10])
+    write_json("transforms_test.json", frames_test)
